# ðŸš€ Guide d'Installation et d'Utilisation - Nextvision v2.0 Test Suite

## ðŸ“‹ Vue d'ensemble

Ce systÃ¨me de test massif permet de valider Nextvision v2.0 Ã  grande Ã©chelle avec :
- **2,346 combinaisons** (69 CVs Ã— 34 FDPs)
- **Simulations questionnaires** rÃ©alistes
- **Analytics avancÃ©es** et visualisations
- **Monitoring temps rÃ©el**
- **Comparaisons A/B** de scÃ©narios

## ðŸ› ï¸ Installation

### 1. PrÃ©requis

```bash
# Python 3.13.4 requis
python3 --version

# Environnement virtuel Nextvision
source nextvision-env/bin/activate

# VÃ©rification API Nextvision v2.0
cd /path/to/nextvision
git checkout feature/bidirectional-matching-v2
```

### 2. Installation des dÃ©pendances

```bash
# DÃ©pendances principales
pip install requests pandas numpy matplotlib seaborn plotly
pip install psutil scikit-learn scipy aiohttp

# Pour les visualisations avancÃ©es
pip install jupyter notebook  # optionnel
```

### 3. Configuration des chemins

Modifiez les chemins dans `nextvision_master_controller.py` :

```python
# Configuration globale
API_URL = "http://localhost:8000"
CV_DIR = "/Users/baptistecomas/Desktop/CV TEST"
FDP_DIR = "/Users/baptistecomas/Desktop/FDP TEST"
```

## ðŸš€ DÃ©marrage Rapide

### Option 1: Interface UnifiÃ©e (RecommandÃ©e)

```bash
python nextvision_master_controller.py
```

Cette interface vous permet de :
- âœ… VÃ©rifier automatiquement l'API
- ðŸŽ¯ Lancer tous types de tests
- ðŸ“Š GÃ©nÃ©rer visualisations
- ðŸ“ˆ Monitoring temps rÃ©el

### Option 2: Scripts Individuels

```bash
# Test massif personnalisÃ©
python nextvision_mass_testing.py

# Visualisations uniquement
python nextvision_visualizer.py

# Analytics avancÃ©es
python nextvision_advanced_analyzer.py
```

## ðŸ“Š Types de Tests Disponibles

### 1. ðŸ§ª Test Massif Standard
- **Objectif**: Validation de performance Ã  grande Ã©chelle
- **DonnÃ©es**: 69 CVs Ã— 34 FDPs = 2,346 combinaisons
- **Temps estimÃ©**: 3-5 minutes complet
- **RÃ©sultats**: Scores, temps, analytics

```bash
# Via l'interface principale
Choix 3: Test Massif Complet
```

### 2. ðŸŽ¯ Test Rapide (100 combinaisons)
- **Objectif**: Validation rapide de fonctionnement
- **Temps estimÃ©**: 10-30 secondes
- **Utilisation**: Tests de rÃ©gression, debug

```bash
# Via l'interface principale  
Choix 2: Test Massif Rapide
```

### 3. ðŸ§ª Comparaison de ScÃ©narios
- **Objectif**: A/B testing de profils utilisateurs
- **ScÃ©narios inclus**:
  - Candidats motivÃ©s salaire
  - Startups urgentes
  - Reconversions professionnelles

```bash
# Via l'interface principale
Choix 5: Comparaison ScÃ©narios
```

### 4. ðŸ“ˆ Monitoring Temps RÃ©el
- **Objectif**: Surveillance continue de l'API
- **MÃ©triques**: Temps rÃ©ponse, mÃ©moire, CPU, erreurs
- **FrÃ©quence**: Toutes les 5 secondes

```bash
# Via l'interface principale
Choix 6: Monitoring Temps RÃ©el
```

## ðŸ“Š InterprÃ©tation des RÃ©sultats

### Scores de Matching

| Score | InterprÃ©tation | Action |
|-------|----------------|--------|
| > 0.8 | âœ… Excellent match | Candidat prioritaire |
| 0.6-0.8 | ðŸŸ¡ Bon match | Ã€ considÃ©rer |
| 0.4-0.6 | ðŸŸ  Match moyen | Ã‰valuation cas par cas |
| < 0.4 | âŒ Match faible | Pas de suite |

### Performances SystÃ¨me

| MÃ©trique | Seuil Optimal | Seuil Alerte |
|----------|---------------|-------------|
| Temps rÃ©ponse | < 0.1s | > 2.0s |
| Taux succÃ¨s | > 95% | < 90% |
| Variance scores | 0.1-0.3 | > 0.3 |
| Utilisation RAM | < 60% | > 80% |

## ðŸ“ Structure des RÃ©sultats

```
nextvision_test_results/
â”œâ”€â”€ raw_results_YYYYMMDD_HHMMSS.json      # DonnÃ©es brutes
â”œâ”€â”€ analysis_report_YYYYMMDD_HHMMSS.json  # Rapport d'analyse
â”œâ”€â”€ results_YYYYMMDD_HHMMSS.csv           # Export CSV
â””â”€â”€ scenario_comparison_YYYYMMDD_HHMMSS.json # Comparaisons A/B

visualizations/
â”œâ”€â”€ score_distribution.png                 # Distribution des scores
â”œâ”€â”€ performance_analysis.png               # Analyse performances
â”œâ”€â”€ questionnaire_impact.png               # Impact questionnaires
â”œâ”€â”€ correlation_heatmap.png                # CorrÃ©lations
â”œâ”€â”€ temporal_analysis.png                  # Ã‰volution temporelle
â””â”€â”€ interactive_dashboard.html             # Dashboard interactif
```

## ðŸ” VÃ©rifications de CohÃ©rence

### Indicateurs de SantÃ©

1. **Variance des Scores** âœ…
   - Attendu: 0.1 - 0.3
   - ProblÃ¨me si: > 0.3 (instable) ou < 0.1 (trop uniforme)

2. **Performance Temporelle** âœ…
   - Attendu: < 0.2s par test
   - DÃ©gradation: > 1s (optimisation requise)

3. **Taux de RÃ©ussite** âœ…
   - Attendu: > 98%
   - ProblÃ¨me si: < 95% (bugs API)

4. **CohÃ©rence Questionnaires** âœ…
   - Impact visible des paramÃ¨tres
   - CorrÃ©lations logiques

## âš¡ Optimisations Performances

### Configuration RecommandÃ©e

```python
# ParamÃ¨tres optimaux trouvÃ©s
MAX_CONCURRENT_REQUESTS = 10  # Ne pas dÃ©passer
TIMEOUT_REQUEST = 30          # Secondes
BATCH_SIZE = 100             # Tests par lot
```

### Monitoring SystÃ¨me

```bash
# Surveillance ressources pendant les tests
htop                    # CPU/RAM
iostat -x 1            # I/O disque
netstat -i             # Trafic rÃ©seau
```

## ðŸš¨ RÃ©solution de ProblÃ¨mes

### Erreurs Communes

1. **API non accessible**
   ```bash
   # VÃ©rification
   curl http://localhost:8000/docs
   
   # RedÃ©marrage
   uvicorn main_v2:app --host 0.0.0.0 --port 8000 --reload
   ```

2. **Fichiers non trouvÃ©s**
   ```bash
   # VÃ©rification chemins
   ls "/Users/baptistecomas/Desktop/CV TEST"
   ls "/Users/baptistecomas/Desktop/FDP TEST"
   ```

3. **MÃ©moire insuffisante**
   ```bash
   # RÃ©duire concurrence
   MAX_CONCURRENT_REQUESTS = 5
   
   # Tests par petits lots
   max_combinations = 500
   ```

4. **Temps de rÃ©ponse Ã©levÃ©s**
   ```bash
   # VÃ©rification processus
   ps aux | grep uvicorn
   
   # Surveillance ressources
   top -p $(pgrep uvicorn)
   ```

### Debug AvancÃ©

```python
# Mode debug dans les scripts
import logging
logging.basicConfig(level=logging.DEBUG)

# Logs dÃ©taillÃ©s API
uvicorn main_v2:app --log-level debug
```

## ðŸ“ˆ MÃ©triques de Validation

### CritÃ¨res de RÃ©ussite v2.0

- âœ… **Performance**: < 0.1s par match (objectif: 1000 matchs/s)
- âœ… **PrÃ©cision**: Score moyen > 0.7
- âœ… **StabilitÃ©**: Variance < 0.2
- âœ… **FiabilitÃ©**: Taux succÃ¨s > 98%
- âœ… **CohÃ©rence**: Impact questionnaires visible

### KPIs Business

- ðŸŽ¯ **Matching Quality**: Score moyen par profil
- ðŸ“Š **System Efficiency**: Temps traitement global
- ðŸ”„ **Scalability**: Performance avec charge
- ðŸŽ® **UX Impact**: Influence questionnaires

## ðŸŽ¯ Prochaines Ã‰tapes

### Phase 1: Validation Technique âœ…
- [x] Architecture bidirectionnelle
- [x] Tests massifs 
- [x] Monitoring performances

### Phase 2: Optimisation (En cours)
- [ ] Machine Learning avancÃ©
- [ ] Cache intelligent
- [ ] API rate limiting

### Phase 3: Production
- [ ] DÃ©ploiement containerisÃ©
- [ ] CI/CD intÃ©grÃ©
- [ ] Monitoring production

## ðŸ“ž Support

### Logs et Debug
```bash
# Logs API
tail -f uvicorn.log

# Logs tests
tail -f nextvision_test.log

# Profiling performance
python -m cProfile nextvision_mass_testing.py
```

### Contacts Ã‰quipe
- **Lead Dev**: Baptiste Comas
- **Architecture**: Nextvision v2.0 team
- **Support**: NEXTEN technical team

---

ðŸŽ‰ **Nextvision v2.0 Test Suite - Validation Ã  Grande Ã‰chelle RÃ©ussie!** ðŸŽ‰