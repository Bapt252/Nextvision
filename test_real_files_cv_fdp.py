#!/usr/bin/env python3
"""
üéØ NEXTVISION V3.2.1 - TESTS AVEC VRAIS FICHIERS CV & FDP

Test complet du matching avec de vrais documents depuis le bureau.
Parcours: CV Parsing ‚Üí FDP Parsing ‚Üí Matching Intelligence

Version: 3.2.1-REAL-FILES
Date: 2025-07-11
Auteur: Assistant Claude - TEST R√âEL
"""

import asyncio
import time
import json
import os
import glob
import aiohttp
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
import logging

# Configuration des logs
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('nextvision_real_files')

class NextvisionRealFilesTester:
    """Testeur avec vrais fichiers CV et FDP"""
    
    def __init__(self, base_url: str = "http://localhost:8001"):
        self.base_url = base_url
        self.session = None
        self.desktop_path = Path.home() / "Desktop"
        self.bureau_path = Path.home() / "Bureau"  # Pour les Macs fran√ßais
        
        # R√©sultats des tests
        self.test_results = []
        self.matching_results = []
        
        # Extensions support√©es
        self.cv_extensions = ['.pdf', '.docx', '.doc', '.txt']
        self.fdp_extensions = ['.pdf', '.docx', '.doc', '.txt']
    
    async def __aenter__(self):
        """Initialisation asynchrone"""
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=60)  # Plus long pour vrais fichiers
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Nettoyage asynchrone"""
        if self.session:
            await self.session.close()
    
    def find_desktop_path(self) -> Path:
        """Trouve le chemin du bureau selon la langue du syst√®me"""
        if self.bureau_path.exists():
            logger.info(f"üìÅ Bureau trouv√©: {self.bureau_path}")
            return self.bureau_path
        elif self.desktop_path.exists():
            logger.info(f"üìÅ Desktop trouv√©: {self.desktop_path}")
            return self.desktop_path
        else:
            logger.warning("‚ö†Ô∏è Ni Bureau ni Desktop trouv√©, utilisation du r√©pertoire home")
            return Path.home()
    
    def find_files(self, keywords: List[str], extensions: List[str]) -> List[Path]:
        """Trouve les fichiers correspondant aux crit√®res"""
        desktop = self.find_desktop_path()
        found_files = []
        
        for keyword in keywords:
            for ext in extensions:
                # Recherche case-insensitive
                pattern = f"*{keyword.lower()}*{ext}"
                files = list(desktop.glob(pattern))
                
                # Recherche aussi en majuscules
                pattern_upper = f"*{keyword.upper()}*{ext}"
                files.extend(list(desktop.glob(pattern_upper)))
                
                # Recherche capitalized
                pattern_cap = f"*{keyword.capitalize()}*{ext}"
                files.extend(list(desktop.glob(pattern_cap)))
                
                found_files.extend(files)
        
        # Supprimer les doublons
        unique_files = list(set(found_files))
        return unique_files
    
    def find_cv_files(self) -> List[Path]:
        """Trouve les fichiers CV sur le bureau"""
        cv_keywords = ['cv', 'resume', 'curriculum', 'candidat', 'candidate']
        cv_files = self.find_files(cv_keywords, self.cv_extensions)
        
        logger.info(f"üìÑ {len(cv_files)} fichier(s) CV trouv√©(s):")
        for cv_file in cv_files:
            logger.info(f"   ‚Ä¢ {cv_file.name}")
        
        return cv_files
    
    def find_fdp_files(self) -> List[Path]:
        """Trouve les fichiers FDP (Fiches de Poste) sur le bureau"""
        fdp_keywords = ['fdp', 'fiche', 'poste', 'job', 'offre', 'emploi', 'position']
        fdp_files = self.find_files(fdp_keywords, self.fdp_extensions)
        
        logger.info(f"üìã {len(fdp_files)} fichier(s) FDP trouv√©(s):")
        for fdp_file in fdp_files:
            logger.info(f"   ‚Ä¢ {fdp_file.name}")
        
        return fdp_files
    
    def generate_realistic_questionnaire(self, cv_filename: str) -> Dict:
        """G√©n√®re un questionnaire r√©aliste bas√© sur le nom du fichier CV"""
        
        # Analyse du nom de fichier pour d√©duire le profil
        filename_lower = cv_filename.lower()
        
        questionnaire_base = {
            "personal_info": {
                "firstName": "Test",
                "lastName": "Candidat"
            },
            "raison_ecoute": "Recherche nouveau d√©fi",
            "transport_preferences": {
                "modes_preferes": ["voiture", "transport_commun"],
                "temps_max_acceptable": 45,
                "jours_teletravail_souhaites": 2
            },
            "salary_expectations": {
                "min": 35000,
                "max": 50000,
                "current": 40000
            },
            "location_preferences": {
                "ville_actuelle": "Paris",
                "villes_acceptees": ["Paris", "Boulogne-Billancourt", "Neuilly-sur-Seine"],
                "distance_max_km": 30
            }
        }
        
        # Ajustements selon le profil d√©duit du nom de fichier
        if any(word in filename_lower for word in ['senior', 'manager', 'chef', 'directeur', 'lead']):
            questionnaire_base["raison_ecoute"] = "Recherche nouveau d√©fi"
            questionnaire_base["salary_expectations"] = {
                "min": 60000, "max": 85000, "current": 65000
            }
        elif any(word in filename_lower for word in ['junior', 'assistant', 'stage', 'alternant']):
            questionnaire_base["raison_ecoute"] = "R√©mun√©ration trop faible"
            questionnaire_base["salary_expectations"] = {
                "min": 28000, "max": 35000, "current": 30000
            }
        elif any(word in filename_lower for word in ['comptable', 'finance', 'daf']):
            questionnaire_base["raison_ecoute"] = "Poste ne co√Øncide pas avec poste propos√©"
            questionnaire_base["salary_expectations"] = {
                "min": 45000, "max": 70000, "current": 50000
            }
        
        return questionnaire_base
    
    async def test_cv_parsing(self, cv_file: Path) -> Dict:
        """Teste le parsing d'un CV r√©el"""
        logger.info(f"üîç Test parsing CV: {cv_file.name}")
        start_time = time.time()
        
        try:
            # Lecture du fichier
            with open(cv_file, 'rb') as f:
                cv_content = f.read()
            
            # G√©n√©ration du questionnaire r√©aliste
            questionnaire = self.generate_realistic_questionnaire(cv_file.name)
            
            # Pr√©paration des donn√©es pour l'API
            data = aiohttp.FormData()
            data.add_field('file', 
                          cv_content, 
                          filename=cv_file.name,
                          content_type='application/octet-stream')
            data.add_field('candidat_questionnaire', json.dumps(questionnaire))
            
            # Appel √† l'API
            async with self.session.post(
                f"{self.base_url}/api/v2/conversion/commitment/enhanced",
                data=data
            ) as response:
                
                duration = (time.time() - start_time) * 1000
                
                if response.status == 200:
                    result = await response.json()
                    logger.info(f"‚úÖ CV pars√© avec succ√®s ({duration:.1f}ms)")
                    return {
                        "success": True,
                        "duration_ms": duration,
                        "filename": cv_file.name,
                        "parsing_result": result,
                        "questionnaire_used": questionnaire
                    }
                else:
                    error_text = await response.text()
                    logger.error(f"‚ùå √âchec parsing CV: {response.status} - {error_text}")
                    return {
                        "success": False,
                        "duration_ms": duration,
                        "filename": cv_file.name,
                        "error": f"HTTP {response.status}: {error_text}",
                        "questionnaire_used": questionnaire
                    }
        
        except Exception as e:
            duration = (time.time() - start_time) * 1000
            logger.error(f"‚ùå Erreur parsing CV {cv_file.name}: {str(e)}")
            return {
                "success": False,
                "duration_ms": duration,
                "filename": cv_file.name,
                "error": str(e)
            }
    
    async def test_fdp_parsing(self, fdp_file: Path) -> Dict:
        """Teste le parsing d'une FDP r√©elle"""
        logger.info(f"üîç Test parsing FDP: {fdp_file.name}")
        start_time = time.time()
        
        try:
            # Lecture du fichier
            with open(fdp_file, 'rb') as f:
                fdp_content = f.read()
            
            # Contexte pour la FDP
            context = {
                "company": "Entreprise Test",
                "department": "Finance",
                "urgent": False
            }
            
            # Pr√©paration des donn√©es pour l'API
            data = aiohttp.FormData()
            data.add_field('file', 
                          fdp_content, 
                          filename=fdp_file.name,
                          content_type='application/octet-stream')
            data.add_field('additional_context', json.dumps(context))
            
            # Appel √† l'API
            async with self.session.post(
                f"{self.base_url}/api/v2/jobs/parse",
                data=data
            ) as response:
                
                duration = (time.time() - start_time) * 1000
                
                if response.status == 200:
                    result = await response.json()
                    logger.info(f"‚úÖ FDP pars√©e avec succ√®s ({duration:.1f}ms)")
                    return {
                        "success": True,
                        "duration_ms": duration,
                        "filename": fdp_file.name,
                        "parsing_result": result,
                        "context_used": context
                    }
                else:
                    error_text = await response.text()
                    logger.error(f"‚ùå √âchec parsing FDP: {response.status} - {error_text}")
                    return {
                        "success": False,
                        "duration_ms": duration,
                        "filename": fdp_file.name,
                        "error": f"HTTP {response.status}: {error_text}",
                        "context_used": context
                    }
        
        except Exception as e:
            duration = (time.time() - start_time) * 1000
            logger.error(f"‚ùå Erreur parsing FDP {fdp_file.name}: {str(e)}")
            return {
                "success": False,
                "duration_ms": duration,
                "filename": fdp_file.name,
                "error": str(e)
            }
    
    def create_matching_request_from_parsed_data(self, cv_result: Dict, questionnaire: Dict) -> Dict:
        """Cr√©e une requ√™te de matching √† partir des donn√©es pars√©es"""
        
        # Si le parsing a r√©ussi, utiliser les donn√©es pars√©es
        if cv_result.get("success") and cv_result.get("parsing_result"):
            parsed_data = cv_result["parsing_result"].get("parsing_result", {})
            personal_info = parsed_data.get("personal_info", {})
            
            # Extraction des donn√©es pars√©es ou utilisation des donn√©es du questionnaire
            first_name = personal_info.get("prenom", questionnaire["personal_info"]["firstName"])
            last_name = personal_info.get("nom", questionnaire["personal_info"]["lastName"])
            skills = parsed_data.get("competences", ["Comptabilit√©", "Finance", "Excel"])
            experience_years = parsed_data.get("experience", {}).get("annees_experience", 5)
            
        else:
            # Fallback sur les donn√©es du questionnaire
            first_name = questionnaire["personal_info"]["firstName"]
            last_name = questionnaire["personal_info"]["lastName"]
            skills = ["Comptabilit√©", "Finance", "Excel"]  # Comp√©tences par d√©faut
            experience_years = 5  # Exp√©rience par d√©faut
        
        # Construction de la requ√™te de matching
        matching_request = {
            "pourquoi_ecoute": questionnaire["raison_ecoute"],
            "candidate_profile": {
                "personal_info": {
                    "firstName": first_name,
                    "lastName": last_name,
                    "email": f"{first_name.lower()}.{last_name.lower()}@example.com",
                    "phone": "0123456789"
                },
                "skills": skills,
                "experience_years": experience_years,
                "education": "Formation professionnelle",
                "current_role": "Poste actuel"
            },
            "preferences": {
                "salary_expectations": questionnaire["salary_expectations"],
                "location_preferences": {
                    "city": questionnaire["location_preferences"]["ville_actuelle"],
                    "acceptedCities": questionnaire["location_preferences"]["villes_acceptees"],
                    "maxDistance": questionnaire["location_preferences"]["distance_max_km"]
                },
                "remote_preferences": f"{questionnaire['transport_preferences']['jours_teletravail_souhaites']} jours/semaine",
                "sectors": ["Finance", "Comptabilit√©"],
                "company_size": "PME/ETI"
            },
            "availability": "Imm√©diate"
        }
        
        return matching_request
    
    async def test_complete_matching(self, cv_result: Dict, fdp_result: Dict) -> Dict:
        """Teste le matching complet entre un CV et une FDP"""
        logger.info(f"üéØ Test matching: {cv_result['filename']} ‚Üî {fdp_result.get('filename', 'FDP simul√©e')}")
        start_time = time.time()
        
        try:
            # Cr√©ation de la requ√™te de matching
            questionnaire = cv_result.get("questionnaire_used", {})
            matching_request = self.create_matching_request_from_parsed_data(cv_result, questionnaire)
            
            # ID unique pour ce test
            candidate_id = f"real_test_{int(time.time())}"
            
            # Appel √† l'API de matching
            async with self.session.post(
                f"{self.base_url}/api/v1/matching/candidate/{candidate_id}",
                json=matching_request
            ) as response:
                
                duration = (time.time() - start_time) * 1000
                
                if response.status == 200:
                    result = await response.json()
                    
                    # Extraction des m√©triques importantes
                    matching_results = result.get("matching_results", {})
                    total_score = matching_results.get("total_score", 0)
                    component_scores = matching_results.get("component_scores", {})
                    adaptive_weighting = result.get("adaptive_weighting", {})
                    
                    logger.info(f"‚úÖ Matching r√©ussi - Score: {total_score:.3f} ({duration:.1f}ms)")
                    
                    return {
                        "success": True,
                        "duration_ms": duration,
                        "cv_filename": cv_result["filename"],
                        "fdp_filename": fdp_result.get("filename", "FDP simul√©e"),
                        "candidate_id": candidate_id,
                        "total_score": total_score,
                        "component_scores": component_scores,
                        "adaptive_weighting": adaptive_weighting,
                        "full_result": result,
                        "matching_request": matching_request
                    }
                else:
                    error_text = await response.text()
                    logger.error(f"‚ùå √âchec matching: {response.status} - {error_text}")
                    return {
                        "success": False,
                        "duration_ms": duration,
                        "cv_filename": cv_result["filename"],
                        "fdp_filename": fdp_result.get("filename", "FDP simul√©e"),
                        "error": f"HTTP {response.status}: {error_text}"
                    }
        
        except Exception as e:
            duration = (time.time() - start_time) * 1000
            logger.error(f"‚ùå Erreur matching: {str(e)}")
            return {
                "success": False,
                "duration_ms": duration,
                "cv_filename": cv_result["filename"],
                "fdp_filename": fdp_result.get("filename", "FDP simul√©e"),
                "error": str(e)
            }
    
    async def run_complete_test_suite(self) -> Dict:
        """Lance la suite compl√®te de tests avec vrais fichiers"""
        logger.info("üöÄ D√©marrage des tests avec vrais fichiers CV et FDP")
        start_time = time.time()
        
        # 1. Recherche des fichiers
        cv_files = self.find_cv_files()
        fdp_files = self.find_fdp_files()
        
        if not cv_files:
            logger.warning("‚ö†Ô∏è Aucun fichier CV trouv√© sur le bureau")
            return {"error": "Aucun fichier CV trouv√©"}
        
        # 2. Test du parsing des CV
        logger.info(f"\nüìÑ === PHASE 1: PARSING {len(cv_files)} CV(S) ===")
        cv_results = []
        for cv_file in cv_files[:3]:  # Limite √† 3 CV pour √©viter la surcharge
            cv_result = await self.test_cv_parsing(cv_file)
            cv_results.append(cv_result)
            self.test_results.append(cv_result)
        
        # 3. Test du parsing des FDP (si disponibles)
        logger.info(f"\nüìã === PHASE 2: PARSING {len(fdp_files)} FDP(S) ===")
        fdp_results = []
        if fdp_files:
            for fdp_file in fdp_files[:2]:  # Limite √† 2 FDP
                fdp_result = await self.test_fdp_parsing(fdp_file)
                fdp_results.append(fdp_result)
                self.test_results.append(fdp_result)
        else:
            logger.info("‚ÑπÔ∏è Aucune FDP trouv√©e, utilisation d'une FDP simul√©e")
            fdp_results.append({
                "success": True,
                "filename": "FDP_simul√©e.txt",
                "parsing_result": {
                    "job_id": "simulated_job_001",
                    "titre_poste": "Comptable G√©n√©ral",
                    "entreprise": "Entreprise Test",
                    "localisation": "Paris 15√®me",
                    "type_contrat": "CDI",
                    "competences_requises": ["Comptabilit√©", "Sage", "Excel"],
                    "salaire": "35000-45000‚Ç¨"
                }
            })
        
        # 4. Test des matchings complets
        logger.info(f"\nüéØ === PHASE 3: MATCHING COMPLET ===")
        for cv_result in cv_results:
            if cv_result["success"]:
                for fdp_result in fdp_results:
                    matching_result = await self.test_complete_matching(cv_result, fdp_result)
                    self.matching_results.append(matching_result)
        
        # 5. G√©n√©ration du rapport final
        total_duration = time.time() - start_time
        return self.generate_final_report(total_duration)
    
    def generate_final_report(self, total_duration: float) -> Dict:
        """G√©n√®re le rapport final des tests"""
        
        # Statistiques globales
        successful_cv_parsing = len([r for r in self.test_results if "CV" in r.get("filename", "") and r.get("success")])
        failed_cv_parsing = len([r for r in self.test_results if "CV" in r.get("filename", "") and not r.get("success")])
        
        successful_fdp_parsing = len([r for r in self.test_results if "FDP" in r.get("filename", "") and r.get("success")])
        failed_fdp_parsing = len([r for r in self.test_results if "FDP" in r.get("filename", "") and not r.get("success")])
        
        successful_matching = len([r for r in self.matching_results if r.get("success")])
        failed_matching = len([r for r in self.matching_results if not r.get("success")])
        
        # Analyse des scores de matching
        scores = [r.get("total_score", 0) for r in self.matching_results if r.get("success")]
        avg_score = sum(scores) / len(scores) if scores else 0
        max_score = max(scores) if scores else 0
        min_score = min(scores) if scores else 0
        
        # Performance
        durations = [r.get("duration_ms", 0) for r in self.matching_results if r.get("success")]
        avg_duration = sum(durations) / len(durations) if durations else 0
        
        report = {
            "summary": {
                "test_type": "Real Files CV & FDP Testing",
                "total_duration_seconds": total_duration,
                "timestamp": datetime.now().isoformat(),
                "cv_parsing": {
                    "successful": successful_cv_parsing,
                    "failed": failed_cv_parsing,
                    "success_rate": successful_cv_parsing / (successful_cv_parsing + failed_cv_parsing) if (successful_cv_parsing + failed_cv_parsing) > 0 else 0
                },
                "fdp_parsing": {
                    "successful": successful_fdp_parsing,
                    "failed": failed_fdp_parsing,
                    "success_rate": successful_fdp_parsing / (successful_fdp_parsing + failed_fdp_parsing) if (successful_fdp_parsing + failed_fdp_parsing) > 0 else 0
                },
                "matching": {
                    "successful": successful_matching,
                    "failed": failed_matching,
                    "success_rate": successful_matching / (successful_matching + failed_matching) if (successful_matching + failed_matching) > 0 else 0,
                    "avg_score": avg_score,
                    "max_score": max_score,
                    "min_score": min_score,
                    "avg_duration_ms": avg_duration
                }
            },
            "detailed_results": {
                "cv_parsing_results": [r for r in self.test_results if "CV" in r.get("filename", "")],
                "fdp_parsing_results": [r for r in self.test_results if "FDP" in r.get("filename", "")],
                "matching_results": self.matching_results
            },
            "best_matches": sorted([r for r in self.matching_results if r.get("success")], 
                                 key=lambda x: x.get("total_score", 0), reverse=True)[:3],
            "recommendations": self.generate_recommendations()
        }
        
        return report
    
    def generate_recommendations(self) -> List[str]:
        """G√©n√®re des recommandations bas√©es sur les r√©sultats"""
        recommendations = []
        
        successful_matching = len([r for r in self.matching_results if r.get("success")])
        total_matching = len(self.matching_results)
        
        if successful_matching == total_matching and total_matching > 0:
            recommendations.append("üéâ Tous les matchings ont r√©ussi ! Le syst√®me fonctionne parfaitement avec de vrais fichiers.")
        elif successful_matching > 0:
            recommendations.append(f"‚úÖ {successful_matching}/{total_matching} matchings r√©ussis.")
        
        scores = [r.get("total_score", 0) for r in self.matching_results if r.get("success")]
        if scores:
            avg_score = sum(scores) / len(scores)
            if avg_score > 0.8:
                recommendations.append(f"üéØ Excellent score moyen: {avg_score:.3f}")
            elif avg_score > 0.6:
                recommendations.append(f"üëç Bon score moyen: {avg_score:.3f}")
            else:
                recommendations.append(f"‚ö†Ô∏è Score moyen √† am√©liorer: {avg_score:.3f}")
        
        recommendations.append("üìã Prochaines √©tapes:")
        recommendations.append("   ‚Ä¢ Tester avec plus de fichiers vari√©s")
        recommendations.append("   ‚Ä¢ Impl√©menter le syst√®me hi√©rarchique")
        recommendations.append("   ‚Ä¢ Optimiser les scores de matching")
        
        return recommendations


async def main():
    """Fonction principale pour les tests avec vrais fichiers"""
    print("üéØ NEXTVISION V3.2.1 - TESTS AVEC VRAIS FICHIERS CV & FDP")
    print("=" * 65)
    print("üìÅ Recherche de fichiers sur le bureau...")
    print("=" * 65)
    
    async with NextvisionRealFilesTester() as tester:
        report = await tester.run_complete_test_suite()
        
        if "error" in report:
            print(f"‚ùå Erreur: {report['error']}")
            print("\nüí° Suggestions:")
            print("   ‚Ä¢ Placez des fichiers CV sur votre bureau (noms contenant 'cv', 'resume', 'candidat')")
            print("   ‚Ä¢ Placez des fichiers FDP sur votre bureau (noms contenant 'fdp', 'fiche', 'poste', 'offre')")
            print("   ‚Ä¢ Extensions support√©es: .pdf, .docx, .doc, .txt")
            return 1
        
        # Affichage du rapport final
        print("\n" + "=" * 65)
        print("üìä RAPPORT FINAL - TESTS AVEC VRAIS FICHIERS")
        print("=" * 65)
        
        summary = report['summary']
        
        print(f"‚è±Ô∏è Dur√©e totale: {summary['total_duration_seconds']:.1f}s")
        print(f"üìÖ Timestamp: {summary['timestamp']}")
        
        print(f"\nüìÑ PARSING CV:")
        cv_stats = summary['cv_parsing']
        print(f"   R√©ussis: {cv_stats['successful']}")
        print(f"   √âchecs: {cv_stats['failed']}")
        print(f"   Taux de r√©ussite: {cv_stats['success_rate']:.1%}")
        
        print(f"\nüìã PARSING FDP:")
        fdp_stats = summary['fdp_parsing']
        print(f"   R√©ussis: {fdp_stats['successful']}")
        print(f"   √âchecs: {fdp_stats['failed']}")
        print(f"   Taux de r√©ussite: {fdp_stats['success_rate']:.1%}")
        
        print(f"\nüéØ MATCHING:")
        matching_stats = summary['matching']
        print(f"   R√©ussis: {matching_stats['successful']}")
        print(f"   √âchecs: {matching_stats['failed']}")
        print(f"   Taux de r√©ussite: {matching_stats['success_rate']:.1%}")
        print(f"   Score moyen: {matching_stats['avg_score']:.3f}")
        print(f"   Score max: {matching_stats['max_score']:.3f}")
        print(f"   Score min: {matching_stats['min_score']:.3f}")
        print(f"   Dur√©e moyenne: {matching_stats['avg_duration_ms']:.1f}ms")
        
        print(f"\nüèÜ MEILLEURS MATCHINGS:")
        for i, match in enumerate(report['best_matches'], 1):
            print(f"   {i}. {match['cv_filename']} ‚Üí Score: {match['total_score']:.3f}")
        
        print("\nüìã RECOMMANDATIONS:")
        for rec in report['recommendations']:
            print(f"  {rec}")
        
        # Sauvegarde du rapport
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"nextvision_real_files_report_{timestamp}.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nüíæ Rapport d√©taill√© sauvegard√©: {report_file}")
        
        # Code de sortie
        exit_code = 0 if matching_stats['success_rate'] > 0.5 else 1
        print(f"\nüéØ Tests termin√©s avec le code: {exit_code}")
        
        return exit_code


if __name__ == "__main__":
    try:
        exit_code = asyncio.run(main())
        exit(exit_code)
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Tests interrompus par l'utilisateur")
        exit(2)
    except Exception as e:
        print(f"\n‚ùå Erreur critique: {str(e)}")
        import traceback
        traceback.print_exc()
        exit(3)