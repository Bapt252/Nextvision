"""
üéØ Nextvision V3.0 - Enhanced Commitment Bridge V3.0 Int√©gr√©
Version int√©gr√©e avec Commitment- Enhanced Parser v4.0 r√©el

üöÄ PRINCIPALES AM√âLIORATIONS:
- Int√©gration CommitmentParsingBridge pour parsing r√©el
- Conversion automatique des formats
- Pr√©paration pour Transport Intelligence V3.0
- Pipeline end-to-end fonctionnel
- Fallback intelligent s√©curis√©

Author: NEXTEN Team
Version: 3.0.0-integrated - Production Ready with Real Parsing
"""

import json
import logging
import asyncio
import time
from typing import Dict, List, Optional, Union, Any, Tuple
from datetime import datetime
from dataclasses import dataclass, asdict, field
import tempfile
import os
from pathlib import Path

# Import Enhanced Bridge V3.0 original
from nextvision.services.enhanced_commitment_bridge_v3_integrated import EnhancedCommitmentBridgeV3Integrated, IntegratedBridgeFactory
# Import Enhanced Bridge V3.0 - will be imported lazily
    EnhancedCommitmentBridgeV3 as OriginalBridgeV3,
    BridgeV3Stats, BridgeV3Metrics, AutoFixEngineV3,
    EnhancedBridgeV3Factory
)

# Import CommitmentParsingBridge
from nextvision.services.parsing.commitment_bridge_optimized import (
    CommitmentParsingBridge, CommitmentParsingResult, ParsingStatus, 
    ParsingStrategy, CommitmentBridgeFactory
)

# Import mod√®les V3.0
from nextvision.models.extended_matching_models_v3 import (
    ExtendedMatchingProfile, AdaptiveWeightingConfig
)

# Import mod√®les bidirectionnels
from nextvision.models.bidirectional_models import (
    BiDirectionalCandidateProfile, BiDirectionalCompanyProfile
)

# Import utils
from nextvision.utils.file_utils import FileUtils
from nextvision.logging.logger import get_logger

logger = get_logger(__name__)

# === STRUCTURES INT√âGR√âES ===

@dataclass
class IntegratedBridgeStats(BridgeV3Stats):
    """Statistiques Bridge V3.0 int√©gr√© avec parsing r√©el"""
    
    # Statistiques Commitment-
    commitment_parsing_attempts: int = 0
    commitment_parsing_success: int = 0
    commitment_parsing_fallback: int = 0
    commitment_parsing_errors: int = 0
    
    # Performance parsing
    avg_commitment_parsing_time_ms: float = 0.0
    avg_commitment_confidence: float = 0.0
    
    # Strat√©gies utilis√©es
    real_parsing_usage: int = 0
    fallback_parsing_usage: int = 0
    simulation_parsing_usage: int = 0
    
    # Int√©gration
    successful_integrations: int = 0
    integration_errors: int = 0

@dataclass
class IntegratedBridgeMetrics(BridgeV3Metrics):
    """M√©triques Bridge V3.0 int√©gr√©"""
    
    # M√©triques Commitment-
    commitment_parsing_time_ms: float = 0.0
    commitment_confidence: float = 0.0
    commitment_fields_extracted: int = 0
    commitment_strategy_used: str = "unknown"
    
    # Pipeline int√©gr√©
    format_conversion_time_ms: float = 0.0
    data_enrichment_time_ms: float = 0.0
    transport_preparation_time_ms: float = 0.0
    
    # Qualit√©
    data_quality_score: float = 0.0
    integration_success: bool = False

# === ENHANCED COMMITMENT BRIDGE V3.0 INT√âGR√â ===

class EnhancedCommitmentBridgeV3Integrated:
    """
    üåâ Enhanced Bridge V3.0 avec int√©gration Commitment- r√©elle
    
    H√©rite de Enhanced Bridge V3.0 et ajoute :
    - Parsing r√©el via CommitmentParsingBridge
    - Conversion automatique des formats
    - Pipeline end-to-end avec Transport Intelligence V3.0
    - Fallback intelligent s√©curis√©
    """
    
    def __init__(self, 
                 enable_real_parsing: bool = True,
                 enable_commitment_fallback: bool = True,
                 commitment_timeout: int = 30):
        """
        Initialise le bridge int√©gr√©
        
        Args:
            enable_real_parsing: Activer parsing r√©el Commitment-
            enable_commitment_fallback: Activer fallback Commitment-
            commitment_timeout: Timeout parsing Commitment-
        """
        
        # Initialisation Enhanced Bridge V3.0
                # Import Enhanced Bridge V3.0 dynamically to avoid circular imports
        from nextvision.services.enhanced_commitment_bridge_v3 import EnhancedCommitmentBridgeV3
        self._enhanced_bridge_v3 = EnhancedCommitmentBridgeV3()
        
        # Configuration int√©gration
        self.integration_config = {
            'enable_real_parsing': enable_real_parsing,
            'enable_commitment_fallback': enable_commitment_fallback,
            'commitment_timeout': commitment_timeout,
            'enable_format_conversion': True,
            'enable_data_enrichment': True,
            'enable_transport_preparation': True,
            'max_file_size_mb': 10,
            'supported_formats': ['.pdf', '.txt', '.doc', '.docx', '.md']
        }
        
        # Initialisation CommitmentParsingBridge
        if enable_real_parsing:
            self.commitment_bridge = CommitmentBridgeFactory.create_production_bridge()
        else:
            self.commitment_bridge = CommitmentBridgeFactory.create_development_bridge()
        
        # Utils
        self.file_utils = FileUtils()
        
        # Stats int√©gr√©es
        self.integrated_stats = IntegratedBridgeStats(last_reset=datetime.now())
        
        # Cache r√©sultats
        self.parsing_cache = {}
        self.cache_ttl = 3600  # 1 heure
        
        logger.info("üåâ Enhanced Commitment Bridge V3.0 Int√©gr√© initialis√©")
        logger.info(f"üéØ Parsing r√©el: {'‚úÖ Activ√©' if enable_real_parsing else '‚ùå D√©sactiv√©'}")
        logger.info(f"üîÑ Fallback: {'‚úÖ Activ√©' if enable_commitment_fallback else '‚ùå D√©sactiv√©'}")
        logger.info(f"‚è±Ô∏è Timeout: {commitment_timeout}s")
    
    async def convert_candidat_enhanced_integrated(self, 
                                                 parser_output: Optional[Dict] = None,
                                                 cv_file_path: Optional[str] = None,
                                                 questionnaire_data: Optional[Dict] = None,
                                                 enable_real_parsing: bool = True) -> Tuple[Union[BiDirectionalCandidateProfile, ExtendedMatchingProfile], IntegratedBridgeMetrics]:
        """
        üîÑ Conversion candidat avec int√©gration Commitment- r√©elle
        
        Args:
            parser_output: Sortie parser existante (optionnel)
            cv_file_path: Chemin vers fichier CV pour parsing r√©el
            questionnaire_data: Donn√©es questionnaire
            enable_real_parsing: Activer parsing r√©el
            
        Returns:
            Tuple[Profil candidat, M√©triques int√©gr√©es]
        """
        
        start_time = time.time()
        metrics = IntegratedBridgeMetrics(
            conversion_time_ms=0, validation_time_ms=0, auto_fix_time_ms=0,
            total_time_ms=0, fields_processed=0, auto_fixes_count=0, cache_used=False,
            commitment_parsing_time_ms=0, commitment_confidence=0.0,
            commitment_fields_extracted=0, commitment_strategy_used="unknown",
            format_conversion_time_ms=0, data_enrichment_time_ms=0,
            transport_preparation_time_ms=0, data_quality_score=0.0,
            integration_success=False
        )
        
        try:
            self.integrated_stats.commitment_parsing_attempts += 1
            
            # === √âTAPE 1: Parsing r√©el avec Commitment- ===
            parsing_result = None
            if enable_real_parsing and self.integration_config['enable_real_parsing'] and cv_file_path:
                
                parsing_start = time.time()
                
                # Validation fichier
                if not self._validate_cv_file(cv_file_path):
                    logger.warning(f"‚ö†Ô∏è Fichier CV invalide: {cv_file_path}")
                else:
                    try:
                        # Parsing avec Commitment-
                        parsing_result = await self.commitment_bridge.parse_cv_file(cv_file_path)
                        
                        metrics.commitment_parsing_time_ms = (time.time() - parsing_start) * 1000
                        metrics.commitment_confidence = parsing_result.extraction_confidence
                        metrics.commitment_fields_extracted = parsing_result.fields_extracted
                        metrics.commitment_strategy_used = parsing_result.strategy_used.value
                        
                        if parsing_result.success:
                            self.integrated_stats.commitment_parsing_success += 1
                            logger.info(f"‚úÖ Parsing Commitment- r√©ussi: {parsing_result.fields_extracted} champs, confiance {parsing_result.extraction_confidence:.2f}")
                        else:
                            self.integrated_stats.commitment_parsing_errors += 1
                            logger.warning(f"‚ö†Ô∏è Parsing Commitment- √©chou√©: {parsing_result.errors}")
                            
                    except Exception as e:
                        logger.error(f"‚ùå Erreur parsing Commitment-: {e}")
                        self.integrated_stats.commitment_parsing_errors += 1
                        parsing_result = None
            
            # === √âTAPE 2: Conversion format et enrichissement ===
            conversion_start = time.time()
            
            # Utilisation donn√©es parsing ou parser_output
            if parsing_result and parsing_result.success:
                # Conversion donn√©es Commitment- vers format Nextvision
                converted_data = self._convert_commitment_to_nextvision(parsing_result.extracted_data, "candidat")
                metrics.commitment_confidence = parsing_result.extraction_confidence
                
                # Enrichissement avec donn√©es questionnaire
                if questionnaire_data:
                    converted_data = self._enrich_with_questionnaire(converted_data, questionnaire_data, "candidat")
                    
                self.integrated_stats.real_parsing_usage += 1
                
            elif parser_output:
                # Utilisation parser_output existant
                converted_data = parser_output
                self.integrated_stats.fallback_parsing_usage += 1
                
            else:
                # Simulation pour d√©veloppement
                converted_data = self._generate_simulation_data("candidat")
                self.integrated_stats.simulation_parsing_usage += 1
                metrics.commitment_confidence = 0.40
            
            metrics.format_conversion_time_ms = (time.time() - conversion_start) * 1000
            
            # === √âTAPE 3: Conversion Enhanced Bridge V3.0 ===
            bridge_start = time.time()
            
            # Appel Enhanced Bridge V3.0 original
            candidat_profile, bridge_metrics = await self._enhanced_bridge_v3.convert_candidat_enhanced_v3(
                converted_data, questionnaire_data, enable_v3_extensions=True
            )
            
            # Fusion m√©triques
            metrics.conversion_time_ms = bridge_metrics.conversion_time_ms
            metrics.auto_fix_time_ms = bridge_metrics.auto_fix_time_ms
            metrics.auto_fixes_count = bridge_metrics.auto_fixes_count
            metrics.cache_used = bridge_metrics.cache_used
            
            # === √âTAPE 4: Pr√©paration Transport Intelligence V3.0 ===
            transport_start = time.time()
            
            # Enrichissement pour Transport Intelligence (conserv√© et optimis√©)
            if hasattr(candidat_profile, 'base_profile') and candidat_profile.base_profile:
                candidat_profile = self._prepare_for_transport_intelligence(candidat_profile)
            
            metrics.transport_preparation_time_ms = (time.time() - transport_start) * 1000
            
            # === √âTAPE 5: Calcul qualit√© donn√©es ===
            metrics.data_quality_score = self._calculate_data_quality_score(candidat_profile, parsing_result)
            
            # === FINALIZATION ===
            metrics.total_time_ms = (time.time() - start_time) * 1000
            metrics.integration_success = True
            
            # Mise √† jour statistiques
            self.integrated_stats.successful_integrations += 1
            self._update_integrated_stats(parsing_result, metrics)
            
            logger.info(f"‚úÖ Candidat int√©gr√© V3.0: {metrics.total_time_ms:.2f}ms, qualit√© {metrics.data_quality_score:.2f}")
            
            return candidat_profile, metrics
            
        except Exception as e:
            logger.error(f"‚ùå Erreur int√©gration candidat: {e}")
            
            # Fallback s√©curis√© vers Enhanced Bridge V3.0
            try:
                fallback_data = parser_output or self._generate_simulation_data("candidat")
                candidat_profile, bridge_metrics = await self._enhanced_bridge_v3.convert_candidat_enhanced_v3(
                    fallback_data, questionnaire_data, enable_v3_extensions=True
                )
                
                metrics.total_time_ms = (time.time() - start_time) * 1000
                metrics.integration_success = False
                metrics.commitment_confidence = 0.0
                
                self.integrated_stats.integration_errors += 1
                
                logger.info("üîÑ Fallback vers Enhanced Bridge V3.0 r√©ussi")
                
                return candidat_profile, metrics
                
            except Exception as fallback_error:
                logger.error(f"‚ùå Erreur fallback candidat: {fallback_error}")
                metrics.total_time_ms = (time.time() - start_time) * 1000
                metrics.integration_success = False
                self.integrated_stats.integration_errors += 1
                raise
    
    async def convert_entreprise_enhanced_integrated(self,
                                                   chatgpt_output: Optional[Dict] = None,
                                                   job_description_text: Optional[str] = None,
                                                   questionnaire_data: Optional[Dict] = None,
                                                   enable_real_parsing: bool = True) -> Tuple[Union[BiDirectionalCompanyProfile, ExtendedMatchingProfile], IntegratedBridgeMetrics]:
        """
        üîÑ Conversion entreprise avec int√©gration Commitment- r√©elle
        
        Args:
            chatgpt_output: Sortie ChatGPT existante
            job_description_text: Texte description poste pour parsing r√©el
            questionnaire_data: Donn√©es questionnaire
            enable_real_parsing: Activer parsing r√©el
            
        Returns:
            Tuple[Profil entreprise, M√©triques int√©gr√©es]
        """
        
        start_time = time.time()
        metrics = IntegratedBridgeMetrics(
            conversion_time_ms=0, validation_time_ms=0, auto_fix_time_ms=0,
            total_time_ms=0, fields_processed=0, auto_fixes_count=0, cache_used=False,
            commitment_parsing_time_ms=0, commitment_confidence=0.0,
            commitment_fields_extracted=0, commitment_strategy_used="unknown",
            format_conversion_time_ms=0, data_enrichment_time_ms=0,
            transport_preparation_time_ms=0, data_quality_score=0.0,
            integration_success=False
        )
        
        try:
            self.integrated_stats.commitment_parsing_attempts += 1
            
            # === √âTAPE 1: Parsing r√©el description poste ===
            parsing_result = None
            if enable_real_parsing and self.integration_config['enable_real_parsing'] and job_description_text:
                
                parsing_start = time.time()
                
                try:
                    # Parsing avec Commitment-
                    parsing_result = await self.commitment_bridge.parse_job_description(job_description_text)
                    
                    metrics.commitment_parsing_time_ms = (time.time() - parsing_start) * 1000
                    metrics.commitment_confidence = parsing_result.extraction_confidence
                    metrics.commitment_fields_extracted = parsing_result.fields_extracted
                    metrics.commitment_strategy_used = parsing_result.strategy_used.value
                    
                    if parsing_result.success:
                        self.integrated_stats.commitment_parsing_success += 1
                        logger.info(f"‚úÖ Parsing job description r√©ussi: {parsing_result.fields_extracted} champs")
                    else:
                        self.integrated_stats.commitment_parsing_errors += 1
                        logger.warning(f"‚ö†Ô∏è Parsing job description √©chou√©: {parsing_result.errors}")
                        
                except Exception as e:
                    logger.error(f"‚ùå Erreur parsing job description: {e}")
                    self.integrated_stats.commitment_parsing_errors += 1
                    parsing_result = None
            
            # === √âTAPE 2: Conversion format ===
            conversion_start = time.time()
            
            if parsing_result and parsing_result.success:
                # Conversion donn√©es Commitment- vers format Nextvision
                converted_data = self._convert_commitment_to_nextvision(parsing_result.extracted_data, "entreprise")
                
                # Enrichissement avec donn√©es questionnaire
                if questionnaire_data:
                    converted_data = self._enrich_with_questionnaire(converted_data, questionnaire_data, "entreprise")
                
                self.integrated_stats.real_parsing_usage += 1
                
            elif chatgpt_output:
                # Utilisation chatgpt_output existant
                converted_data = chatgpt_output
                self.integrated_stats.fallback_parsing_usage += 1
                
            else:
                # Simulation pour d√©veloppement
                converted_data = self._generate_simulation_data("entreprise")
                self.integrated_stats.simulation_parsing_usage += 1
                metrics.commitment_confidence = 0.40
            
            metrics.format_conversion_time_ms = (time.time() - conversion_start) * 1000
            
            # === √âTAPE 3: Conversion Enhanced Bridge V3.0 ===
            bridge_start = time.time()
            
            # Appel Enhanced Bridge V3.0 original
            entreprise_profile, bridge_metrics = await self._enhanced_bridge_v3.convert_entreprise_enhanced_v3(
                converted_data, questionnaire_data, enable_v3_extensions=True
            )
            
            # Fusion m√©triques
            metrics.conversion_time_ms = bridge_metrics.conversion_time_ms
            metrics.auto_fix_time_ms = bridge_metrics.auto_fix_time_ms
            metrics.auto_fixes_count = bridge_metrics.auto_fixes_count
            metrics.cache_used = bridge_metrics.cache_used
            
            # === √âTAPE 4: Pr√©paration Transport Intelligence V3.0 ===
            transport_start = time.time()
            
            if hasattr(entreprise_profile, 'base_profile') and entreprise_profile.base_profile:
                entreprise_profile = self._prepare_for_transport_intelligence(entreprise_profile)
            
            metrics.transport_preparation_time_ms = (time.time() - transport_start) * 1000
            
            # === √âTAPE 5: Calcul qualit√© donn√©es ===
            metrics.data_quality_score = self._calculate_data_quality_score(entreprise_profile, parsing_result)
            
            # === FINALIZATION ===
            metrics.total_time_ms = (time.time() - start_time) * 1000
            metrics.integration_success = True
            
            # Mise √† jour statistiques
            self.integrated_stats.successful_integrations += 1
            self._update_integrated_stats(parsing_result, metrics)
            
            logger.info(f"‚úÖ Entreprise int√©gr√©e V3.0: {metrics.total_time_ms:.2f}ms, qualit√© {metrics.data_quality_score:.2f}")
            
            return entreprise_profile, metrics
            
        except Exception as e:
            logger.error(f"‚ùå Erreur int√©gration entreprise: {e}")
            
            # Fallback s√©curis√©
            try:
                fallback_data = chatgpt_output or self._generate_simulation_data("entreprise")
                entreprise_profile, bridge_metrics = await self._enhanced_bridge_v3.convert_entreprise_enhanced_v3(
                    fallback_data, questionnaire_data, enable_v3_extensions=True
                )
                
                metrics.total_time_ms = (time.time() - start_time) * 1000
                metrics.integration_success = False
                metrics.commitment_confidence = 0.0
                
                self.integrated_stats.integration_errors += 1
                
                logger.info("üîÑ Fallback vers Enhanced Bridge V3.0 r√©ussi")
                
                return entreprise_profile, metrics
                
            except Exception as fallback_error:
                logger.error(f"‚ùå Erreur fallback entreprise: {fallback_error}")
                metrics.total_time_ms = (time.time() - start_time) * 1000
                metrics.integration_success = False
                self.integrated_stats.integration_errors += 1
                raise
    
    # === M√âTHODES UTILITAIRES ===
    
    def _validate_cv_file(self, file_path: str) -> bool:
        """Valide un fichier CV"""
        
        try:
            if not os.path.exists(file_path):
                return False
            
            # V√©rification taille
            file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB
            if file_size > self.integration_config['max_file_size_mb']:
                logger.warning(f"‚ö†Ô∏è Fichier trop volumineux: {file_size:.2f}MB")
                return False
            
            # V√©rification format
            file_extension = Path(file_path).suffix.lower()
            if file_extension not in self.integration_config['supported_formats']:
                logger.warning(f"‚ö†Ô∏è Format non support√©: {file_extension}")
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur validation fichier: {e}")
            return False
    
    def _convert_commitment_to_nextvision(self, commitment_data: Dict, data_type: str) -> Dict:
        """Convertit donn√©es Commitment- vers format Nextvision"""
        
        try:
            if data_type == "candidat":
                return self._convert_commitment_candidat(commitment_data)
            else:
                return self._convert_commitment_entreprise(commitment_data)
                
        except Exception as e:
            logger.error(f"‚ùå Erreur conversion Commitment-: {e}")
            return commitment_data  # Fallback
    
    def _convert_commitment_candidat(self, commitment_data: Dict) -> Dict:
        """Convertit donn√©es candidat Commitment- vers Nextvision"""
        
        nextvision_data = {
            "personal_info": {},
            "skills": [],
            "experience": {},
            "education": [],
            "parsing_confidence": commitment_data.get('parsing_confidence', 0.8)
        }
        
        # Mapping champs personnels
        if 'firstName' in commitment_data:
            nextvision_data['personal_info']['firstName'] = commitment_data['firstName']
        if 'lastName' in commitment_data:
            nextvision_data['personal_info']['lastName'] = commitment_data['lastName']
        if 'email' in commitment_data:
            nextvision_data['personal_info']['email'] = commitment_data['email']
        if 'phone' in commitment_data:
            nextvision_data['personal_info']['phone'] = commitment_data['phone']
        
        # Mapping comp√©tences
        if 'skills' in commitment_data:
            nextvision_data['skills'] = commitment_data['skills']
        
        # Mapping exp√©rience
        if 'experience_years' in commitment_data:
            nextvision_data['experience']['total_years'] = commitment_data['experience_years']
        
        # Mapping formations
        if 'has_education' in commitment_data:
            nextvision_data['education'] = [{"degree": "Formation d√©tect√©e", "validated": False}]
        
        # Enrichissement avec donn√©es d√©tect√©es
        if 'location' in commitment_data:
            nextvision_data['personal_info']['location'] = commitment_data['location']
        
        return nextvision_data
    
    def _convert_commitment_entreprise(self, commitment_data: Dict) -> Dict:
        """Convertit donn√©es entreprise Commitment- vers Nextvision"""
        
        nextvision_data = {
            "titre": commitment_data.get('title', 'Poste non sp√©cifi√©'),
            "localisation": commitment_data.get('location', 'Non sp√©cifi√©'),
            "competences_requises": commitment_data.get('required_skills', []),
            "parsing_confidence": commitment_data.get('parsing_confidence', 0.8)
        }
        
        # Mapping sp√©cifique
        if 'salary' in commitment_data:
            nextvision_data['salaire'] = commitment_data['salary']
        
        if 'contract_type' in commitment_data:
            nextvision_data['type_contrat'] = commitment_data['contract_type']
        
        if 'experience_level' in commitment_data:
            nextvision_data['experience_requise'] = commitment_data['experience_level']
        
        if 'sector' in commitment_data:
            nextvision_data['secteur'] = commitment_data['sector']
        
        return nextvision_data
    
    def _enrich_with_questionnaire(self, data: Dict, questionnaire_data: Dict, data_type: str) -> Dict:
        """Enrichit les donn√©es avec le questionnaire"""
        
        try:
            if data_type == "candidat":
                # Enrichissement candidat
                if 'mobility_preferences' in questionnaire_data:
                    data['mobility_preferences'] = questionnaire_data['mobility_preferences']
                
                if 'motivations_sectors' in questionnaire_data:
                    data['motivations_sectors'] = questionnaire_data['motivations_sectors']
                
                if 'availability_status' in questionnaire_data:
                    data['availability_status'] = questionnaire_data['availability_status']
                    
            else:
                # Enrichissement entreprise
                if 'company_structure' in questionnaire_data:
                    data['company_structure'] = questionnaire_data['company_structure']
                
                if 'job_details' in questionnaire_data:
                    data['job_details'] = questionnaire_data['job_details']
                
                if 'recruitment_process' in questionnaire_data:
                    data['recruitment_process'] = questionnaire_data['recruitment_process']
            
            return data
            
        except Exception as e:
            logger.error(f"‚ùå Erreur enrichissement questionnaire: {e}")
            return data
    
    def _prepare_for_transport_intelligence(self, profile: Union[BiDirectionalCandidateProfile, ExtendedMatchingProfile]) -> Union[BiDirectionalCandidateProfile, ExtendedMatchingProfile]:
        """Pr√©pare le profil pour Transport Intelligence V3.0 (CONSERV√â et optimis√©)"""
        
        try:
            # V√©rification et enrichissement donn√©es transport
            if hasattr(profile, 'base_profile') and profile.base_profile:
                base_profile = profile.base_profile
                
                # Enrichissement mobilit√© si n√©cessaire
                if hasattr(base_profile, 'mobility_preferences'):
                    mobility = base_profile.mobility_preferences
                    
                    # Standardisation m√©thodes transport
                    if mobility.transport_methods:
                        mobility.transport_methods = self._standardize_transport_methods(mobility.transport_methods)
                    
                    # Validation temps trajet
                    if mobility.max_travel_time:
                        mobility.max_travel_time = self._validate_travel_time(mobility.max_travel_time)
                
                # Enrichissement localisation
                if hasattr(base_profile, 'personal_info') and base_profile.personal_info:
                    if not hasattr(base_profile.personal_info, 'location') or not base_profile.personal_info.location:
                        base_profile.personal_info.location = "Paris"  # D√©faut
            
            logger.info("üó∫Ô∏è Profil pr√©par√© pour Transport Intelligence V3.0")
            return profile
            
        except Exception as e:
            logger.error(f"‚ùå Erreur pr√©paration Transport Intelligence: {e}")
            return profile
    
    def _standardize_transport_methods(self, methods: List[str]) -> List[str]:
        """Standardise les m√©thodes de transport"""
        
        standardized = []
        for method in methods:
            if method.lower() in ['voiture', 'auto', 'car']:
                standardized.append('voiture')
            elif method.lower() in ['m√©tro', 'bus', 'transport_public', 'rer']:
                standardized.append('transport_public')
            elif method.lower() in ['v√©lo', 'bike']:
                standardized.append('v√©lo')
            elif method.lower() in ['marche', 'pied']:
                standardized.append('marche')
            elif method.lower() in ['t√©l√©travail', 'remote']:
                standardized.append('t√©l√©travail')
            else:
                standardized.append(method)
        
        return list(set(standardized))  # Suppression doublons
    
    def _validate_travel_time(self, travel_time: str) -> str:
        """Valide et standardise le temps de trajet"""
        
        # Extraction nombre de minutes
        import re
        numbers = re.findall(r'\d+', travel_time)
        
        if numbers:
            minutes = int(numbers[0])
            if minutes <= 30:
                return "30 minutes"
            elif minutes <= 45:
                return "45 minutes"
            elif minutes <= 60:
                return "1 heure"
            else:
                return "1 heure+"
        
        return travel_time
    
    def _calculate_data_quality_score(self, profile: Any, parsing_result: Optional[CommitmentParsingResult]) -> float:
        """Calcule un score de qualit√© des donn√©es"""
        
        try:
            quality_score = 0.0
            
            # Score parsing Commitment-
            if parsing_result and parsing_result.success:
                quality_score += parsing_result.extraction_confidence * 0.4
            else:
                quality_score += 0.1  # Score minimal
            
            # Score compl√©tude profil
            if hasattr(profile, 'base_profile') and profile.base_profile:
                base_profile = profile.base_profile
                
                # V√©rification champs essentiels
                essential_fields = 0
                total_fields = 5
                
                if hasattr(base_profile, 'personal_info') and base_profile.personal_info:
                    if base_profile.personal_info.firstName:
                        essential_fields += 1
                    if base_profile.personal_info.email:
                        essential_fields += 1
                
                if hasattr(base_profile, 'skills') and base_profile.skills:
                    essential_fields += 1
                
                if hasattr(base_profile, 'experience') and base_profile.experience:
                    essential_fields += 1
                
                if hasattr(base_profile, 'mobility_preferences') and base_profile.mobility_preferences:
                    essential_fields += 1
                
                quality_score += (essential_fields / total_fields) * 0.3
            
            # Score extensions V3.0
            if hasattr(profile, 'v3_components_count') and profile.v3_components_count:
                quality_score += min(profile.v3_components_count / 10, 1.0) * 0.2
            
            # Score validation
            if hasattr(profile, 'questionnaire_exploitation_rate') and profile.questionnaire_exploitation_rate:
                quality_score += profile.questionnaire_exploitation_rate * 0.1
            
            return min(quality_score, 1.0)
            
        except Exception as e:
            logger.error(f"‚ùå Erreur calcul qualit√© donn√©es: {e}")
            return 0.5
    
    def _generate_simulation_data(self, data_type: str) -> Dict:
        """G√©n√®re des donn√©es de simulation"""
        
        if data_type == "candidat":
            return {
                "personal_info": {
                    "firstName": "Jean",
                    "lastName": "Dupont",
                    "email": "jean.dupont@email.com",
                    "phone": "0123456789"
                },
                "skills": ["Python", "JavaScript", "React"],
                "experience": {"total_years": 3},
                "parsing_confidence": 0.40,
                "simulation_note": "Donn√©es simul√©es - Bridge int√©gr√©"
            }
        else:
            return {
                "titre": "D√©veloppeur Full Stack",
                "localisation": "Paris",
                "competences_requises": ["JavaScript", "React", "Node.js"],
                "parsing_confidence": 0.40,
                "simulation_note": "Donn√©es simul√©es - Bridge int√©gr√©"
            }
    
    def _update_integrated_stats(self, parsing_result: Optional[CommitmentParsingResult], metrics: IntegratedBridgeMetrics):
        """Met √† jour les statistiques int√©gr√©es"""
        
        if parsing_result:
            # Mise √† jour temps parsing
            if self.integrated_stats.commitment_parsing_success > 0:
                self.integrated_stats.avg_commitment_parsing_time_ms = (
                    (self.integrated_stats.avg_commitment_parsing_time_ms * (self.integrated_stats.commitment_parsing_success - 1) + 
                     parsing_result.parsing_time_ms) / self.integrated_stats.commitment_parsing_success
                )
                
                self.integrated_stats.avg_commitment_confidence = (
                    (self.integrated_stats.avg_commitment_confidence * (self.integrated_stats.commitment_parsing_success - 1) + 
                     parsing_result.extraction_confidence) / self.integrated_stats.commitment_parsing_success
                )
    
    # === M√âTHODES PUBLIQUES ===
    
    def get_integrated_stats(self) -> Dict[str, Any]:
        """R√©cup√®re les statistiques int√©gr√©es"""
        
        # Stats Enhanced Bridge V3.0
        base_stats = self._enhanced_bridge_v3.get_enhanced_stats_v3()
        
        # Stats Commitment-
        commitment_stats = {}
        if hasattr(self, 'commitment_bridge'):
            commitment_stats = self.commitment_bridge.get_health_status()
        
        # Stats int√©gr√©es
        integrated_stats = {
            "integration_stats": {
                "commitment_parsing_attempts": self.integrated_stats.commitment_parsing_attempts,
                "commitment_parsing_success": self.integrated_stats.commitment_parsing_success,
                "commitment_parsing_success_rate": (
                    (self.integrated_stats.commitment_parsing_success / max(1, self.integrated_stats.commitment_parsing_attempts)) * 100
                ),
                "commitment_parsing_fallback": self.integrated_stats.commitment_parsing_fallback,
                "commitment_parsing_errors": self.integrated_stats.commitment_parsing_errors,
                "avg_commitment_parsing_time_ms": round(self.integrated_stats.avg_commitment_parsing_time_ms, 2),
                "avg_commitment_confidence": round(self.integrated_stats.avg_commitment_confidence, 2),
                "successful_integrations": self.integrated_stats.successful_integrations,
                "integration_errors": self.integrated_stats.integration_errors
            },
            "parsing_strategies": {
                "real_parsing_usage": self.integrated_stats.real_parsing_usage,
                "fallback_parsing_usage": self.integrated_stats.fallback_parsing_usage,
                "simulation_parsing_usage": self.integrated_stats.simulation_parsing_usage
            },
            "commitment_bridge_health": commitment_stats,
            "configuration": self.integration_config
        }
        
        # Fusion stats
        base_stats.update(integrated_stats)
        
        return base_stats
    
    def get_integration_health(self) -> Dict[str, Any]:
        """R√©cup√®re le statut de sant√© de l'int√©gration"""
        
        total_attempts = self.integrated_stats.commitment_parsing_attempts
        success_rate = 0
        
        if total_attempts > 0:
            success_rate = (self.integrated_stats.successful_integrations / total_attempts) * 100
        
        # D√©termination statut
        if success_rate >= 90:
            status = "excellent"
        elif success_rate >= 75:
            status = "good"
        elif success_rate >= 50:
            status = "degraded"
        else:
            status = "critical"
        
        return {
            "status": status,
            "integration_success_rate": round(success_rate, 2),
            "commitment_parsing_success_rate": round(
                (self.integrated_stats.commitment_parsing_success / max(1, total_attempts)) * 100, 2
            ),
            "avg_processing_time_ms": round(self.integrated_stats.avg_commitment_parsing_time_ms, 2),
            "avg_data_confidence": round(self.integrated_stats.avg_commitment_confidence, 2),
            "total_integrations": total_attempts,
            "successful_integrations": self.integrated_stats.successful_integrations,
            "integration_errors": self.integrated_stats.integration_errors,
            "real_parsing_enabled": self.integration_config['enable_real_parsing'],
            "fallback_enabled": self.integration_config['enable_commitment_fallback']
        }
    
    def reset_integrated_stats(self):
        """Remet √† z√©ro les statistiques int√©gr√©es"""
        self._enhanced_bridge_v3.reset_stats_v3()
        self.integrated_stats = IntegratedBridgeStats(last_reset=datetime.now())
        
        if hasattr(self, 'commitment_bridge'):
            self.commitment_bridge.reset_stats()
        
        logger.info("üîÑ Statistiques int√©gr√©es remises √† z√©ro")
    
    async def close(self):
        """Ferme le bridge int√©gr√©"""
        
        if hasattr(self, 'commitment_bridge'):
            await self.commitment_bridge.close()
        
        logger.info("üîí Enhanced Bridge V3.0 Int√©gr√© ferm√©")

# === FACTORY INT√âGR√â ===

class IntegratedBridgeFactory:
    """üèóÔ∏è Factory pour Enhanced Bridge V3.0 Int√©gr√©"""
    
    @staticmethod
    def create_integrated_bridge(enable_real_parsing: bool = True,
                               enable_commitment_fallback: bool = True,
                               commitment_timeout: int = 30) -> EnhancedCommitmentBridgeV3Integrated:
        """Cr√©e un bridge int√©gr√© avec configuration"""
        
        return EnhancedCommitmentBridgeV3Integrated(
            enable_real_parsing=enable_real_parsing,
            enable_commitment_fallback=enable_commitment_fallback,
            commitment_timeout=commitment_timeout
        )
    
    @staticmethod
    def create_production_integrated_bridge() -> EnhancedCommitmentBridgeV3Integrated:
        """Cr√©e un bridge int√©gr√© optimis√© pour production"""
        
        return EnhancedCommitmentBridgeV3Integrated(
            enable_real_parsing=True,
            enable_commitment_fallback=True,
            commitment_timeout=45
        )
    
    @staticmethod
    def create_development_integrated_bridge() -> EnhancedCommitmentBridgeV3Integrated:
        """Cr√©e un bridge int√©gr√© pour d√©veloppement"""
        
        return EnhancedCommitmentBridgeV3Integrated(
            enable_real_parsing=False,  # Simulation en d√©veloppement
            enable_commitment_fallback=True,
            commitment_timeout=15
        )

# === TESTS INT√âGRATION ===

if __name__ == "__main__":
    async def test_integrated_bridge():
        """Test du bridge int√©gr√©"""
        
        bridge = IntegratedBridgeFactory.create_development_integrated_bridge()
        
        print("üß™ === TEST ENHANCED BRIDGE V3.0 INT√âGR√â ===")
        
        # Test candidat avec CV
        candidat_questionnaire = {
            "mobility_preferences": {
                "transport_methods": ["transport_public", "v√©lo"],
                "max_travel_time": "45 minutes"
            },
            "motivations_sectors": {
                "motivations_ranking": ["d√©fis_techniques", "√©quilibre_vie"],
                "preferred_sectors": ["technologie"]
            },
            "availability_status": {
                "availability_timing": "1-3_mois",
                "current_status": "en_poste"
            }
        }
        
        # Test sans fichier CV (simulation)
        candidat_result, metrics = await bridge.convert_candidat_enhanced_integrated(
            parser_output=None,
            cv_file_path=None,
            questionnaire_data=candidat_questionnaire,
            enable_real_parsing=False
        )
        
        print(f"‚úÖ Candidat int√©gr√©: {type(candidat_result).__name__}")
        print(f"üéØ Int√©gration r√©ussie: {metrics.integration_success}")
        print(f"‚ö° Temps total: {metrics.total_time_ms:.2f}ms")
        print(f"üîç Confiance parsing: {metrics.commitment_confidence:.2f}")
        print(f"üìä Qualit√© donn√©es: {metrics.data_quality_score:.2f}")
        print(f"üõ†Ô∏è Strat√©gie: {metrics.commitment_strategy_used}")
        
        # Test entreprise
        entreprise_questionnaire = {
            "company_structure": {
                "sector": "technologie",
                "size": "startup"
            },
            "job_details": {
                "contract_type": "CDI",
                "benefits": ["mutuelle", "t√©l√©travail"]
            }
        }
        
        job_description = """
        Nous recherchons un D√©veloppeur Full Stack Senior pour rejoindre notre √©quipe.
        Comp√©tences requises: JavaScript, React, Node.js, Python
        Exp√©rience: 5+ ans
        Localisation: Paris
        Type: CDI
        Salaire: 60K - 80K
        """
        
        entreprise_result, metrics2 = await bridge.convert_entreprise_enhanced_integrated(
            chatgpt_output=None,
            job_description_text=job_description,
            questionnaire_data=entreprise_questionnaire,
            enable_real_parsing=True
        )
        
        print(f"\nüè¢ Entreprise int√©gr√©e: {type(entreprise_result).__name__}")
        print(f"üéØ Int√©gration r√©ussie: {metrics2.integration_success}")
        print(f"‚ö° Temps total: {metrics2.total_time_ms:.2f}ms")
        print(f"üîç Confiance parsing: {metrics2.commitment_confidence:.2f}")
        print(f"üìä Qualit√© donn√©es: {metrics2.data_quality_score:.2f}")
        
        # Statistiques int√©gr√©es
        stats = bridge.get_integrated_stats()
        print(f"\nüìä === STATISTIQUES INT√âGR√âES ===")
        print(f"üéØ Tentatives parsing: {stats['integration_stats']['commitment_parsing_attempts']}")
        print(f"‚úÖ Succ√®s parsing: {stats['integration_stats']['commitment_parsing_success']}")
        print(f"üìà Taux succ√®s: {stats['integration_stats']['commitment_parsing_success_rate']:.1f}%")
        print(f"‚ö° Temps moyen: {stats['integration_stats']['avg_commitment_parsing_time_ms']:.2f}ms")
        
        # Health check
        health = bridge.get_integration_health()
        print(f"\nüè• === SANT√â INT√âGRATION ===")
        print(f"üéØ Statut: {health['status']}")
        print(f"‚úÖ Taux succ√®s int√©gration: {health['integration_success_rate']:.1f}%")
        print(f"üîç Parsing r√©el activ√©: {health['real_parsing_enabled']}")
        print(f"üîÑ Fallback activ√©: {health['fallback_enabled']}")
        
        await bridge.close()
        
        print("\n‚úÖ Tests Enhanced Bridge V3.0 Int√©gr√© r√©ussis!")
    
    # Lancement test
    asyncio.run(test_integrated_bridge())
