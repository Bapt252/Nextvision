#!/usr/bin/env python3
"""
üöÄ NEXTVISION V3.2.1 - LANCEUR DE TESTS COMPLET

Orchestration compl√®te des tests end-to-end :
1. Diagnostic pr√©-tests automatique
2. Validation syst√®me
3. Lancement des tests e2e
4. G√©n√©ration rapport consolid√©
5. Recommandations post-tests

Version: 3.2.1
Date: 2025-07-11
Auteur: Assistant Claude
"""

import sys
import subprocess
import json
import asyncio
from datetime import datetime
from pathlib import Path
import argparse

class TestLauncher:
    """Lanceur orchestr√© des tests Nextvision V3.2.1"""
    
    def __init__(self, args):
        self.args = args
        self.results = {
            "diagnostic": None,
            "e2e_tests": None,
            "summary": None
        }
        
    def print_banner(self):
        """Affiche la banni√®re de lancement"""
        print("üöÄ NEXTVISION V3.2.1 - VALIDATION COMPL√àTE")
        print("=" * 60)
        print("Tests End-to-End avec Diagnostic Automatique")
        print("Validation compl√®te du parcours utilisateur")
        print("=" * 60)
        print()
    
    def run_diagnostic(self) -> bool:
        """Lance le diagnostic pr√©-tests"""
        print("üîç √âTAPE 1/3: Diagnostic Syst√®me")
        print("-" * 40)
        
        try:
            # Lancement du diagnostic
            result = subprocess.run([
                sys.executable, "diagnostic_pre_tests.py"
            ], capture_output=True, text=True, timeout=120)
            
            # R√©cup√©ration du code de sortie
            diagnostic_success = result.returncode == 0
            
            # Affichage des r√©sultats
            if result.stdout:
                print(result.stdout)
            
            if result.stderr and not diagnostic_success:
                print("Erreurs d√©tect√©es:")
                print(result.stderr)
            
            # Chargement du rapport JSON si disponible
            try:
                diagnostic_files = list(Path(".").glob("diagnostic_report_*.json"))
                if diagnostic_files:
                    latest_file = max(diagnostic_files, key=lambda f: f.stat().st_mtime)
                    with open(latest_file, 'r', encoding='utf-8') as f:
                        self.results["diagnostic"] = json.load(f)
                        
            except Exception as e:
                print(f"‚ö†Ô∏è  Impossible de charger le rapport diagnostic: {e}")
            
            if diagnostic_success:
                print("‚úÖ Diagnostic termin√© avec succ√®s!")
                return True
            else:
                print("‚ùå Diagnostic a d√©tect√© des probl√®mes critiques")
                if not self.args.force:
                    print("üí° Utiliser --force pour continuer malgr√© les erreurs")
                    return False
                else:
                    print("‚ö†Ô∏è  Continuation forc√©e malgr√© les erreurs")
                    return True
                    
        except subprocess.TimeoutExpired:
            print("‚ùå Timeout du diagnostic (>2 minutes)")
            return False
        except Exception as e:
            print(f"‚ùå Erreur lors du diagnostic: {e}")
            return False
    
    async def run_e2e_tests(self) -> bool:
        """Lance les tests end-to-end"""
        print("\nüß™ √âTAPE 2/3: Tests End-to-End")
        print("-" * 40)
        
        try:
            # Lancement des tests e2e
            if self.args.quick:
                print("‚ö° Mode rapide activ√© - Tests essentiels uniquement")
                # Pour le mode rapide, on pourrait modifier le script e2e
                # ou cr√©er une version all√©g√©e
            
            result = subprocess.run([
                sys.executable, "test_e2e_nextvision_v321.py"
            ], capture_output=True, text=True, timeout=600)  # 10 minutes max
            
            # R√©cup√©ration du code de sortie
            tests_success = result.returncode == 0
            
            # Affichage des r√©sultats
            if result.stdout:
                print(result.stdout)
            
            if result.stderr and not tests_success:
                print("Erreurs pendant les tests:")
                print(result.stderr)
            
            # Chargement du rapport JSON si disponible
            try:
                e2e_files = list(Path(".").glob("nextvision_e2e_report_*.json"))
                if e2e_files:
                    latest_file = max(e2e_files, key=lambda f: f.stat().st_mtime)
                    with open(latest_file, 'r', encoding='utf-8') as f:
                        self.results["e2e_tests"] = json.load(f)
                        
            except Exception as e:
                print(f"‚ö†Ô∏è  Impossible de charger le rapport e2e: {e}")
            
            if tests_success:
                print("‚úÖ Tests end-to-end termin√©s avec succ√®s!")
                return True
            else:
                print("‚ùå Certains tests end-to-end ont √©chou√©")
                return False
                
        except subprocess.TimeoutExpired:
            print("‚ùå Timeout des tests e2e (>10 minutes)")
            return False
        except Exception as e:
            print(f"‚ùå Erreur lors des tests e2e: {e}")
            return False
    
    def generate_consolidated_report(self):
        """G√©n√®re un rapport consolid√©"""
        print("\nüìä √âTAPE 3/3: Rapport Consolid√©")
        print("-" * 40)
        
        # Analyse des r√©sultats
        diagnostic_data = self.results.get("diagnostic", {})
        e2e_data = self.results.get("e2e_tests", {})
        
        # Extraction des m√©triques cl√©s
        diagnostic_summary = diagnostic_data.get("summary", {})
        e2e_summary = e2e_data.get("summary", {})
        
        # Calcul du score global
        diagnostic_score = diagnostic_summary.get("success_rate", 0)
        e2e_score = e2e_summary.get("success_rate", 0)
        global_score = (diagnostic_score + e2e_score) / 2 if diagnostic_score and e2e_score else 0
        
        # Statut global
        if global_score >= 0.9:
            global_status = "EXCELLENT"
            status_emoji = "üéâ"
        elif global_score >= 0.8:
            global_status = "BON"
            status_emoji = "‚úÖ"
        elif global_score >= 0.6:
            global_status = "ACCEPTABLE"
            status_emoji = "‚ö†Ô∏è"
        else:
            global_status = "CRITIQUE"
            status_emoji = "‚ùå"
        
        # G√©n√©ration du rapport
        consolidated_report = {
            "validation_summary": {
                "timestamp": datetime.now().isoformat(),
                "global_score": global_score,
                "global_status": global_status,
                "diagnostic_success_rate": diagnostic_score,
                "e2e_success_rate": e2e_score,
                "ready_for_production": global_score >= 0.8
            },
            "diagnostic_results": diagnostic_data,
            "e2e_test_results": e2e_data,
            "final_recommendations": self._generate_final_recommendations()
        }
        
        # Sauvegarde du rapport consolid√©
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"nextvision_validation_report_{timestamp}.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(consolidated_report, f, indent=2, ensure_ascii=False)
        
        # Affichage du r√©sum√©
        print(f"{status_emoji} STATUT GLOBAL: {global_status}")
        print(f"Score de validation: {global_score:.1%}")
        print(f"Diagnostic: {diagnostic_score:.1%}")
        print(f"Tests E2E: {e2e_score:.1%}")
        
        if consolidated_report["validation_summary"]["ready_for_production"]:
            print("\nüéØ NEXTVISION V3.2.1 EST PR√äT POUR LA PRODUCTION ! üéØ")
        else:
            print(f"\n‚ö†Ô∏è  Optimisations n√©cessaires avant production")
        
        print(f"\nüíæ Rapport complet: {report_file}")
        
        # Affichage des recommandations
        print("\nüìã RECOMMANDATIONS FINALES:")
        for rec in consolidated_report["final_recommendations"]:
            print(f"  ‚Ä¢ {rec}")
        
        self.results["summary"] = consolidated_report
        
        return global_score >= 0.8
    
    def _generate_final_recommendations(self):
        """G√©n√®re les recommandations finales"""
        recommendations = []
        
        diagnostic_data = self.results.get("diagnostic", {})
        e2e_data = self.results.get("e2e_tests", {})
        
        # Analyse du diagnostic
        if diagnostic_data:
            diagnostic_summary = diagnostic_data.get("summary", {})
            if diagnostic_summary.get("success_rate", 0) < 0.8:
                recommendations.append("Corriger les probl√®mes d√©tect√©s lors du diagnostic syst√®me")
            
            critical_failures = diagnostic_summary.get("critical_failures", [])
            if critical_failures:
                recommendations.append(f"R√©soudre les √©checs critiques: {', '.join(critical_failures)}")
        
        # Analyse des tests e2e
        if e2e_data:
            e2e_summary = e2e_data.get("summary", {})
            if e2e_summary.get("success_rate", 0) < 0.8:
                recommendations.append("Investiguer les √©checs des tests end-to-end")
            
            # Recommandations sp√©cifiques bas√©es sur les tests
            test_results = e2e_data.get("test_results", [])
            for test in test_results:
                if not test.get("success"):
                    test_name = test.get("test_name", "")
                    if "Charlotte DARMON" in test_name or "Hierarchical" in test_name:
                        recommendations.append("V√©rifier le syst√®me hi√©rarchique V3.2.1")
                    elif "Google Maps" in test_name:
                        recommendations.append("V√©rifier la configuration Google Maps API")
                    elif "Transport" in test_name:
                        recommendations.append("Optimiser le module Transport Intelligence")
                    elif "Performance" in test_name:
                        recommendations.append("Optimiser les performances syst√®me")
        
        # Recommandations g√©n√©rales
        if not recommendations:
            recommendations.extend([
                "Syst√®me valid√© - Pr√™t pour la mise en production",
                "Surveiller les performances en production",
                "Mettre en place le monitoring automatique",
                "Documenter les proc√©dures de d√©ploiement"
            ])
        else:
            recommendations.append("Relancer les tests apr√®s corrections")
            recommendations.append("V√©rifier la documentation de d√©ploiement")
        
        return recommendations
    
    def run(self) -> int:
        """Lance la validation compl√®te"""
        self.print_banner()
        
        # √âtape 1: Diagnostic
        if not self.args.skip_diagnostic:
            diagnostic_success = self.run_diagnostic()
            if not diagnostic_success and not self.args.force:
                print("\n‚ùå Arr√™t en raison d'√©checs du diagnostic")
                print("üí° Utiliser --force pour continuer ou corriger les probl√®mes")
                return 1
        else:
            print("‚è≠Ô∏è  Diagnostic ignor√© (--skip-diagnostic)")
        
        # √âtape 2: Tests E2E
        if not self.args.skip_e2e:
            e2e_success = asyncio.run(self.run_e2e_tests())
        else:
            print("‚è≠Ô∏è  Tests E2E ignor√©s (--skip-e2e)")
            e2e_success = True
        
        # √âtape 3: Rapport consolid√©
        final_success = self.generate_consolidated_report()
        
        # Code de sortie
        if final_success:
            print("\nüéâ VALIDATION NEXTVISION V3.2.1 R√âUSSIE !")
            return 0
        else:
            print("\n‚ö†Ô∏è  Validation incompl√®te - Voir les recommandations")
            return 1


def main():
    """Fonction principale avec arguments"""
    parser = argparse.ArgumentParser(
        description="Lanceur de tests complet Nextvision V3.2.1",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples d'utilisation:
  python launch_complete_tests.py                 # Validation compl√®te
  python launch_complete_tests.py --quick         # Tests rapides
  python launch_complete_tests.py --force         # Continue malgr√© les erreurs
  python launch_complete_tests.py --skip-diagnostic  # Ignore le diagnostic
  python launch_complete_tests.py --skip-e2e      # Ignore les tests e2e
        """
    )
    
    parser.add_argument(
        '--quick',
        action='store_true',
        help='Mode rapide - Tests essentiels uniquement'
    )
    
    parser.add_argument(
        '--force',
        action='store_true',
        help='Continue m√™me si le diagnostic d√©tecte des probl√®mes'
    )
    
    parser.add_argument(
        '--skip-diagnostic',
        action='store_true',
        help='Ignore le diagnostic pr√©-tests'
    )
    
    parser.add_argument(
        '--skip-e2e',
        action='store_true',
        help='Ignore les tests end-to-end'
    )
    
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='Affichage verbeux'
    )
    
    args = parser.parse_args()
    
    # Validation des arguments
    if args.skip_diagnostic and args.skip_e2e:
        print("‚ùå Erreur: Impossible d'ignorer √† la fois le diagnostic ET les tests e2e")
        return 2
    
    try:
        launcher = TestLauncher(args)
        return launcher.run()
        
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Tests interrompus par l'utilisateur")
        return 2
    except Exception as e:
        print(f"\n‚ùå Erreur critique: {str(e)}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 3


if __name__ == "__main__":
    exit(main())
