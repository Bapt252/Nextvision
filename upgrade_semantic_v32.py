#!/usr/bin/env python3
"""
Script de Mise √† Niveau S√©mantique V3.2 - Nextvision
====================================================

Script pour appliquer les am√©liorations s√©mantiques et tester les r√©sultats
Corrige les 4 probl√®mes identifi√©s :
1. Surqualification mal d√©tect√©e  
2. Matches parfaits sous-√©valu√©s
3. Incompatibilit√©s sectorielles 
4. Algorithme de matching trop simpliste

Usage: python upgrade_semantic_v32.py

Baptiste Comas - Nextvision V3.2
"""

import sys
import time
import logging
from typing import Dict, Any
import os

# Ajout du chemin des modules
sys.path.append('gpt_modules')

# Configuration logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('semantic_upgrade')

class SemanticUpgradeManager:
    """Gestionnaire de mise √† niveau s√©mantique"""
    
    def __init__(self):
        self.logger = logger
        self.backup_created = False
        
        # Import des modules existants
        try:
            from integration import GPTNextvisionIntegrator, quick_test_charlotte_vs_comptable
            from cv_parser import CVParserGPT
            from job_parser import JobParserGPT
            
            self.integration_module = GPTNextvisionIntegrator
            self.test_function = quick_test_charlotte_vs_comptable
            
            # Configuration OpenAI si disponible
            openai_client = None
            if os.getenv('OPENAI_API_KEY'):
                try:
                    import openai
                    openai_client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
                except:
                    pass
            
            # Initialisation des parsers
            self.cv_parser = CVParserGPT(openai_client)
            self.job_parser = JobParserGPT(openai_client)
            
            logger.info("‚úÖ Modules Nextvision charg√©s")
            
        except ImportError as e:
            logger.error(f"‚ùå Erreur import: {e}")
            sys.exit(1)

    def create_enhanced_semantic_method(self):
        """Cr√©e la m√©thode s√©mantique am√©lior√©e"""
        
        # Dictionnaires int√©gr√©s directement
        skills_synonyms = {
            "tech": {
                "javascript": ["js", "ecmascript", "node.js", "frontend", "react", "vue"],
                "python": ["py", "django", "flask", "data science", "backend"],
                "react": ["reactjs", "react.js", "frontend", "spa", "javascript"],
                "node": ["nodejs", "node.js", "backend", "javascript", "express"],
                "api": ["rest", "api rest", "web service", "microservice"],
                "git": ["github", "gitlab", "version control", "versionning"],
                "docker": ["container", "containerisation", "devops"],
                "sql": ["mysql", "postgresql", "database", "bdd"],
                "frontend": ["front-end", "interface", "ui", "client-side"],
                "backend": ["back-end", "serveur", "server-side", "api"]
            },
            "finance": {
                "excel": ["tableur", "spreadsheet", "vba", "mod√©lisation financi√®re"],
                "sap": ["erp", "syst√®me de gestion", "sap fi", "sap co"],
                "ifrs": ["normes comptables", "consolidation", "reporting financier"],
                "comptabilit√©": ["compta", "comptable", "√©critures", "saisie"],
                "contr√¥le": ["contr√¥le de gestion", "budget", "pilotage"],
                "audit": ["r√©vision", "contr√¥le interne", "audit interne"],
                "consolidation": ["comptes consolid√©s", "ifrs", "groupe"],
                "fiscalit√©": ["fiscal", "imp√¥ts", "d√©clarations", "tva"],
                "tr√©sorerie": ["cash management", "finances", "liquidit√©"],
                "reporting": ["rapport", "dashboard", "tableau de bord"]
            },
            "general": {
                "management": ["gestion √©quipe", "encadrement", "leadership"],
                "gestion": ["pilotage", "organisation", "coordination"],
                "projet": ["gestion de projet", "chef de projet", "project management"],
                "analyse": ["analytique", "√©tude", "investigation"]
            }
        }
        
        sector_incompatibilities = {
            ("tech", "finance"): 0.3,
            ("tech", "comptabilit√©"): 0.2,
            ("finance", "tech"): 0.3,
            ("comptabilit√©", "tech"): 0.2,
            ("commercial", "technique"): 0.4,
            ("technique", "commercial"): 0.4
        }
        
        def check_synonyms(skill1: str, skill2: str, sector: str) -> float:
            """V√©rifie si deux comp√©tences sont synonymes"""
            sector_synonyms = skills_synonyms.get(sector, {})
            general_synonyms = skills_synonyms.get("general", {})
            all_synonyms = {**sector_synonyms, **general_synonyms}
            
            for key, synonyms in all_synonyms.items():
                if key in skill1:
                    if any(syn in skill2 for syn in synonyms) or skill2 in synonyms:
                        return 0.9
                if key in skill2:
                    if any(syn in skill1 for syn in synonyms) or skill1 in synonyms:
                        return 0.9
                if any(syn in skill1 for syn in synonyms) and any(syn in skill2 for syn in synonyms):
                    return 0.7
            return 0.0
        
        def calculate_sector_penalty(candidate_sector: str, job_sector: str) -> float:
            """Calcule la p√©nalit√© sectorielle"""
            if not candidate_sector or not job_sector:
                return 1.0
            
            candidate_lower = candidate_sector.lower()
            job_lower = job_sector.lower()
            
            # Correspondance exacte
            if candidate_lower == job_lower:
                return 1.0
            
            # V√©rification des incompatibilit√©s
            sector_pair = (candidate_lower, job_lower)
            if sector_pair in sector_incompatibilities:
                return sector_incompatibilities[sector_pair]
            
            # Secteurs compatibles
            finance_sectors = ["finance", "comptabilit√©", "audit", "contr√¥le"]
            tech_sectors = ["tech", "informatique", "d√©veloppement"]
            
            candidate_finance = any(sector in candidate_lower for sector in finance_sectors)
            job_finance = any(sector in job_lower for sector in finance_sectors)
            candidate_tech = any(sector in candidate_lower for sector in tech_sectors)
            job_tech = any(sector in job_lower for sector in tech_sectors)
            
            if candidate_finance and job_finance:
                return 0.8
            if candidate_tech and job_tech:
                return 0.9
            
            return 0.6
        
        def detect_overqualification(candidate_data: Dict, job_data: Dict) -> float:
            """D√©tecte la surqualification"""
            candidate_level = candidate_data.get('professional_info', {}).get('hierarchical_level', '')
            job_level = job_data.get('requirements', {}).get('hierarchical_level', '')
            
            hierarchy_order = {
                'ENTRY': 0, 'JUNIOR': 1, 'SENIOR': 2,
                'MANAGER': 3, 'DIRECTOR': 4, 'EXECUTIVE': 5
            }
            
            candidate_rank = hierarchy_order.get(candidate_level, 0)
            job_rank = hierarchy_order.get(job_level, 0)
            level_gap = candidate_rank - job_rank
            
            if level_gap <= 0:
                return 1.0
            elif level_gap == 1:
                return 0.9
            elif level_gap == 2:
                return 0.7
            elif level_gap >= 3:
                return 0.5
            return 1.0
        
        def enhanced_calculate_semantic_score(self, candidate_data: Dict, job_data: Dict) -> float:
            """
            NOUVEAU: Algorithme s√©mantique am√©lior√© V3.2
            Corrige les 4 probl√®mes identifi√©s lors des tests
            """
            try:
                # Extraction des donn√©es
                candidate_skills = candidate_data.get('skills', {}).get('technical_skills', [])
                candidate_sector = candidate_data.get('professional_info', {}).get('sector', '').lower()
                
                job_required_skills = job_data.get('requirements', {}).get('required_skills', [])
                job_preferred_skills = job_data.get('requirements', {}).get('preferred_skills', [])
                job_sector = job_data.get('job_info', {}).get('sector', '').lower()
                
                if not candidate_skills or not job_required_skills:
                    return 0.4
                
                # Calcul des matches avec synonymes
                required_matches = 0
                required_confidence_sum = 0.0
                
                for req_skill in job_required_skills:
                    req_skill_lower = req_skill.lower()
                    best_match_confidence = 0.0
                    
                    for cand_skill in candidate_skills:
                        cand_skill_lower = cand_skill.lower()
                        confidence = 0.0
                        
                        # Match exact
                        if req_skill_lower == cand_skill_lower:
                            confidence = 1.0
                        # Match partiel
                        elif req_skill_lower in cand_skill_lower or cand_skill_lower in req_skill_lower:
                            confidence = 0.8
                        # Match synonyme
                        else:
                            confidence = check_synonyms(req_skill_lower, cand_skill_lower, job_sector)
                        
                        best_match_confidence = max(best_match_confidence, confidence)
                    
                    if best_match_confidence > 0.5:  # Seuil de confiance
                        required_matches += 1
                    required_confidence_sum += best_match_confidence
                
                # Calcul des matches pr√©f√©r√©s
                preferred_matches = 0
                preferred_confidence_sum = 0.0
                
                if job_preferred_skills:
                    for pref_skill in job_preferred_skills:
                        pref_skill_lower = pref_skill.lower()
                        best_match_confidence = 0.0
                        
                        for cand_skill in candidate_skills:
                            cand_skill_lower = cand_skill.lower()
                            confidence = 0.0
                            
                            if pref_skill_lower == cand_skill_lower:
                                confidence = 1.0
                            elif pref_skill_lower in cand_skill_lower or cand_skill_lower in pref_skill_lower:
                                confidence = 0.8
                            else:
                                confidence = check_synonyms(pref_skill_lower, cand_skill_lower, job_sector)
                            
                            best_match_confidence = max(best_match_confidence, confidence)
                        
                        if best_match_confidence > 0.5:
                            preferred_matches += 1
                        preferred_confidence_sum += best_match_confidence
                
                # Score bas√© sur la couverture ET la confiance
                required_coverage = required_matches / len(job_required_skills)
                required_avg_confidence = required_confidence_sum / len(job_required_skills)
                required_score = (required_coverage * 0.6) + (required_avg_confidence * 0.4)
                
                preferred_score = 0.0
                if job_preferred_skills:
                    preferred_coverage = preferred_matches / len(job_preferred_skills)
                    preferred_avg_confidence = preferred_confidence_sum / len(job_preferred_skills)
                    preferred_score = (preferred_coverage * 0.6) + (preferred_avg_confidence * 0.4)
                
                # Score combin√© (75% requis, 25% pr√©f√©r√©)
                base_semantic_score = (required_score * 0.75) + (preferred_score * 0.25)
                
                # NOUVEAU: Application des p√©nalit√©s
                sector_penalty = calculate_sector_penalty(candidate_sector, job_sector)
                overqualification_penalty = detect_overqualification(candidate_data, job_data)
                
                # Score final avec p√©nalit√©s
                final_score = base_semantic_score * sector_penalty * overqualification_penalty
                
                # Bonus pour matches parfaits (r√©sout le probl√®me des 0.890)
                if required_matches == len(job_required_skills) and required_avg_confidence > 0.9:
                    final_score = min(final_score * 1.1, 1.0)  # Bonus de 10%
                
                # Log am√©lior√© pour debugging
                self.logger.debug(f"S√©mantique V3.2: base={base_semantic_score:.3f}, "
                                f"secteur={sector_penalty:.2f}, surqualif={overqualification_penalty:.2f}, "
                                f"final={final_score:.3f}")
                
                return final_score
                
            except Exception as e:
                self.logger.error(f"Erreur s√©mantique V3.2: {e}")
                return 0.3  # Score de s√©curit√©
        
        return enhanced_calculate_semantic_score

    def apply_upgrade(self):
        """Applique la mise √† niveau s√©mantique"""
        
        logger.info("üöÄ D√âBUT MISE √Ä NIVEAU S√âMANTIQUE V3.2")
        logger.info("=" * 50)
        
        # Test AVANT la mise √† niveau
        logger.info("üìã Test AVANT mise √† niveau (V3.1)")
        integrator_v31 = self.integration_module(
            cv_parser=self.cv_parser,
            job_parser=self.job_parser
        )
        
        result_before = integrator_v31.test_charlotte_darmon_vs_comptable()
        score_before = result_before['result'].total_score
        semantic_before = result_before['result'].scores_breakdown.get('semantic', 0)
        
        logger.info(f"   Score total V3.1: {score_before:.3f}")
        logger.info(f"   Score s√©mantique V3.1: {semantic_before:.3f}")
        
        # Application de la mise √† niveau
        logger.info("\nüîß Application des am√©liorations V3.2...")
        
        enhanced_method = self.create_enhanced_semantic_method()
        
        # Remplacement de la m√©thode
        self.integration_module.calculate_semantic_score = enhanced_method
        
        # Test APR√àS la mise √† niveau
        logger.info("\nüìã Test APR√àS mise √† niveau (V3.2)")
        integrator_v32 = self.integration_module(
            cv_parser=self.cv_parser,
            job_parser=self.job_parser
        )
        integrator_v32.version = "3.2.0"  # Mise √† jour version
        
        result_after = integrator_v32.test_charlotte_darmon_vs_comptable()
        score_after = result_after['result'].total_score
        semantic_after = result_after['result'].scores_breakdown.get('semantic', 0)
        
        logger.info(f"   Score total V3.2: {score_after:.3f}")
        logger.info(f"   Score s√©mantique V3.2: {semantic_after:.3f}")
        
        # Validation du succ√®s
        charlotte_maintained = abs(score_after - score_before) < 0.05  # Tol√©rance 5%
        
        logger.info("\n" + "=" * 50)
        logger.info("üìä R√âSULTATS DE LA MISE √Ä NIVEAU")
        logger.info("=" * 50)
        
        if charlotte_maintained:
            logger.info("‚úÖ Test Charlotte DARMON maintenu (objectif principal)")
            logger.info(f"   √âcart: {abs(score_after - score_before):.3f}")
        else:
            logger.info("‚ùå Test Charlotte DARMON impact√©")
            logger.info(f"   √âcart: {abs(score_after - score_before):.3f}")
        
        logger.info(f"üìà √âvolution s√©mantique: {semantic_before:.3f} ‚Üí {semantic_after:.3f}")
        
        return {
            "success": charlotte_maintained,
            "score_before": score_before,
            "score_after": score_after,
            "semantic_before": semantic_before,
            "semantic_after": semantic_after,
            "integrator_v32": integrator_v32
        }

    def run_enhanced_tests(self, integrator_v32):
        """Lance les tests avec l'algorithme am√©lior√©"""
        
        logger.info("\nüß™ TESTS AVEC ALGORITHME V3.2")
        logger.info("=" * 40)
        
        # Import du script de test
        try:
            from test_semantic_matching import SemanticTestSuite
            
            # Configuration de la suite de tests avec l'int√©grateur V3.2
            test_suite = SemanticTestSuite(os.getenv('OPENAI_API_KEY'))
            test_suite.integrator = integrator_v32  # Utilisation de la V3.2
            
            # Ex√©cution des tests
            results = test_suite.run_full_test_suite()
            
            logger.info(f"‚úÖ Tests r√©ussis V3.2: {results['successful_tests']}/{results['total_tests']} "
                      f"({results['success_rate']:.1f}%)")
            
            # Comparaison avec les r√©sultats pr√©c√©dents (60%)
            improvement = results['success_rate'] - 60.0
            if improvement > 0:
                logger.info(f"üìà AM√âLIORATION: +{improvement:.1f}% par rapport √† V3.1")
            else:
                logger.info(f"üìâ R√©gression: {improvement:.1f}% par rapport √† V3.1")
            
            return results
            
        except ImportError:
            logger.warning("‚ö†Ô∏è Script de test non trouv√©, tests manuels uniquement")
            return None

def main():
    """Fonction principale"""
    
    print("üöÄ NEXTVISION V3.2 - MISE √Ä NIVEAU S√âMANTIQUE")
    print("=" * 50)
    
    try:
        # Initialisation du gestionnaire
        upgrade_manager = SemanticUpgradeManager()
        
        # Application de la mise √† niveau
        upgrade_result = upgrade_manager.apply_upgrade()
        
        if upgrade_result["success"]:
            print("\n‚úÖ MISE √Ä NIVEAU R√âUSSIE")
            print("Objectif Charlotte DARMON maintenu")
            
            # Tests √©tendus avec V3.2
            test_results = upgrade_manager.run_enhanced_tests(upgrade_result["integrator_v32"])
            
            if test_results and test_results["success_rate"] >= 80:
                print("üéØ SUCC√àS COMPLET: Syst√®me V3.2 op√©rationnel")
                print(f"   Performance: {test_results['success_rate']:.1f}% de r√©ussite")
            elif test_results:
                print("‚ö†Ô∏è AM√âLIORATION PARTIELLE")
                print(f"   Performance: {test_results['success_rate']:.1f}% de r√©ussite")
                print("   Optimisations suppl√©mentaires recommand√©es")
            
            # Sauvegarde de la version am√©lior√©e
            logger.info("\nüíæ Pour sauvegarder d√©finitivement:")
            logger.info("   1. git add gpt_modules/")
            logger.info("   2. git commit -m 'feat: Algorithme s√©mantique V3.2'")
            logger.info("   3. git push origin feature/gpt-integration-v31")
            
        else:
            print("\n‚ùå MISE √Ä NIVEAU √âCHOU√âE")
            print("Objectif Charlotte DARMON non maintenu")
            print("R√©vision des param√®tres n√©cessaire")
    
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la mise √† niveau: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
