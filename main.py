"""
ğŸ¯ Nextvision - Main FastAPI Application avec PondÃ©ration Adaptative RÃ‰ELLE
Algorithme de matching IA adaptatif pour NEXTEN

Author: NEXTEN Team
Version: 1.0.0
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Dict, List, Optional
import uvicorn
import time
import logging

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="ğŸ¯ Nextvision API",
    description="""
    **Algorithme de matching IA adaptatif pour NEXTEN**
    
    ## ğŸ¯ Innovation: PondÃ©ration Adaptative Contextuelle
    
    L'algorithme ajuste automatiquement les poids selon le "pourquoi_ecoute" du candidat:
    
    * **"RÃ©munÃ©ration trop faible"** â†’ PrioritÃ© rÃ©munÃ©ration (30% +10%)
    * **"Poste ne coÃ¯ncide pas"** â†’ PrioritÃ© sÃ©mantique (45% +10%) 
    * **"Poste trop loin"** â†’ PrioritÃ© localisation (20% +10%)
    * **"Manque de flexibilitÃ©"** â†’ PrioritÃ© environnement (15% +10%)
    * **"Manque perspectives"** â†’ PrioritÃ© motivations (15% +10%)
    
    ## ğŸ”— IntÃ©gration avec Commitment-
    
    Cette API communique avec [Commitment-](https://github.com/Bapt252/Commitment-)
    """,
    version="1.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ğŸ—ï¸ ModÃ¨les Pydantic simplifiÃ©s

class PersonalInfo(BaseModel):
    firstName: str
    lastName: str
    email: str  # Validation email basique de pydantic
    phone: Optional[str] = None

class SalaryExpectations(BaseModel):
    min: int
    max: int
    current: Optional[int] = None

class LocationPreferences(BaseModel):
    city: str
    acceptedCities: Optional[List[str]] = []
    maxDistance: Optional[int] = 0

class CandidateProfile(BaseModel):
    personal_info: PersonalInfo
    skills: List[str]
    experience_years: int
    education: Optional[str] = ""
    current_role: Optional[str] = ""

class Preferences(BaseModel):
    salary_expectations: SalaryExpectations
    location_preferences: LocationPreferences
    remote_preferences: Optional[str] = ""
    sectors: Optional[List[str]] = []
    company_size: Optional[str] = ""

class MatchingRequest(BaseModel):
    pourquoi_ecoute: str  # ğŸ¯ CHAMP CLÃ‰ pour pondÃ©ration adaptative
    candidate_profile: CandidateProfile
    preferences: Preferences
    availability: Optional[str] = ""

# ğŸ¯ Configuration des poids adaptatifs
DEFAULT_WEIGHTS = {
    "semantique": 0.35,
    "remuneration": 0.20,
    "timing": 0.15,
    "localisation": 0.10,
    "secteurs": 0.10,
    "environnement": 0.05,
    "motivations": 0.05
}

ADAPTIVE_WEIGHTS_CONFIG = {
    "RÃ©munÃ©ration trop faible": {
        "remuneration": 0.30,  # +10%
        "semantique": 0.30,    # -5%
        "reasoning": "PrioritÃ© accordÃ©e Ã  l'amÃ©lioration salariale"
    },
    "Poste ne coÃ¯ncide pas avec poste proposÃ©": {
        "semantique": 0.45,    # +10%
        "remuneration": 0.15,  # -5%
        "reasoning": "Focus sur l'adÃ©quation des compÃ©tences et du poste"
    },
    "Poste trop loin de mon domicile": {
        "localisation": 0.20,  # +10%
        "semantique": 0.30,    # -5%
        "reasoning": "PrioritÃ© Ã  la proximitÃ© gÃ©ographique"
    },
    "Manque de flexibilitÃ©": {
        "environnement": 0.15, # +10%
        "motivations": 0.10,   # +5%
        "reasoning": "Recherche d'un meilleur Ã©quilibre vie pro/perso"
    },
    "Manque de perspectives d'Ã©volution": {
        "motivations": 0.15,   # +10%
        "semantique": 0.30,    # -5%
        "reasoning": "Focus sur les opportunitÃ©s de dÃ©veloppement"
    }
}

def get_adaptive_weights(pourquoi_ecoute: str) -> Dict:
    """
    ğŸ¯ COEUR DE L'INNOVATION: PondÃ©ration Adaptative Contextuelle
    
    Ajuste intelligemment les poids selon le contexte du candidat
    """
    base_weights = DEFAULT_WEIGHTS.copy()
    adaptation_applied = False
    reasoning = "PondÃ©ration standard appliquÃ©e"
    
    # Normalisation de la raison
    normalized_reason = pourquoi_ecoute.strip()
    
    logger.info(f"ğŸ¯ Analyse pondÃ©ration pour: '{normalized_reason}'")
    
    if normalized_reason in ADAPTIVE_WEIGHTS_CONFIG:
        adaptation = ADAPTIVE_WEIGHTS_CONFIG[normalized_reason]
        
        # Appliquer les adaptations spÃ©cifiques
        for component, new_weight in adaptation.items():
            if component != "reasoning":
                logger.info(f"   ğŸ“Š {component}: {base_weights[component]} â†’ {new_weight}")
                base_weights[component] = new_weight
        
        adaptation_applied = True
        reasoning = adaptation["reasoning"]
        
        logger.info(f"âœ… PondÃ©ration adaptative appliquÃ©e: {reasoning}")
    else:
        logger.info(f"âš ï¸ Raison non reconnue pour adaptation: '{normalized_reason}'")
        logger.info("ğŸ“Š PondÃ©ration standard utilisÃ©e")
    
    return {
        "weights": base_weights,
        "adaptation_applied": adaptation_applied,
        "reasoning": reasoning,
        "original_reason": pourquoi_ecoute
    }

def calculate_mock_matching_scores(request: MatchingRequest, weights: Dict) -> Dict:
    """ğŸ§® Calcul de scores de matching (simulÃ© pour dÃ©monstration)"""
    
    # Simulation basÃ©e sur les donnÃ©es du candidat
    skills_count = len(request.candidate_profile.skills)
    experience = request.candidate_profile.experience_years
    salary_min = request.preferences.salary_expectations.min
    
    # Scores simulÃ©s mais cohÃ©rents
    scores = {
        "semantique": min(0.9, 0.5 + (skills_count * 0.08) + (experience * 0.02)),
        "remuneration": min(0.95, 0.6 + (salary_min / 100000) * 0.3),
        "localisation": 0.75,
        "timing": 0.85,
        "secteurs": 0.70,
        "environnement": 0.65,
        "motivations": 0.80
    }
    
    # Score total pondÃ©rÃ©
    total_score = sum(scores[component] * weights[component] for component in scores.keys())
    
    return {
        "component_scores": scores,
        "total_score": round(total_score, 3),
        "confidence": round(min(0.95, total_score * 1.1), 3)
    }

def _calculate_weight_changes(adapted_weights: Dict) -> Dict:
    """ğŸ“Š Calcule les changements de poids"""
    changes = {}
    for component, adapted_weight in adapted_weights.items():
        default_weight = DEFAULT_WEIGHTS[component]
        change = adapted_weight - default_weight
        if abs(change) > 0.001:
            changes[component] = {
                "from": default_weight,
                "to": adapted_weight,
                "change": round(change, 3),
                "change_percent": round((change / default_weight) * 100, 1)
            }
    return changes

# ğŸŒ ENDPOINTS API

@app.get("/", tags=["Root"])
async def root():
    """ğŸ  Root endpoint"""
    return {
        "service": "Nextvision",
        "description": "Algorithme de matching IA adaptatif pour NEXTEN",
        "version": "1.0.0",
        "status": "active",
        "innovation": "PondÃ©ration Adaptative Contextuelle",
        "frontend_integration": "https://github.com/Bapt252/Commitment-",
        "docs": "/docs",
        "health": "/api/v1/health",
        "adaptive_reasons_supported": list(ADAPTIVE_WEIGHTS_CONFIG.keys())
    }

@app.get("/api/v1/health", tags=["Health"])
async def health_check():
    """â¤ï¸ Health Check"""
    return {
        "status": "healthy",
        "service": "Nextvision",
        "version": "1.0.0",
        "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ"),
        "environment": "development",
        "features": {
            "adaptive_weighting": True,
            "semantic_matching": True,
            "real_time_processing": True
        }
    }

@app.post("/api/v1/matching/candidate/{candidate_id}", tags=["ğŸ¯ Matching"])
async def match_candidate(candidate_id: str, request: MatchingRequest):
    """ğŸ¯ ENDPOINT PRINCIPAL: Matching avec PondÃ©ration Adaptative"""
    start_time = time.time()
    
    logger.info(f"ğŸ¯ === MATCHING CANDIDAT {candidate_id} ===")
    logger.info(f"ğŸ“‹ Raison d'Ã©coute: '{request.pourquoi_ecoute}'")
    logger.info(f"ğŸ‘¤ Candidat: {request.candidate_profile.personal_info.firstName} {request.candidate_profile.personal_info.lastName}")
    logger.info(f"ğŸ’¼ CompÃ©tences: {request.candidate_profile.skills}")
    logger.info(f"ğŸ’° Attentes: {request.preferences.salary_expectations.min}â‚¬ - {request.preferences.salary_expectations.max}â‚¬")
    
    try:
        # 1. ğŸ¯ PondÃ©ration adaptative
        weight_analysis = get_adaptive_weights(request.pourquoi_ecoute)
        weights = weight_analysis["weights"]
        
        # 2. ğŸ§® Calcul des scores
        matching_analysis = calculate_mock_matching_scores(request, weights)
        
        # 3. ğŸ“Š RÃ©ponse dÃ©taillÃ©e
        processing_time = round((time.time() - start_time) * 1000, 2)
        
        response = {
            "status": "success",
            "candidate_id": candidate_id,
            "matching_results": {
                "total_score": matching_analysis["total_score"],
                "confidence": matching_analysis["confidence"],
                "component_scores": matching_analysis["component_scores"],
                "weights_used": weights
            },
            "adaptive_weighting": {
                "applied": weight_analysis["adaptation_applied"],
                "reason": request.pourquoi_ecoute,
                "reasoning": weight_analysis["reasoning"],
                "weight_changes": _calculate_weight_changes(weights) if weight_analysis["adaptation_applied"] else None
            },
            "candidate_summary": {
                "name": f"{request.candidate_profile.personal_info.firstName} {request.candidate_profile.personal_info.lastName}",
                "skills_count": len(request.candidate_profile.skills),
                "experience_years": request.candidate_profile.experience_years,
                "salary_range": f"{request.preferences.salary_expectations.min}â‚¬ - {request.preferences.salary_expectations.max}â‚¬"
            },
            "metadata": {
                "processing_time_ms": processing_time,
                "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ"),
                "api_version": "1.0.0",
                "algorithm": "Adaptive Contextual Weighting"
            }
        }
        
        logger.info(f"âœ… Matching terminÃ© en {processing_time}ms")
        logger.info(f"ğŸ“Š Score final: {matching_analysis['total_score']} (confiance: {matching_analysis['confidence']})")
        
        return response
        
    except Exception as e:
        logger.error(f"âŒ Erreur matching: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur: {str(e)}")

@app.get("/api/v1/weights/preview", tags=["ğŸ¯ Matching"])
async def preview_adaptive_weights(pourquoi_ecoute: str):
    """ğŸ” PrÃ©visualisation des Poids Adaptatifs"""
    weight_analysis = get_adaptive_weights(pourquoi_ecoute)
    
    return {
        "reason": pourquoi_ecoute,
        "default_weights": DEFAULT_WEIGHTS,
        "adapted_weights": weight_analysis["weights"],
        "adaptation_applied": weight_analysis["adaptation_applied"],
        "reasoning": weight_analysis["reasoning"],
        "weight_changes": _calculate_weight_changes(weight_analysis["weights"]) if weight_analysis["adaptation_applied"] else None,
        "supported_reasons": list(ADAPTIVE_WEIGHTS_CONFIG.keys())
    }

@app.get("/api/v1/debug/supported-reasons", tags=["ğŸ”§ Debug"])
async def get_supported_reasons():
    """ğŸ”§ Liste des raisons supportÃ©es"""
    return {
        "supported_reasons": list(ADAPTIVE_WEIGHTS_CONFIG.keys()),
        "default_weights": DEFAULT_WEIGHTS,
        "adaptive_configs": ADAPTIVE_WEIGHTS_CONFIG
    }

if __name__ == "__main__":
    print("ğŸ¯ === NEXTVISION API STARTUP ===")
    print("ğŸš€ Algorithme de matching IA adaptatif pour NEXTEN")
    print("ğŸ“š Documentation: http://localhost:8000/docs")
    print("â¤ï¸ Health Check: http://localhost:8000/api/v1/health")
    print("ğŸ” Preview Weights: http://localhost:8000/api/v1/weights/preview")
    print("ğŸ¯ PondÃ©ration Adaptative: ACTIVE")
    print("ğŸ”— Frontend Integration: Commitment- â†’ Nextvision")
    print("=======================================")
    
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)
