"""
üéØ Nextvision - Main FastAPI Application avec Google Maps Intelligence
Algorithme de matching IA adaptatif pour NEXTEN + Bridge Commitment- + Intelligence G√©ospatiale

Author: NEXTEN Team
Version: 2.0.0 (Prompt 2 - Google Maps Intelligence)
"""

from fastapi import FastAPI, HTTPException, UploadFile, File, Form, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
from typing import Dict, List, Optional, Union
import uvicorn
import time
import logging
import tempfile
import os
import shutil
from datetime import datetime

# Import du service bridge existant
from nextvision.services.commitment_bridge import (
    CommitmentNextvisionBridge, 
    BridgeRequest,
    BridgeConfig
)

# üó∫Ô∏è NOUVEAUX IMPORTS GOOGLE MAPS INTELLIGENCE (Prompt 2)
from nextvision.models.transport_models import (
    GoogleMapsMode, TransportConstraint, CandidatTransportProfile,
    JobTransportInfo, create_default_candidat_profile
)
from nextvision.services.google_maps_service import get_google_maps_service
from nextvision.services.transport_calculator import TransportCalculatorService
from nextvision.engines.transport_filtering import TransportFilteringEngine, quick_filter_jobs
from nextvision.engines.location_scoring import enhance_location_component_score, get_location_zone_recommendation
from nextvision.utils.google_maps_helpers import (
    get_global_cache, get_global_performance_monitor, batch_geocode_addresses,
    optimize_transport_calculations
)
from nextvision.config import get_config, validate_production_config

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="üéØ Nextvision API with Google Maps Intelligence",
    description="""
    **Algorithme de matching IA adaptatif pour NEXTEN avec Intelligence G√©ospatiale**
    
    ## üéØ Innovation: Pond√©ration Adaptative Contextuelle
    
    L'algorithme ajuste automatiquement les poids selon le "pourquoi_ecoute" du candidat:
    
    * **"R√©mun√©ration trop faible"** ‚Üí Priorit√© r√©mun√©ration (30% +10%)
    * **"Poste ne co√Øncide pas"** ‚Üí Priorit√© s√©mantique (45% +10%) 
    * **"Poste trop loin"** ‚Üí Priorit√© localisation (20% +10%) **üÜï + Intelligence Google Maps**
    * **"Manque de flexibilit√©"** ‚Üí Priorit√© environnement (15% +10%)
    * **"Manque perspectives"** ‚Üí Priorit√© motivations (15% +10%)
    
    ## üó∫Ô∏è NOUVEAUT√â: Google Maps Intelligence (Prompt 2)
    
    **Intelligence Transport G√©ospatiale R√©volutionnaire:**
    
    * **Pr√©-filtering automatique** : Exclusion jobs incompatibles AVANT pond√©ration (20-40% CPU gain)
    * **Multi-modal intelligent** : Voiture, transport public, v√©lo, marche avec contraintes
    * **Heures de pointe** : Ajustement temps trajets selon circulation r√©elle
    * **Score localisation enrichi** : Distance + temps + qualit√© + co√ªt + flexibilit√©
    * **Cache intelligent** : Redis + fallback optimis√© pour performance
    * **Analyse g√©ospatiale** : Zones optimales, suggestions transport, explications d√©taill√©es
    
    ## üåâ Int√©gration Bridge avec Commitment-
    
    **Bridge z√©ro redondance** avec [Commitment-](https://github.com/Bapt252/Commitment-):
    
    * **Job Parser GPT** : Infrastructure mature existante
    * **CV Parser GPT** : Connexion directe services op√©rationnels  
    * **Workflow complet** : Parse ‚Üí Pre-filter ‚Üí Match en une requ√™te
    * **Architecture optimale** : Aucune duplication de code
    """,
    version="2.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# üèóÔ∏è Mod√®les Pydantic existants (conserv√©s)

class PersonalInfo(BaseModel):
    firstName: str
    lastName: str
    email: str
    phone: Optional[str] = None

class SalaryExpectations(BaseModel):
    min: int
    max: int
    current: Optional[int] = None

class LocationPreferences(BaseModel):
    city: str
    acceptedCities: Optional[List[str]] = []
    maxDistance: Optional[int] = 0

class CandidateProfile(BaseModel):
    personal_info: PersonalInfo
    skills: List[str]
    experience_years: int
    education: Optional[str] = ""
    current_role: Optional[str] = ""

class Preferences(BaseModel):
    salary_expectations: SalaryExpectations
    location_preferences: LocationPreferences
    remote_preferences: Optional[str] = ""
    sectors: Optional[List[str]] = []
    company_size: Optional[str] = ""

class MatchingRequest(BaseModel):
    pourquoi_ecoute: str  # üéØ CHAMP CL√â pour pond√©ration adaptative
    candidate_profile: CandidateProfile
    preferences: Preferences
    availability: Optional[str] = ""

# üó∫Ô∏è NOUVEAUX MOD√àLES GOOGLE MAPS INTELLIGENCE

class TransportConstraintRequest(BaseModel):
    """üöó Contrainte de transport pour API"""
    mode: str = Field(description="Mode: driving, transit, walking, bicycling")
    max_duration_minutes: int = Field(gt=0, description="Dur√©e max en minutes")
    max_duration_peak_minutes: Optional[int] = Field(None, description="Dur√©e max heures pointe")
    max_transfers: Optional[int] = Field(None, description="Correspondances max (transit)")
    tolerance_minutes: int = Field(default=5, description="Tol√©rance en minutes")

class TransportFilteringRequest(BaseModel):
    """üö´ Requ√™te de pr√©-filtering transport"""
    candidat_address: str = Field(description="Adresse domicile candidat")
    transport_constraints: List[TransportConstraintRequest] = Field(description="Contraintes transport")
    jobs: List[Dict] = Field(description="Liste des jobs √† filtrer")
    quick_mode: bool = Field(default=True, description="Mode rapide (pr√©-screening)")
    candidat_id: Optional[str] = Field(None, description="ID candidat")

class LocationScoringRequest(BaseModel):
    """üéØ Requ√™te de scoring localisation enrichi"""
    candidat_address: str
    job_address: str
    transport_constraints: List[TransportConstraintRequest]
    original_location_score: float = Field(ge=0.0, le=1.0)
    pourquoi_ecoute: str
    remote_work_days: int = Field(default=0, ge=0, le=5)
    flexible_hours: bool = Field(default=False)

# üéØ Configuration des poids adaptatifs (conserv√©e et enrichie)
DEFAULT_WEIGHTS = {
    "semantique": 0.35,
    "remuneration": 0.20,
    "timing": 0.15,
    "localisation": 0.10,  # üÜï Sera enrichi par Google Maps Intelligence
    "secteurs": 0.10,
    "environnement": 0.05,
    "motivations": 0.05
}

ADAPTIVE_WEIGHTS_CONFIG = {
    "R√©mun√©ration trop faible": {
        "remuneration": 0.30,  # +10%
        "semantique": 0.30,    # -5%
        "reasoning": "Priorit√© accord√©e √† l'am√©lioration salariale"
    },
    "Poste ne co√Øncide pas avec poste propos√©": {
        "semantique": 0.45,    # +10%
        "remuneration": 0.15,  # -5%
        "reasoning": "Focus sur l'ad√©quation des comp√©tences et du poste"
    },
    "Poste trop loin de mon domicile": {
        "localisation": 0.20,  # +10% üÜï + Intelligence Google Maps
        "semantique": 0.30,    # -5%
        "reasoning": "Priorit√© √† la proximit√© g√©ographique avec analyse g√©ospatiale"
    },
    "Manque de flexibilit√©": {
        "environnement": 0.15, # +10%
        "motivations": 0.10,   # +5%
        "reasoning": "Recherche d'un meilleur √©quilibre vie pro/perso"
    },
    "Manque de perspectives d'√©volution": {
        "motivations": 0.15,   # +10%
        "semantique": 0.30,    # -5%
        "reasoning": "Focus sur les opportunit√©s de d√©veloppement"
    }
}

def get_adaptive_weights(pourquoi_ecoute: str) -> Dict:
    """
    üéØ COEUR DE L'INNOVATION: Pond√©ration Adaptative Contextuelle
    
    Ajuste intelligemment les poids selon le contexte du candidat
    """
    base_weights = DEFAULT_WEIGHTS.copy()
    adaptation_applied = False
    reasoning = "Pond√©ration standard appliqu√©e"
    
    # Normalisation de la raison
    normalized_reason = pourquoi_ecoute.strip()
    
    logger.info(f"üéØ Analyse pond√©ration pour: '{normalized_reason}'")
    
    if normalized_reason in ADAPTIVE_WEIGHTS_CONFIG:
        adaptation = ADAPTIVE_WEIGHTS_CONFIG[normalized_reason]
        
        # Appliquer les adaptations sp√©cifiques
        for component, new_weight in adaptation.items():
            if component != "reasoning":
                logger.info(f"   üìä {component}: {base_weights[component]} ‚Üí {new_weight}")
                base_weights[component] = new_weight
        
        adaptation_applied = True
        reasoning = adaptation["reasoning"]
        
        logger.info(f"‚úÖ Pond√©ration adaptative appliqu√©e: {reasoning}")
    else:
        logger.info(f"‚ö†Ô∏è Raison non reconnue pour adaptation: '{normalized_reason}'")
        logger.info("üìä Pond√©ration standard utilis√©e")
    
    return {
        "weights": base_weights,
        "adaptation_applied": adaptation_applied,
        "reasoning": reasoning,
        "original_reason": pourquoi_ecoute
    }

def calculate_mock_matching_scores(request: MatchingRequest, weights: Dict) -> Dict:
    """üßÆ Calcul de scores de matching (simul√© pour d√©monstration)"""
    
    # Simulation bas√©e sur les donn√©es du candidat
    skills_count = len(request.candidate_profile.skills)
    experience = request.candidate_profile.experience_years
    salary_min = request.preferences.salary_expectations.min
    
    # Scores simul√©s mais coh√©rents
    scores = {
        "semantique": min(0.9, 0.5 + (skills_count * 0.08) + (experience * 0.02)),
        "remuneration": min(0.95, 0.6 + (salary_min / 100000) * 0.3),
        "localisation": 0.75,  # üÜï Sera enrichi par Google Maps Intelligence
        "timing": 0.85,
        "secteurs": 0.70,
        "environnement": 0.65,
        "motivations": 0.80
    }
    
    # Score total pond√©r√©
    total_score = sum(scores[component] * weights[component] for component in scores.keys())
    
    return {
        "component_scores": scores,
        "total_score": round(total_score, 3),
        "confidence": round(min(0.95, total_score * 1.1), 3)
    }

def _calculate_weight_changes(adapted_weights: Dict) -> Dict:
    """üìä Calcule les changements de poids"""
    changes = {}
    for component, adapted_weight in adapted_weights.items():
        default_weight = DEFAULT_WEIGHTS[component]
        change = adapted_weight - default_weight
        if abs(change) > 0.001:
            changes[component] = {
                "from": default_weight,
                "to": adapted_weight,
                "change": round(change, 3),
                "change_percent": round((change / default_weight) * 100, 1)
            }
    return changes

# üåê ENDPOINTS API ORIGINAUX (conserv√©s)

@app.get("/", tags=["Root"])
async def root():
    """üè† Root endpoint enrichi avec Google Maps Intelligence"""
    config = get_config()
    config_issues = validate_production_config(config)
    
    return {
        "service": "Nextvision",
        "description": "Algorithme de matching IA adaptatif pour NEXTEN avec Google Maps Intelligence",
        "version": "2.0.0",
        "status": "active",
        "innovation": "Pond√©ration Adaptative Contextuelle + Intelligence G√©ospatiale",
        "new_features": {
            "google_maps_intelligence": True,
            "transport_pre_filtering": True,
            "enhanced_location_scoring": True,
            "multi_modal_analysis": True,
            "intelligent_caching": True
        },
        "frontend_integration": "https://github.com/Bapt252/Commitment-",
        "bridge_integration": "Commitment- ‚Üí Nextvision",
        "docs": "/docs",
        "health": "/api/v1/health",
        "google_maps_health": "/api/v2/transport/health",
        "integration_health": "/api/v1/integration/health",
        "adaptive_reasons_supported": list(ADAPTIVE_WEIGHTS_CONFIG.keys()),
        "config_status": "healthy" if not config_issues else "warnings",
        "config_issues": config_issues
    }

@app.get("/api/v1/health", tags=["Health"])
async def health_check():
    """‚ù§Ô∏è Health Check enrichi"""
    return {
        "status": "healthy",
        "service": "Nextvision",
        "version": "2.0.0",
        "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ"),
        "environment": get_config().environment.value,
        "features": {
            "adaptive_weighting": True,
            "semantic_matching": True,
            "real_time_processing": True,
            "bridge_integration": True,
            "google_maps_intelligence": True,
            "transport_pre_filtering": True,
            "enhanced_location_scoring": True
        }
    }

@app.post("/api/v1/matching/candidate/{candidate_id}", tags=["üéØ Matching"])
async def match_candidate(candidate_id: str, request: MatchingRequest):
    """üéØ ENDPOINT PRINCIPAL: Matching avec Pond√©ration Adaptative (conserv√©)"""
    start_time = time.time()
    
    logger.info(f"üéØ === MATCHING CANDIDAT {candidate_id} ===")
    logger.info(f"üìã Raison d'√©coute: '{request.pourquoi_ecoute}'")
    logger.info(f"üë§ Candidat: {request.candidate_profile.personal_info.firstName} {request.candidate_profile.personal_info.lastName}")
    logger.info(f"üíº Comp√©tences: {request.candidate_profile.skills}")
    logger.info(f"üí∞ Attentes: {request.preferences.salary_expectations.min}‚Ç¨ - {request.preferences.salary_expectations.max}‚Ç¨")
    
    try:
        # 1. üéØ Pond√©ration adaptative
        weight_analysis = get_adaptive_weights(request.pourquoi_ecoute)
        weights = weight_analysis["weights"]
        
        # 2. üßÆ Calcul des scores
        matching_analysis = calculate_mock_matching_scores(request, weights)
        
        # 3. üìä R√©ponse d√©taill√©e
        processing_time = round((time.time() - start_time) * 1000, 2)
        
        response = {
            "status": "success",
            "candidate_id": candidate_id,
            "matching_results": {
                "total_score": matching_analysis["total_score"],
                "confidence": matching_analysis["confidence"],
                "component_scores": matching_analysis["component_scores"],
                "weights_used": weights
            },
            "adaptive_weighting": {
                "applied": weight_analysis["adaptation_applied"],
                "reason": request.pourquoi_ecoute,
                "reasoning": weight_analysis["reasoning"],
                "weight_changes": _calculate_weight_changes(weights) if weight_analysis["adaptation_applied"] else None
            },
            "candidate_summary": {
                "name": f"{request.candidate_profile.personal_info.firstName} {request.candidate_profile.personal_info.lastName}",
                "skills_count": len(request.candidate_profile.skills),
                "experience_years": request.candidate_profile.experience_years,
                "salary_range": f"{request.preferences.salary_expectations.min}‚Ç¨ - {request.preferences.salary_expectations.max}‚Ç¨"
            },
            "metadata": {
                "processing_time_ms": processing_time,
                "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ"),
                "api_version": "2.0.0",
                "algorithm": "Adaptive Contextual Weighting",
                "google_maps_intelligence": "available"
            }
        }
        
        logger.info(f"‚úÖ Matching termin√© en {processing_time}ms")
        logger.info(f"üìä Score final: {matching_analysis['total_score']} (confiance: {matching_analysis['confidence']})")
        
        return response
        
    except Exception as e:
        logger.error(f"‚ùå Erreur matching: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur: {str(e)}")

@app.get("/api/v1/weights/preview", tags=["üéØ Matching"])
async def preview_adaptive_weights(pourquoi_ecoute: str):
    """üîç Pr√©visualisation des Poids Adaptatifs (conserv√©e)"""
    weight_analysis = get_adaptive_weights(pourquoi_ecoute)
    
    return {
        "reason": pourquoi_ecoute,
        "default_weights": DEFAULT_WEIGHTS,
        "adapted_weights": weight_analysis["weights"],
        "adaptation_applied": weight_analysis["adaptation_applied"],
        "reasoning": weight_analysis["reasoning"],
        "weight_changes": _calculate_weight_changes(weight_analysis["weights"]) if weight_analysis["adaptation_applied"] else None,
        "supported_reasons": list(ADAPTIVE_WEIGHTS_CONFIG.keys()),
        "google_maps_enhanced": weight_analysis["weights"]["localisation"] > DEFAULT_WEIGHTS["localisation"]
    }

# üó∫Ô∏è NOUVEAUX ENDPOINTS GOOGLE MAPS INTELLIGENCE (Prompt 2)

@app.get("/api/v2/transport/health", tags=["üó∫Ô∏è Google Maps Intelligence"])
async def google_maps_health_check():
    """üó∫Ô∏è Health Check Google Maps Intelligence"""
    try:
        gmaps_service = await get_google_maps_service()
        health_status = await gmaps_service.health_check()
        
        cache = await get_global_cache()
        cache_stats = cache.get_stats()
        
        performance_monitor = await get_global_performance_monitor()
        perf_summary = performance_monitor.get_performance_summary(minutes=60)
        
        config = get_config()
        
        return {
            "status": health_status["status"],
            "google_maps_service": health_status,
            "cache_performance": cache_stats,
            "performance_summary": perf_summary,
            "configuration": {
                "environment": config.environment.value,
                "cache_backend": config.cache.backend.value,
                "rate_limit_rps": config.google_maps.requests_per_second,
                "fallback_enabled": config.fallback.enable_fallback
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur Google Maps health check: {e}")
        return JSONResponse(
            status_code=503,
            content={
                "status": "unhealthy",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
        )

@app.post("/api/v2/transport/filter-jobs", tags=["üó∫Ô∏è Google Maps Intelligence"])
async def transport_filter_jobs(request: TransportFilteringRequest):
    """üö´ Pr√©-filtering transport automatique des jobs"""
    
    start_time = time.time()
    logger.info(f"üö´ D√©marrage pr√©-filtering: {len(request.jobs)} jobs pour {request.candidat_address}")
    
    try:
        # Conversion des contraintes
        transport_constraints = []
        for constraint_req in request.transport_constraints:
            constraint = TransportConstraint(
                mode=GoogleMapsMode(constraint_req.mode),
                max_duration_minutes=constraint_req.max_duration_minutes,
                max_duration_peak_minutes=constraint_req.max_duration_peak_minutes,
                max_transfers=constraint_req.max_transfers,
                tolerance_minutes=constraint_req.tolerance_minutes
            )
            transport_constraints.append(constraint)
        
        # Cr√©ation profil candidat
        candidat_profile = CandidatTransportProfile(
            candidat_id=request.candidat_id or "api_request",
            home_address=request.candidat_address,
            constraints=transport_constraints
        )
        
        # Ex√©cution du filtering
        async with TransportFilteringEngine() as filtering_engine:
            jobs_included, jobs_excluded, report = await filtering_engine.filter_jobs_batch(
                candidat_profile=candidat_profile,
                jobs=request.jobs,
                quick_mode=request.quick_mode,
                max_concurrent=10
            )
        
        processing_time = (time.time() - start_time) * 1000
        
        response = {
            "status": "success",
            "filtering_results": {
                "jobs_included": jobs_included,
                "jobs_excluded": jobs_excluded,
                "inclusion_count": len(jobs_included),
                "exclusion_count": len(jobs_excluded),
                "exclusion_rate": len(jobs_excluded) / len(request.jobs) if request.jobs else 0
            },
            "performance_gains": {
                "cpu_time_saved_ms": report.cpu_time_saved_ms,
                "jobs_excluded_before_matching": len(jobs_excluded),
                "performance_improvement": f"{report.exclusion_rate:.1%} less CPU usage"
            },
            "filtering_report": report.dict(),
            "metadata": {
                "processing_time_ms": processing_time,
                "mode": "quick" if request.quick_mode else "detailed",
                "timestamp": datetime.now().isoformat(),
                "total_jobs_processed": len(request.jobs)
            }
        }
        
        logger.info(f"‚úÖ Pr√©-filtering termin√©: {len(jobs_included)} inclus, {len(jobs_excluded)} exclus en {processing_time:.1f}ms")
        
        return response
        
    except Exception as e:
        logger.error(f"‚ùå Erreur pr√©-filtering transport: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur filtering: {str(e)}")

@app.post("/api/v2/transport/location-scoring", tags=["üó∫Ô∏è Google Maps Intelligence"])
async def enhanced_location_scoring(request: LocationScoringRequest):
    """üéØ Scoring de localisation enrichi avec Google Maps Intelligence"""
    
    start_time = time.time()
    logger.info(f"üéØ Scoring localisation enrichi: {request.candidat_address} ‚Üí {request.job_address}")
    
    try:
        # Conversion des contraintes
        transport_constraints = []
        for constraint_req in request.transport_constraints:
            constraint = TransportConstraint(
                mode=GoogleMapsMode(constraint_req.mode),
                max_duration_minutes=constraint_req.max_duration_minutes,
                max_duration_peak_minutes=constraint_req.max_duration_peak_minutes,
                max_transfers=constraint_req.max_transfers,
                tolerance_minutes=constraint_req.tolerance_minutes
            )
            transport_constraints.append(constraint)
        
        # Cr√©ation des profils
        candidat_profile = CandidatTransportProfile(
            candidat_id="location_scoring",
            home_address=request.candidat_address,
            constraints=transport_constraints,
            accepts_remote_work=request.remote_work_days > 0,
            remote_days_per_week=request.remote_work_days,
            flexible_hours=request.flexible_hours
        )
        
        job_info = JobTransportInfo(
            job_id="location_scoring_job",
            office_address=request.job_address,
            remote_policy="hybrid" if request.remote_work_days > 0 else "none",
            flexible_hours=request.flexible_hours
        )
        
        # Calcul transport (simul√© pour la d√©mo - en production utiliser TransportCalculatorService)
        async with TransportCalculatorService() as calculator:
            transport_result = await calculator.calculate_multi_modal_options(
                candidat_profile=candidat_profile,
                job_info=job_info
            )
        
        # Scoring enrichi
        final_score, metadata = enhance_location_component_score(
            candidat_profile=candidat_profile,
            job_info=job_info,
            transport_result=transport_result,
            original_score=request.original_location_score,
            pourquoi_ecoute=request.pourquoi_ecoute
        )
        
        # Recommandations g√©ospatiales
        zone_recommendation = get_location_zone_recommendation(transport_result)
        
        processing_time = (time.time() - start_time) * 1000
        
        response = {
            "status": "success",
            "location_scoring": {
                "original_score": request.original_location_score,
                "enhanced_score": metadata["enhanced_scoring"]["enhanced_score"],
                "final_score": final_score,
                "improvement": final_score - request.original_location_score
            },
            "transport_analysis": {
                "is_compatible": transport_result.is_transport_compatible,
                "best_mode": transport_result.best_transport_mode.value if transport_result.best_transport_mode else None,
                "overall_transport_score": transport_result.overall_transport_score,
                "viable_modes": len([a for a in transport_result.transport_analyses if a.is_viable]),
                "recommended_modes": [mode.value for mode in transport_result.recommended_modes]
            },
            "geospatial_insights": zone_recommendation,
            "adaptive_integration": {
                "reason": request.pourquoi_ecoute,
                "weighting_applied": metadata["integration"]["adaptation_reason"] == request.pourquoi_ecoute,
                "enhancement_impact": metadata["integration"]["enhancement_impact"]
            },
            "detailed_metadata": metadata,
            "performance": {
                "processing_time_ms": processing_time,
                "google_maps_requests": transport_result.google_maps_requests,
                "cache_efficiency": "enabled"
            },
            "timestamp": datetime.now().isoformat()
        }
        
        logger.info(f"üéØ Location scoring enrichi: {request.original_location_score:.3f} ‚Üí {final_score:.3f} (+{final_score-request.original_location_score:.3f})")
        
        return response
        
    except Exception as e:
        logger.error(f"‚ùå Erreur location scoring enrichi: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur scoring: {str(e)}")

@app.post("/api/v2/transport/geocode-batch", tags=["üó∫Ô∏è Google Maps Intelligence"])
async def batch_geocode(addresses: List[str]):
    """üó∫Ô∏è G√©ocodage en batch avec cache intelligent"""
    
    start_time = time.time()
    logger.info(f"üó∫Ô∏è G√©ocodage batch: {len(addresses)} adresses")
    
    try:
        cache = await get_global_cache()
        results = await batch_geocode_addresses(addresses, cache)
        
        processing_time = (time.time() - start_time) * 1000
        
        successful_geocodes = len([r for addr, r in results if r is not None])
        success_rate = successful_geocodes / len(addresses) if addresses else 0
        
        response = {
            "status": "success",
            "geocoding_results": [
                {
                    "address": addr,
                    "geocoded": result.dict() if result else None,
                    "success": result is not None
                }
                for addr, result in results
            ],
            "summary": {
                "total_addresses": len(addresses),
                "successful_geocodes": successful_geocodes,
                "success_rate": success_rate,
                "failed_geocodes": len(addresses) - successful_geocodes
            },
            "performance": {
                "processing_time_ms": processing_time,
                "avg_time_per_address": processing_time / len(addresses) if addresses else 0,
                "cache_efficiency": "optimized"
            },
            "timestamp": datetime.now().isoformat()
        }
        
        logger.info(f"üó∫Ô∏è Batch geocoding termin√©: {successful_geocodes}/{len(addresses)} succ√®s en {processing_time:.1f}ms")
        
        return response
        
    except Exception as e:
        logger.error(f"‚ùå Erreur batch geocoding: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur g√©ocodage: {str(e)}")

@app.get("/api/v2/transport/performance-metrics", tags=["üó∫Ô∏è Google Maps Intelligence"])
async def get_performance_metrics(minutes: int = Query(default=60, ge=1, le=1440)):
    """üìä M√©triques de performance Google Maps Intelligence"""
    
    try:
        performance_monitor = await get_global_performance_monitor()
        cache = await get_global_cache()
        gmaps_service = await get_google_maps_service()
        
        # R√©cup√©ration des m√©triques
        perf_summary = performance_monitor.get_performance_summary(minutes=minutes)
        cache_stats = cache.get_stats()
        gmaps_metrics = gmaps_service.get_metrics()
        
        response = {
            "status": "success",
            "time_period_minutes": minutes,
            "performance_overview": {
                "total_operations": perf_summary["total_operations"],
                "success_rate": perf_summary["success_rate"],
                "avg_response_time_ms": perf_summary["avg_duration_ms"],
                "google_maps_calls": perf_summary["google_maps_calls"],
                "cache_hit_rate": perf_summary["cache_hit_rate"]
            },
            "cache_performance": cache_stats,
            "google_maps_metrics": gmaps_metrics,
            "detailed_performance": perf_summary,
            "alerts": {
                "slow_operations": perf_summary["alerts"]["slow_operations"],
                "failed_operations": perf_summary["alerts"]["failed_operations"],
                "performance_status": "healthy" if perf_summary["success_rate"] > 0.9 else "degraded"
            },
            "timestamp": datetime.now().isoformat()
        }
        
        return response
        
    except Exception as e:
        logger.error(f"‚ùå Erreur r√©cup√©ration m√©triques: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur m√©triques: {str(e)}")

@app.post("/api/v2/transport/optimize-calculations", tags=["üó∫Ô∏è Google Maps Intelligence"])
async def optimize_transport_calculations_endpoint(
    candidat_addresses: List[str],
    job_addresses: List[str]
):
    """‚ö° Optimisation globale des calculs transport avec pr√©-g√©ocodage"""
    
    start_time = time.time()
    logger.info(f"‚ö° Optimisation transport: {len(candidat_addresses)} candidats √ó {len(job_addresses)} jobs")
    
    try:
        # Simulation de profils pour la d√©mo
        candidat_profiles = []
        for i, addr in enumerate(candidat_addresses):
            profile = create_default_candidat_profile(
                candidat_id=f"candidat_{i}",
                home_address=addr
            )
            candidat_profiles.append(profile)
        
        jobs = []
        for i, addr in enumerate(job_addresses):
            jobs.append({
                "id": f"job_{i}",
                "office_address": addr,
                "title": f"Poste {i+1}"
            })
        
        # Optimisation
        cache = await get_global_cache()
        optimization_result = await optimize_transport_calculations(
            candidat_profiles=candidat_profiles,
            jobs=jobs,
            cache=cache
        )
        
        processing_time = (time.time() - start_time) * 1000
        
        response = {
            "status": "success",
            "optimization_summary": {
                "total_combinations": len(candidat_addresses) * len(job_addresses),
                "unique_addresses": len(set(candidat_addresses + job_addresses)),
                "geocoded_addresses": optimization_result["stats"]["geocoded_addresses"],
                "geocoding_success_rate": optimization_result["stats"]["geocoding_success_rate"]
            },
            "performance_gains": {
                "geocoding_time_ms": optimization_result["stats"]["processing_time_ms"],
                "addresses_cached": optimization_result["stats"]["geocoded_addresses"],
                "estimated_time_saved": f"{optimization_result['stats']['geocoded_addresses'] * 100}ms per subsequent calculation"
            },
            "geocoded_index_sample": {
                addr: result.dict() if result else None
                for addr, result in list(optimization_result["geocode_index"].items())[:5]
            },
            "metadata": {
                "processing_time_ms": processing_time,
                "cache_optimization": "enabled",
                "timestamp": datetime.now().isoformat()
            }
        }
        
        logger.info(f"‚ö° Optimisation termin√©e: {optimization_result['stats']['geocoded_addresses']} adresses g√©ocod√©es en {processing_time:.1f}ms")
        
        return response
        
    except Exception as e:
        logger.error(f"‚ùå Erreur optimisation transport: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur optimisation: {str(e)}")

# ===== üåâ ENDPOINTS D'INT√âGRATION BRIDGE (conserv√©s) =====

@app.post("/api/v1/integration/complete-workflow", tags=["üåâ Integration"])
async def complete_workflow_integration(
    pourquoi_ecoute: str = Form(...),
    job_file: Optional[UploadFile] = File(None),
    job_text: Optional[str] = Form(None),
    cv_file: Optional[UploadFile] = File(None),
    force_refresh: bool = Form(False)
):
    """
    üåâ WORKFLOW COMPLET NEXTEN: Job Parsing + CV Parsing + Matching Adaptatif + Google Maps Intelligence
    
    Workflow enrichi qui inclut maintenant:
    1. Parse l'offre d'emploi avec Commitment- Job Parser GPT
    2. Parse le CV avec Commitment- CV Parser GPT  
    3. üÜï Pr√©-filtering transport automatique (si adresses disponibles)
    4. Applique l'algorithme de matching avec pond√©ration adaptative
    5. üÜï Enrichissement score localisation avec Google Maps Intelligence
    
    **Innovation Prompt 2:** Intelligence g√©ospatiale int√©gr√©e dans le workflow complet
    """
    start_time = time.time()
    
    logger.info("üåâ === WORKFLOW COMPLET NEXTEN + GOOGLE MAPS INTELLIGENCE ===")
    logger.info(f"üìã Raison d'√©coute: '{pourquoi_ecoute}'")
    
    # Validation des param√®tres
    if not job_file and not job_text and not cv_file:
        raise HTTPException(
            status_code=400, 
            detail="Au moins un des param√®tres job_file, job_text ou cv_file doit √™tre fourni"
        )
    
    try:
        # [Conserv√©] Pr√©paration des fichiers temporaires
        job_file_data = None
        cv_file_data = None
        temp_files = []
        
        if job_file:
            job_temp = tempfile.NamedTemporaryFile(delete=False, suffix=f".{job_file.filename.split('.')[-1]}")
            shutil.copyfileobj(job_file.file, job_temp)
            job_temp.close()
            temp_files.append(job_temp.name)
            
            with open(job_temp.name, 'rb') as f:
                job_file_data = f.read()
        
        if cv_file:
            cv_temp = tempfile.NamedTemporaryFile(delete=False, suffix=f".{cv_file.filename.split('.')[-1]}")
            shutil.copyfileobj(cv_file.file, cv_temp)
            cv_temp.close()
            temp_files.append(cv_temp.name)
            
            with open(cv_temp.name, 'rb') as f:
                cv_file_data = f.read()
        
        # [Conserv√©] Cr√©ation de la requ√™te bridge
        bridge_request = BridgeRequest(
            pourquoi_ecoute=pourquoi_ecoute,
            job_file=job_file_data,
            job_text=job_text,
            cv_file=cv_file_data,
            force_refresh=force_refresh
        )
        
        # [Conserv√©] Ex√©cution du workflow avec le bridge
        async with CommitmentNextvisionBridge() as bridge:
            result = await bridge.execute_complete_workflow(bridge_request)
        
        # üÜï ENRICHISSEMENT GOOGLE MAPS INTELLIGENCE
        google_maps_enhancement = None
        if result.cv_data and result.job_data:
            try:
                # Tentative d'enrichissement avec intelligence g√©ospatiale
                candidat_address = getattr(result.cv_data, 'location', None) or getattr(result.cv_data, 'address', None)
                job_address = getattr(result.job_data, 'location', None) or getattr(result.job_data, 'address', None)
                
                if candidat_address and job_address:
                    logger.info(f"üó∫Ô∏è Enrichissement Google Maps: {candidat_address} ‚Üí {job_address}")
                    
                    # Calcul rapide de scoring enrichi (version simplifi√©e pour d√©mo)
                    default_constraints = [
                        TransportConstraint(mode=GoogleMapsMode.DRIVING, max_duration_minutes=30),
                        TransportConstraint(mode=GoogleMapsMode.TRANSIT, max_duration_minutes=45)
                    ]
                    
                    candidat_profile = CandidatTransportProfile(
                        candidat_id="workflow_integration",
                        home_address=candidat_address,
                        constraints=default_constraints
                    )
                    
                    job_info = JobTransportInfo(
                        job_id="workflow_job",
                        office_address=job_address
                    )
                    
                    # Calcul transport simplifi√©
                    async with TransportCalculatorService() as calculator:
                        transport_result = await calculator.calculate_multi_modal_options(
                            candidat_profile=candidat_profile,
                            job_info=job_info
                        )
                    
                    # Enrichissement scoring
                    original_location_score = 0.6  # Score par d√©faut
                    enhanced_score, enhancement_metadata = enhance_location_component_score(
                        candidat_profile=candidat_profile,
                        job_info=job_info,
                        transport_result=transport_result,
                        original_score=original_location_score,
                        pourquoi_ecoute=pourquoi_ecoute
                    )
                    
                    google_maps_enhancement = {
                        "enabled": True,
                        "transport_compatibility": transport_result.is_transport_compatible,
                        "location_score_enhancement": {
                            "original": original_location_score,
                            "enhanced": enhanced_score,
                            "improvement": enhanced_score - original_location_score
                        },
                        "transport_summary": {
                            "viable_modes": len([a for a in transport_result.transport_analyses if a.is_viable]),
                            "best_mode": transport_result.best_transport_mode.value if transport_result.best_transport_mode else None
                        },
                        "geospatial_insights": get_location_zone_recommendation(transport_result)
                    }
                    
                    logger.info(f"üó∫Ô∏è Google Maps enhancement: Score {original_location_score:.3f} ‚Üí {enhanced_score:.3f}")
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Google Maps enhancement failed: {e}")
                google_maps_enhancement = {
                    "enabled": False,
                    "error": str(e),
                    "fallback": "Standard workflow completed without geographical intelligence"
                }
        
        # [Conserv√©] Nettoyage des fichiers temporaires
        for temp_file in temp_files:
            try:
                os.unlink(temp_file)
            except:
                pass
        
        # [Enrichi] Enrichissement de la r√©ponse
        processing_time = round((time.time() - start_time) * 1000, 2)
        
        response_data = {
            "status": result.status,
            "workflow_results": {
                "job_parsing": {
                    "success": result.job_data is not None,
                    "data": result.job_data.dict() if result.job_data else None
                },
                "cv_parsing": {
                    "success": result.cv_data is not None,
                    "data": result.cv_data.dict() if result.cv_data else None
                },
                "matching": {
                    "success": result.matching_results is not None,
                    "data": result.matching_results
                },
                "google_maps_intelligence": google_maps_enhancement  # üÜï
            },
            "integration_metadata": {
                "processing_time_ms": processing_time,
                "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ"),
                "bridge_version": "1.0.0",
                "services_integration": "Commitment- ‚Üí Nextvision + Google Maps Intelligence",
                "adaptive_weighting": True,
                "google_maps_enhancement": google_maps_enhancement is not None and google_maps_enhancement.get("enabled", False)
            },
            "performance": result.processing_details,
            "errors": result.errors
        }
        
        logger.info(f"‚úÖ Workflow complet + Google Maps Intelligence termin√© en {processing_time}ms")
        
        return JSONResponse(content=response_data)
        
    except Exception as e:
        logger.error(f"‚ùå Erreur workflow complet: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur workflow: {str(e)}")

# [CONSERV√â] Autres endpoints d'int√©gration existants
# (parse-job-from-commitment, parse-cv-from-commitment, cv-to-matching, integration/health, integration/status)
# [Pas de modifications n√©cessaires, ils restent identiques]

# ===== MIDDLEWARE POUR L'INT√âGRATION (enrichi) =====

@app.middleware("http")
async def integration_logging_middleware(request, call_next):
    """üìù Middleware enrichi pour logger les requ√™tes d'int√©gration et Google Maps"""
    start_time = time.time()
    
    # Logger les requ√™tes d'int√©gration et Google Maps
    if request.url.path.startswith("/api/v1/integration/") or request.url.path.startswith("/api/v2/transport/"):
        service_type = "üåâ Bridge" if "integration" in request.url.path else "üó∫Ô∏è Google Maps"
        logger.info(f"{service_type} {request.method} {request.url.path}")
    
    response = await call_next(request)
    
    # Logger les performances
    if request.url.path.startswith("/api/v1/integration/") or request.url.path.startswith("/api/v2/transport/"):
        process_time = round((time.time() - start_time) * 1000, 2)
        service_type = "üåâ" if "integration" in request.url.path else "üó∫Ô∏è"
        logger.info(f"‚úÖ {service_type} {request.method} {request.url.path} - {response.status_code} - {process_time}ms")
    
    return response

# Startup et shutdown events pour Google Maps Intelligence
@app.on_event("startup")
async def startup_event():
    """üöÄ Initialisation Google Maps Intelligence"""
    logger.info("üó∫Ô∏è Initialisation Google Maps Intelligence...")
    
    try:
        # Validation de la configuration
        config = get_config()
        config_issues = validate_production_config(config)
        
        if config_issues:
            logger.warning("‚ö†Ô∏è Issues de configuration d√©tect√©es:")
            for issue in config_issues:
                logger.warning(f"  - {issue}")
        
        # Initialisation des services
        gmaps_service = await get_google_maps_service()
        cache = await get_global_cache()
        performance_monitor = await get_global_performance_monitor()
        
        logger.info("‚úÖ Google Maps Intelligence initialis√© avec succ√®s")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur initialisation Google Maps Intelligence: {e}")

@app.on_event("shutdown")
async def shutdown_event():
    """üîå Nettoyage Google Maps Intelligence"""
    logger.info("üîå Nettoyage Google Maps Intelligence...")
    
    try:
        from nextvision.services.google_maps_service import close_google_maps_service
        from nextvision.utils.google_maps_helpers import cleanup_global_helpers
        
        await close_google_maps_service()
        await cleanup_global_helpers()
        
        logger.info("‚úÖ Nettoyage Google Maps Intelligence termin√©")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur nettoyage: {e}")

if __name__ == "__main__":
    print("üéØ === NEXTVISION API STARTUP AVEC GOOGLE MAPS INTELLIGENCE ===")
    print("üöÄ Algorithme de matching IA adaptatif pour NEXTEN")
    print("üåâ Bridge Commitment- ‚Üí Nextvision INT√âGR√â")
    print("üó∫Ô∏è Google Maps Intelligence ACTIV√â (Prompt 2)")
    print("üìö Documentation: http://localhost:8000/docs")
    print("‚ù§Ô∏è Health Check: http://localhost:8000/api/v1/health")
    print("üó∫Ô∏è Google Maps Health: http://localhost:8000/api/v2/transport/health")
    print("üåâ Integration Health: http://localhost:8000/api/v1/integration/health")
    print("üìä Integration Status: http://localhost:8000/api/v1/integration/status")
    print("üîç Preview Weights: http://localhost:8000/api/v1/weights/preview")
    print("üö´ Transport Filtering: http://localhost:8000/api/v2/transport/filter-jobs")
    print("üéØ Location Scoring: http://localhost:8000/api/v2/transport/location-scoring")
    print("üìä Performance Metrics: http://localhost:8000/api/v2/transport/performance-metrics")
    print("üéØ Pond√©ration Adaptative: ACTIVE")
    print("üó∫Ô∏è Intelligence G√©ospatiale: OP√âRATIONNELLE")
    print("üîó Int√©gration r√©volutionnaire: NEXTEN 2.0")
    print("=================================================================")
    
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)
