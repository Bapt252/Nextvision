#!/bin/bash

# üöÄ Nextvision V3.0 - Script de Tests avec Couverture de Code
# ============================================================
#
# Script optimis√© pour lancer les tests Nextvision V3.0 avec 
# couverture de code r√©elle sur modules nextvision.services.*
#
# Usage:
#   ./run_tests_v3.sh                    # Tests basiques
#   ./run_tests_v3.sh coverage           # Tests + couverture
#   ./run_tests_v3.sh real-modules       # Tests modules r√©els seulement
#   ./run_tests_v3.sh performance        # Tests performance
#   ./run_tests_v3.sh clean              # Nettoie rapports pr√©c√©dents
#
# Version: 3.0.0 - Coverage & Performance Optimization
# Author: NEXTEN Team - Coverage Fix

set -e  # Arr√™te le script en cas d'erreur

# ============================================================================
# CONFIGURATION & COULEURS
# ============================================================================

# Couleurs pour affichage
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# R√©pertoires
PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
REPORTS_DIR="$PROJECT_ROOT/reports"
COVERAGE_DIR="$REPORTS_DIR/coverage_html"
LOG_FILE="$REPORTS_DIR/test_execution.log"

# Configuration pytest
PYTEST_ARGS=""
MODE="basic"

# ============================================================================
# FONCTIONS UTILITAIRES
# ============================================================================

print_header() {
    echo -e "${BLUE}üöÄ NEXTVISION V3.0 - TESTS & COUVERTURE DE CODE${NC}"
    echo -e "${BLUE}=================================================${NC}"
    echo -e "${CYAN}üìÖ $(date '+%Y-%m-%d %H:%M:%S')${NC}"
    echo -e "${CYAN}üìÇ R√©pertoire: $PROJECT_ROOT${NC}"
    echo -e "${CYAN}üîß Mode: $MODE${NC}"
    echo ""
}

print_section() {
    echo -e "${PURPLE}$1${NC}"
    echo -e "${PURPLE}$(printf '=%.0s' {1..60})${NC}"
}

print_success() {
    echo -e "${GREEN}‚úÖ $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}‚ö†Ô∏è $1${NC}"
}

print_error() {
    echo -e "${RED}‚ùå $1${NC}"
}

print_info() {
    echo -e "${CYAN}üìã $1${NC}"
}

# ============================================================================
# PR√âPARATION ENVIRONNEMENT
# ============================================================================

setup_environment() {
    print_section "üîß PR√âPARATION ENVIRONNEMENT"
    
    # Cr√©ation r√©pertoires de rapports
    mkdir -p "$REPORTS_DIR"
    mkdir -p "$COVERAGE_DIR"
    
    # Variables d'environnement pour tests
    export NEXTVISION_ENV=test
    export NEXTVISION_DEBUG=false
    export NEXTVISION_CACHE_ENABLED=true
    export NEXTVISION_LOG_LEVEL=WARNING
    export PYTEST_RUNNING=true
    export PYTHONDONTWRITEBYTECODE=1
    
    print_success "Environnement configur√©"
    print_info "R√©pertoire rapports: $REPORTS_DIR"
    print_info "Variables d'environnement d√©finies"
    echo ""
}

# ============================================================================
# V√âRIFICATIONS PR√â-TESTS
# ============================================================================

check_dependencies() {
    print_section "üîç V√âRIFICATION D√âPENDANCES"
    
    # V√©rification pytest
    if ! command -v pytest &> /dev/null; then
        print_error "pytest non install√©"
        exit 1
    fi
    
    # V√©rification pytest-cov
    if ! python -c "import pytest_cov" &> /dev/null; then
        print_warning "pytest-cov non install√©, installation..."
        pip install pytest-cov
    fi
    
    # V√©rification structure projet
    if [ ! -d "nextvision" ]; then
        print_error "R√©pertoire nextvision/ non trouv√©"
        exit 1
    fi
    
    if [ ! -d "tests" ]; then
        print_error "R√©pertoire tests/ non trouv√©"
        exit 1
    fi
    
    print_success "Toutes les d√©pendances sont disponibles"
    echo ""
}

diagnose_modules() {
    print_section "üîç DIAGNOSTIC MODULES NEXTVISION"
    
    # Liste des modules attendus
    EXPECTED_MODULES=(
        "nextvision.services.bidirectional_scorer"
        "nextvision.services.enhanced_bidirectional_scorer_v3"
        "nextvision.services.google_maps_service"
        "nextvision.services.transport_calculator"
        "nextvision.services.motivations_scorer_v3"
        "nextvision.services.listening_reasons_scorer_v3"
        "nextvision.services.professional_motivations_scorer_v3"
        "nextvision.services.scorers_v3.location_transport_scorer_v3"
    )
    
    AVAILABLE_COUNT=0
    MISSING_COUNT=0
    
    for module in "${EXPECTED_MODULES[@]}"; do
        if python -c "import $module" &> /dev/null; then
            print_success "Module disponible: $module"
            ((AVAILABLE_COUNT++))
        else
            print_warning "Module manquant/erreur: $module"
            ((MISSING_COUNT++))
        fi
    done
    
    echo ""
    print_info "Modules disponibles: $AVAILABLE_COUNT"
    print_info "Modules manquants: $MISSING_COUNT"
    
    if [ $AVAILABLE_COUNT -eq 0 ]; then
        print_error "Aucun module nextvision.services importable !"
        print_info "V√©rifiez que le module enhanced_bidirectional_scorer_v3.py a √©t√© cr√©√©"
        exit 1
    fi
    
    echo ""
}

# ============================================================================
# NETTOYAGE
# ============================================================================

clean_previous_reports() {
    if [ "$MODE" = "clean" ]; then
        print_section "üßπ NETTOYAGE RAPPORTS PR√âC√âDENTS"
        
        rm -rf "$COVERAGE_DIR"
        rm -f "$REPORTS_DIR"/*.xml
        rm -f "$REPORTS_DIR"/*.json
        rm -f "$REPORTS_DIR"/*.log
        rm -rf .pytest_cache
        rm -rf .coverage
        
        print_success "Rapports pr√©c√©dents supprim√©s"
        exit 0
    fi
    
    # Nettoyage partiel pour nouveaux tests
    rm -f "$LOG_FILE"
    rm -f .coverage
}

# ============================================================================
# CONFIGURATION TESTS PAR MODE
# ============================================================================

configure_basic_tests() {
    print_section "‚öôÔ∏è CONFIGURATION TESTS BASIQUES"
    
    PYTEST_ARGS="-v --tb=short --color=yes"
    print_info "Tests basiques configur√©s"
}

configure_coverage_tests() {
    print_section "üìä CONFIGURATION TESTS COUVERTURE"
    
    PYTEST_ARGS="-v --tb=short --color=yes \
        --cov=nextvision.services \
        --cov=nextvision.models \
        --cov-report=term-missing \
        --cov-report=html:$COVERAGE_DIR \
        --cov-report=xml:$REPORTS_DIR/coverage.xml \
        --cov-report=json:$REPORTS_DIR/coverage.json \
        --cov-fail-under=30"
    
    print_info "Couverture configur√©e avec seuil 30%"
    print_info "Rapports: terminal + HTML + XML + JSON"
}

configure_real_modules_tests() {
    print_section "üéØ CONFIGURATION TESTS MODULES R√âELS"
    
    PYTEST_ARGS="-v --tb=short --color=yes \
        -m real_modules \
        --cov=nextvision.services \
        --cov-report=term-missing \
        --cov-report=html:$COVERAGE_DIR \
        --cov-fail-under=20"
    
    print_info "Tests modules r√©els uniquement"
}

configure_performance_tests() {
    print_section "‚ö° CONFIGURATION TESTS PERFORMANCE"
    
    PYTEST_ARGS="-v --tb=short --color=yes \
        -m performance \
        --durations=10"
    
    print_info "Tests performance configur√©s"
}

# ============================================================================
# EX√âCUTION TESTS
# ============================================================================

run_tests() {
    print_section "üöÄ EX√âCUTION DES TESTS"
    
    # Fichiers de tests prioritaires
    TEST_FILES=(
        "tests/test_nextvision_real_modules.py"
        "tests/test_enhanced_scorer_v3_integration.py"
    )
    
    # Commande pytest finale
    PYTEST_CMD="pytest $PYTEST_ARGS"
    
    # Ajout des fichiers de tests si ils existent
    for test_file in "${TEST_FILES[@]}"; do
        if [ -f "$test_file" ]; then
            PYTEST_CMD="$PYTEST_CMD $test_file"
        fi
    done
    
    print_info "Commande: $PYTEST_CMD"
    echo ""
    
    # Ex√©cution avec logging
    if $PYTEST_CMD 2>&1 | tee "$LOG_FILE"; then
        TESTS_SUCCESS=true
        print_success "Tests ex√©cut√©s avec succ√®s"
    else
        TESTS_SUCCESS=false
        print_error "√âchec lors de l'ex√©cution des tests"
    fi
    
    echo ""
}

# ============================================================================
# G√âN√âRATION RAPPORTS
# ============================================================================

generate_reports() {
    print_section "üìã G√âN√âRATION RAPPORTS"
    
    # Rapport d'ex√©cution
    EXECUTION_REPORT="$REPORTS_DIR/execution_report_$(date +%Y%m%d_%H%M%S).json"
    
    cat > "$EXECUTION_REPORT" << EOF
{
    "timestamp": "$(date -Iseconds)",
    "mode": "$MODE",
    "tests_success": $TESTS_SUCCESS,
    "project_root": "$PROJECT_ROOT",
    "pytest_command": "$PYTEST_CMD",
    "reports": {
        "log_file": "$LOG_FILE",
        "coverage_html": "$COVERAGE_DIR/index.html",
        "coverage_xml": "$REPORTS_DIR/coverage.xml",
        "coverage_json": "$REPORTS_DIR/coverage.json"
    }
}
EOF
    
    print_success "Rapport d'ex√©cution: $EXECUTION_REPORT"
    
    # Affichage liens rapports
    if [ -f "$COVERAGE_DIR/index.html" ]; then
        print_info "üìä Rapport HTML couverture: file://$COVERAGE_DIR/index.html"
    fi
    
    if [ -f "$REPORTS_DIR/coverage.xml" ]; then
        print_info "üìÑ Rapport XML couverture: $REPORTS_DIR/coverage.xml"
    fi
}

display_summary() {
    print_section "üìä R√âSUM√â FINAL"
    
    # Extraction stats de couverture si disponible
    if [ -f "$REPORTS_DIR/coverage.json" ]; then
        COVERAGE_PERCENT=$(python3 -c "
import json
try:
    with open('$REPORTS_DIR/coverage.json') as f:
        data = json.load(f)
    print(f\"{data['totals']['percent_covered']:.1f}%\")
except:
    print('N/A')
" 2>/dev/null || echo "N/A")
        
        if [ "$COVERAGE_PERCENT" != "N/A" ]; then
            print_info "üéØ Couverture de code: $COVERAGE_PERCENT"
        fi
    fi
    
    # Status final
    if [ "$TESTS_SUCCESS" = true ]; then
        print_success "TESTS R√âUSSIS ‚úÖ"
        echo -e "${GREEN}üéâ Nextvision V3.0 - Tests valid√©s avec succ√®s !${NC}"
    else
        print_error "TESTS √âCHOU√âS ‚ùå"
        echo -e "${RED}üí• Nextvision V3.0 - √âchec des tests${NC}"
    fi
    
    echo ""
    print_info "üìÇ Tous les rapports sont dans: $REPORTS_DIR"
    print_info "üìã Log d√©taill√©: $LOG_FILE"
}

# ============================================================================
# FONCTION PRINCIPALE
# ============================================================================

main() {
    # Analyse des arguments
    case "${1:-basic}" in
        "coverage")
            MODE="coverage"
            ;;
        "real-modules")
            MODE="real-modules"
            ;;
        "performance")
            MODE="performance"
            ;;
        "clean")
            MODE="clean"
            ;;
        *)
            MODE="basic"
            ;;
    esac
    
    # Ex√©cution s√©quentielle
    print_header
    setup_environment
    check_dependencies
    diagnose_modules
    clean_previous_reports
    
    case "$MODE" in
        "coverage")
            configure_coverage_tests
            ;;
        "real-modules")
            configure_real_modules_tests
            ;;
        "performance")
            configure_performance_tests
            ;;
        *)
            configure_basic_tests
            ;;
    esac
    
    run_tests
    generate_reports
    display_summary
    
    # Code de sortie bas√© sur succ√®s des tests
    if [ "$TESTS_SUCCESS" = true ]; then
        exit 0
    else
        exit 1
    fi
}

# ============================================================================
# AIDE
# ============================================================================

if [ "${1:-}" = "--help" ] || [ "${1:-}" = "-h" ]; then
    echo "üöÄ Nextvision V3.0 - Script de Tests & Couverture"
    echo ""
    echo "Usage:"
    echo "  ./run_tests_v3.sh [MODE]"
    echo ""
    echo "Modes disponibles:"
    echo "  basic        Tests basiques (d√©faut)"
    echo "  coverage     Tests + couverture de code compl√®te"
    echo "  real-modules Tests modules r√©els seulement"
    echo "  performance  Tests performance uniquement"
    echo "  clean        Nettoie les rapports pr√©c√©dents"
    echo ""
    echo "Exemples:"
    echo "  ./run_tests_v3.sh coverage     # Tests avec couverture"
    echo "  ./run_tests_v3.sh clean        # Nettoyage rapports"
    echo ""
    exit 0
fi

# Lancement du script principal
main "$@"
