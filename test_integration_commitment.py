#!/usr/bin/env python3
"""
üåê NEXTVISION V3.2.1 - TEST INT√âGRATION FRONTEND COMMITMENT-

Validation de l'int√©gration compl√®te :
- Frontend Commitment- (parseurs GPT)
- Bridge API Nextvision
- Flux end-to-end r√©el
- Tests avec fichiers r√©els
- Validation UX compl√®te

Version: 3.2.1
Date: 2025-07-11
Auteur: Assistant Claude
"""

import asyncio
import aiohttp
import json
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
import base64
import io

@dataclass
class IntegrationTestResult:
    """R√©sultat d'un test d'int√©gration"""
    test_name: str
    success: bool
    duration_ms: float
    frontend_url: str
    backend_response: Dict
    error: Optional[str] = None
    user_journey_step: str = ""

class CommitmentIntegrationTester:
    """Testeur d'int√©gration Commitment- ‚Üî Nextvision"""
    
    def __init__(self):
        self.nextvision_url = "http://localhost:8001"
        self.commitment_urls = {
            "cv_parser": "https://bapt252.github.io/Commitment-/templates/candidate-upload.html",
            "job_parser": "https://bapt252.github.io/Commitment-/templates/client-questionnaire.html"
        }
        self.results: List[IntegrationTestResult] = []
        
        # Donn√©es de test r√©alistes
        self.test_cv_content = """
        CHARLOTTE DARMON
        Directrice Administrative et Financi√®re
        
        EXP√âRIENCE PROFESSIONNELLE
        
        2018 - Pr√©sent : DAF - Soci√©t√© INNOV (Paris 8√®me)
        ‚Ä¢ Direction de l'√©quipe comptable et financi√®re (12 personnes)
        ‚Ä¢ Pilotage budg√©taire et contr√¥le de gestion
        ‚Ä¢ Reporting consolid√© mensuel
        ‚Ä¢ Relations bancaires et investisseurs
        
        2015 - 2018 : Directrice Comptable - Groupe TECH (La D√©fense)
        ‚Ä¢ Management √©quipe de 8 comptables
        ‚Ä¢ Cl√¥tures mensuelles et consolidation
        ‚Ä¢ Audit et contr√¥le interne
        
        2012 - 2015 : Chef Comptable Senior - Cabinet AUDIT+ (Paris 9√®me)
        ‚Ä¢ Supervision missions d'audit
        ‚Ä¢ Formation √©quipes juniors
        ‚Ä¢ Client portfolio management
        
        FORMATION
        ‚Ä¢ Master CCA - Universit√© Paris Dauphine (2012)
        ‚Ä¢ DSCG - 2011
        
        COMP√âTENCES
        ‚Ä¢ Direction d'√©quipe et management
        ‚Ä¢ Consolidation et reporting
        ‚Ä¢ Contr√¥le de gestion et budgets
        ‚Ä¢ Relations bancaires
        ‚Ä¢ SAP, Sage, Excel avanc√©
        
        PR√âTENTIONS SALARIALES
        80 000‚Ç¨ brut annuel + variable
        
        LOCALISATION
        Paris 8√®me - Mobilit√© √éle-de-France
        """
        
        self.test_job_content = {
            "company": "PME Innovante",
            "position": "Comptable G√©n√©ral",
            "location": "Paris 15√®me",
            "description": """
            Nous recherchons un Comptable G√©n√©ral pour rejoindre notre √©quipe.
            
            MISSIONS :
            ‚Ä¢ Tenue de la comptabilit√© g√©n√©rale
            ‚Ä¢ Pr√©paration des d√©clarations fiscales  
            ‚Ä¢ Suivi de la tr√©sorerie
            ‚Ä¢ Relations avec l'expert-comptable
            ‚Ä¢ Participation aux cl√¥tures mensuelles
            
            PROFIL RECHERCH√â :
            ‚Ä¢ Formation comptable (BTS/DUT)
            ‚Ä¢ 2 √† 5 ans d'exp√©rience en comptabilit√©
            ‚Ä¢ Ma√Ætrise Sage et Excel
            ‚Ä¢ Autonomie et rigueur
            ‚Ä¢ Esprit d'√©quipe
            
            R√âMUN√âRATION :
            32 000‚Ç¨ √† 38 000‚Ç¨ selon exp√©rience
            
            TYPE DE CONTRAT :
            CDI - 35h/semaine
            """,
            "required_experience": "2-5 ans",
            "salary_min": 32000,
            "salary_max": 38000,
            "contract_type": "CDI",
            "required_skills": ["Comptabilit√©", "Sage", "Excel", "Fiscalit√©"],
            "level": "JUNIOR"
        }
    
    async def test_cv_parsing_integration(self) -> IntegrationTestResult:
        """Test l'int√©gration du parsing CV"""
        test_name = "CV Parsing Integration"
        start_time = time.time()
        
        try:
            # Simulation de l'envoi depuis le frontend Commitment-
            cv_payload = {
                "cv_text": self.test_cv_content,
                "candidate_name": "Charlotte DARMON",
                "source": "commitment_frontend",
                "timestamp": datetime.now().isoformat()
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.nextvision_url}/api/v2/conversion/commitment/enhanced",
                    json=cv_payload,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    
                    duration_ms = (time.time() - start_time) * 1000
                    
                    if response.status == 200:
                        backend_response = await response.json()
                        
                        # Validation des donn√©es pars√©es
                        required_fields = [
                            'candidate_profile',
                            'skills_extracted', 
                            'experience_level',
                            'salary_expectation',
                            'location_detected'
                        ]
                        
                        missing_fields = [
                            field for field in required_fields 
                            if field not in backend_response
                        ]
                        
                        # Validation sp√©cifique Charlotte DARMON
                        profile = backend_response.get('candidate_profile', {})
                        charlotte_validations = [
                            profile.get('experience_years', 0) >= 10,  # 15 ans d'exp√©rience
                            'DAF' in str(profile.get('title', '')).upper(),
                            profile.get('level') == 'EXECUTIVE',
                            backend_response.get('salary_expectation', 0) >= 70000
                        ]
                        
                        success = (
                            len(missing_fields) == 0 and 
                            all(charlotte_validations)
                        )
                        
                        return IntegrationTestResult(
                            test_name=test_name,
                            success=success,
                            duration_ms=duration_ms,
                            frontend_url=self.commitment_urls["cv_parser"],
                            backend_response=backend_response,
                            user_journey_step="CV Upload ‚Üí Parse ‚Üí Profile Creation",
                            error=None if success else f"Missing fields: {missing_fields} or validation failed"
                        )
                    
                    else:
                        error_text = await response.text()
                        return IntegrationTestResult(
                            test_name=test_name,
                            success=False,
                            duration_ms=duration_ms,
                            frontend_url=self.commitment_urls["cv_parser"],
                            backend_response={},
                            error=f"HTTP {response.status}: {error_text}"
                        )
                        
        except Exception as e:
            duration_ms = (time.time() - start_time) * 1000
            return IntegrationTestResult(
                test_name=test_name,
                success=False,
                duration_ms=duration_ms,
                frontend_url=self.commitment_urls["cv_parser"],
                backend_response={},
                error=str(e)
            )
    
    async def test_job_parsing_integration(self) -> IntegrationTestResult:
        """Test l'int√©gration du parsing fiche de poste"""
        test_name = "Job Parsing Integration"
        start_time = time.time()
        
        try:
            # Simulation de l'envoi depuis le frontend Commitment-
            job_payload = {
                "job_data": self.test_job_content,
                "source": "commitment_frontend",
                "timestamp": datetime.now().isoformat()
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.nextvision_url}/api/v2/conversion/commitment/job",
                    json=job_payload,
                    timeout=aiohttp.ClientTimeout(total=20)
                ) as response:
                    
                    duration_ms = (time.time() - start_time) * 1000
                    
                    if response.status == 200:
                        backend_response = await response.json()
                        
                        # Validation des donn√©es pars√©es
                        required_fields = [
                            'job_profile',
                            'required_skills',
                            'experience_required',
                            'salary_range',
                            'location'
                        ]
                        
                        missing_fields = [
                            field for field in required_fields 
                            if field not in backend_response
                        ]
                        
                        # Validation sp√©cifique du job
                        job_profile = backend_response.get('job_profile', {})
                        job_validations = [
                            'comptable' in str(job_profile.get('title', '')).lower(),
                            job_profile.get('level') == 'JUNIOR',
                            backend_response.get('salary_range', {}).get('min', 0) >= 30000,
                            len(backend_response.get('required_skills', [])) >= 3
                        ]
                        
                        success = (
                            len(missing_fields) == 0 and 
                            all(job_validations)
                        )
                        
                        return IntegrationTestResult(
                            test_name=test_name,
                            success=success,
                            duration_ms=duration_ms,
                            frontend_url=self.commitment_urls["job_parser"],
                            backend_response=backend_response,
                            user_journey_step="Job Description ‚Üí Parse ‚Üí Requirements",
                            error=None if success else f"Missing fields: {missing_fields} or validation failed"
                        )
                    
                    else:
                        error_text = await response.text()
                        return IntegrationTestResult(
                            test_name=test_name,
                            success=False,
                            duration_ms=duration_ms,
                            frontend_url=self.commitment_urls["job_parser"],
                            backend_response={},
                            error=f"HTTP {response.status}: {error_text}"
                        )
                        
        except Exception as e:
            duration_ms = (time.time() - start_time) * 1000
            return IntegrationTestResult(
                test_name=test_name,
                success=False,
                duration_ms=duration_ms,
                frontend_url=self.commitment_urls["job_parser"],
                backend_response={},
                error=str(e)
            )
    
    async def test_complete_matching_flow(self) -> IntegrationTestResult:
        """Test le flux complet de matching"""
        test_name = "Complete Matching Flow"
        start_time = time.time()
        
        try:
            # 1. Parser le CV (Charlotte DARMON)
            cv_result = await self.test_cv_parsing_integration()
            if not cv_result.success:
                raise Exception(f"CV parsing failed: {cv_result.error}")
            
            # 2. Parser le job (Comptable G√©n√©ral)
            job_result = await self.test_job_parsing_integration()
            if not job_result.success:
                raise Exception(f"Job parsing failed: {job_result.error}")
            
            # 3. Lancer le matching
            matching_payload = {
                "candidate": cv_result.backend_response.get('candidate_profile'),
                "job": job_result.backend_response.get('job_profile'),
                "matching_config": {
                    "weights": {
                        "semantic": 0.30,
                        "hierarchical": 0.15,
                        "salary": 0.20,
                        "experience": 0.20,
                        "location": 0.15,
                        "sector": 0.05
                    },
                    "enable_hierarchical_detection": True
                }
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.nextvision_url}/api/v1/matching/enhanced",
                    json=matching_payload,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    
                    duration_ms = (time.time() - start_time) * 1000
                    
                    if response.status == 200:
                        matching_result = await response.json()
                        
                        # Validation du cas Charlotte DARMON
                        # Elle DOIT √™tre rejet√©e (score < 0.6) avec une alerte hi√©rarchique
                        overall_score = matching_result.get('overall_score', 1.0)
                        alerts = matching_result.get('alerts', [])
                        
                        hierarchical_alert = any(
                            alert.get('type') == 'CRITICAL_MISMATCH' 
                            for alert in alerts
                        )
                        
                        # Crit√®res de succ√®s
                        success_criteria = [
                            overall_score < 0.6,  # Charlotte doit √™tre rejet√©e
                            hierarchical_alert,   # Alerte hi√©rarchique obligatoire
                            'scores_detail' in matching_result,  # D√©tails disponibles
                        ]
                        
                        success = all(success_criteria)
                        
                        # Enrichir la r√©ponse avec des m√©triques
                        enhanced_response = {
                            **matching_result,
                            "integration_metrics": {
                                "cv_parsing_duration": cv_result.duration_ms,
                                "job_parsing_duration": job_result.duration_ms,
                                "total_flow_duration": duration_ms,
                                "hierarchical_detection_working": hierarchical_alert,
                                "charlotte_darmon_correctly_rejected": overall_score < 0.6
                            }
                        }
                        
                        return IntegrationTestResult(
                            test_name=test_name,
                            success=success,
                            duration_ms=duration_ms,
                            frontend_url="Full Integration Flow",
                            backend_response=enhanced_response,
                            user_journey_step="CV Upload ‚Üí Job Create ‚Üí Matching ‚Üí Results",
                            error=None if success else f"Charlotte DARMON not properly rejected: score={overall_score:.3f}, hierarchical_alert={hierarchical_alert}"
                        )
                    
                    else:
                        error_text = await response.text()
                        return IntegrationTestResult(
                            test_name=test_name,
                            success=False,
                            duration_ms=duration_ms,
                            frontend_url="Full Integration Flow",
                            backend_response={},
                            error=f"Matching API error: HTTP {response.status}: {error_text}"
                        )
                        
        except Exception as e:
            duration_ms = (time.time() - start_time) * 1000
            return IntegrationTestResult(
                test_name=test_name,
                success=False,
                duration_ms=duration_ms,
                frontend_url="Full Integration Flow",
                backend_response={},
                error=str(e)
            )
    
    async def test_frontend_accessibility(self) -> IntegrationTestResult:
        """Test l'accessibilit√© des frontends Commitment-"""
        test_name = "Frontend Accessibility"
        start_time = time.time()
        
        try:
            frontend_results = {}
            
            async with aiohttp.ClientSession() as session:
                for name, url in self.commitment_urls.items():
                    try:
                        async with session.get(url, timeout=aiohttp.ClientTimeout(total=10)) as response:
                            frontend_results[name] = {
                                "url": url,
                                "status": response.status,
                                "accessible": response.status == 200,
                                "content_length": len(await response.text()) if response.status == 200 else 0
                            }
                    except Exception as e:
                        frontend_results[name] = {
                            "url": url,
                            "status": 0,
                            "accessible": False,
                            "error": str(e)
                        }
            
            # Validation
            accessible_frontends = sum(1 for result in frontend_results.values() if result.get('accessible', False))
            success = accessible_frontends >= len(self.commitment_urls) / 2  # Au moins 50% accessibles
            
            duration_ms = (time.time() - start_time) * 1000
            
            return IntegrationTestResult(
                test_name=test_name,
                success=success,
                duration_ms=duration_ms,
                frontend_url="Multiple URLs",
                backend_response=frontend_results,
                user_journey_step="Frontend Access Validation",
                error=None if success else f"Only {accessible_frontends}/{len(self.commitment_urls)} frontends accessible"
            )
            
        except Exception as e:
            duration_ms = (time.time() - start_time) * 1000
            return IntegrationTestResult(
                test_name=test_name,
                success=False,
                duration_ms=duration_ms,
                frontend_url="Multiple URLs",
                backend_response={},
                error=str(e)
            )
    
    async def run_all_integration_tests(self) -> Dict[str, Any]:
        """Lance tous les tests d'int√©gration"""
        print("üåê TESTS D'INT√âGRATION COMMITMENT- ‚Üî NEXTVISION V3.2.1")
        print("=" * 60)
        
        # Liste des tests d'int√©gration
        tests = [
            ("Frontend Accessibility", self.test_frontend_accessibility),
            ("CV Parsing Integration", self.test_cv_parsing_integration),
            ("Job Parsing Integration", self.test_job_parsing_integration),
            ("Complete Matching Flow", self.test_complete_matching_flow)
        ]
        
        for test_name, test_func in tests:
            print(f"\nüß™ Ex√©cution: {test_name}")
            print("-" * 40)
            
            try:
                result = await test_func()
                self.results.append(result)
                
                status = "‚úÖ PASS" if result.success else "‚ùå FAIL"
                print(f"{status} {result.test_name} ({result.duration_ms:.1f}ms)")
                
                if result.user_journey_step:
                    print(f"   Journey: {result.user_journey_step}")
                
                if not result.success:
                    print(f"   Error: {result.error}")
                
                # Affichage des d√©tails critiques
                if result.test_name == "Complete Matching Flow" and result.backend_response:
                    metrics = result.backend_response.get('integration_metrics', {})
                    score = result.backend_response.get('overall_score', 0)
                    print(f"   Charlotte DARMON Score: {score:.3f}")
                    print(f"   Hierarchical Detection: {'‚úÖ' if metrics.get('hierarchical_detection_working') else '‚ùå'}")
                    print(f"   Correctly Rejected: {'‚úÖ' if metrics.get('charlotte_darmon_correctly_rejected') else '‚ùå'}")
                
            except Exception as e:
                print(f"‚ùå CRASH {test_name}: {str(e)}")
                self.results.append(IntegrationTestResult(
                    test_name=test_name,
                    success=False,
                    duration_ms=0,
                    frontend_url="",
                    backend_response={},
                    error=f"Test crashed: {str(e)}"
                ))
        
        return self._generate_integration_report()
    
    def _generate_integration_report(self) -> Dict[str, Any]:
        """G√©n√®re le rapport d'int√©gration"""
        successful_tests = [r for r in self.results if r.success]
        failed_tests = [r for r in self.results if not r.success]
        
        # M√©triques sp√©ciales pour Charlotte DARMON
        charlotte_test = next(
            (r for r in self.results if r.test_name == "Complete Matching Flow"),
            None
        )
        
        charlotte_metrics = {}
        if charlotte_test and charlotte_test.backend_response:
            metrics = charlotte_test.backend_response.get('integration_metrics', {})
            charlotte_metrics = {
                "test_executed": True,
                "correctly_rejected": metrics.get('charlotte_darmon_correctly_rejected', False),
                "hierarchical_alert_triggered": metrics.get('hierarchical_detection_working', False),
                "overall_score": charlotte_test.backend_response.get('overall_score', 0),
                "total_flow_duration_ms": metrics.get('total_flow_duration', 0)
            }
        
        report = {
            "summary": {
                "total_tests": len(self.results),
                "successful_tests": len(successful_tests),
                "failed_tests": len(failed_tests),
                "success_rate": len(successful_tests) / len(self.results) if self.results else 0,
                "integration_ready": len(successful_tests) >= 3,  # Au moins 3/4 tests r√©ussis
                "timestamp": datetime.now().isoformat()
            },
            "charlotte_darmon_validation": charlotte_metrics,
            "frontend_status": {
                url_name: {
                    "accessible": any(
                        r.backend_response.get(url_name, {}).get('accessible', False)
                        for r in self.results if r.test_name == "Frontend Accessibility"
                    ),
                    "url": url
                }
                for url_name, url in self.commitment_urls.items()
            },
            "test_results": [
                {
                    "test_name": r.test_name,
                    "success": r.success,
                    "duration_ms": r.duration_ms,
                    "user_journey": r.user_journey_step,
                    "error": r.error
                }
                for r in self.results
            ],
            "recommendations": self._generate_integration_recommendations()
        }
        
        return report
    
    def _generate_integration_recommendations(self) -> List[str]:
        """G√©n√®re les recommandations d'int√©gration"""
        recommendations = []
        
        failed_tests = [r for r in self.results if not r.success]
        
        if not failed_tests:
            recommendations.extend([
                "üéâ Int√©gration Commitment- ‚Üî Nextvision parfaitement fonctionnelle",
                "‚úÖ Le syst√®me hi√©rarchique fonctionne correctement",
                "‚úÖ Charlotte DARMON est bien rejet√©e automatiquement",
                "üöÄ Pr√™t pour la mise en production"
            ])
        else:
            for test in failed_tests:
                if "Frontend Accessibility" in test.test_name:
                    recommendations.append("üîß V√©rifier la disponibilit√© des frontends Commitment-")
                elif "CV Parsing" in test.test_name:
                    recommendations.append("üîß Corriger l'int√©gration du parsing CV")
                elif "Job Parsing" in test.test_name:
                    recommendations.append("üîß Corriger l'int√©gration du parsing Job")
                elif "Complete Matching Flow" in test.test_name:
                    recommendations.append("üîß Corriger le flux de matching int√©gr√©")
        
        # Recommandations sp√©cifiques Charlotte DARMON
        charlotte_test = next(
            (r for r in self.results if r.test_name == "Complete Matching Flow"),
            None
        )
        
        if charlotte_test:
            if charlotte_test.success:
                recommendations.append("‚úÖ Cas Charlotte DARMON valid√© - Protection hi√©rarchique active")
            else:
                recommendations.append("‚ö†Ô∏è Cas Charlotte DARMON √† corriger - Risque de matching inappropri√©")
        
        return recommendations


async def main():
    """Fonction principale"""
    print("üåê NEXTVISION V3.2.1 - TEST INT√âGRATION FRONTEND")
    print("=" * 60)
    print("Validation de l'int√©gration Commitment- ‚Üî Nextvision")
    print("Test du parcours utilisateur complet")
    print("=" * 60)
    print()
    
    tester = CommitmentIntegrationTester()
    report = await tester.run_all_integration_tests()
    
    # Affichage du rapport final
    print("\n" + "=" * 60)
    print("üìä RAPPORT D'INT√âGRATION")
    print("=" * 60)
    
    summary = report['summary']
    print(f"Tests ex√©cut√©s: {summary['total_tests']}")
    print(f"Succ√®s: {summary['successful_tests']}")
    print(f"√âchecs: {summary['failed_tests']}")
    print(f"Taux de r√©ussite: {summary['success_rate']:.1%}")
    print(f"Int√©gration pr√™te: {'‚úÖ OUI' if summary['integration_ready'] else '‚ùå NON'}")
    
    # Status Charlotte DARMON
    charlotte = report['charlotte_darmon_validation']
    if charlotte.get('test_executed'):
        print(f"\nüéØ VALIDATION CHARLOTTE DARMON:")
        print(f"Score obtenu: {charlotte.get('overall_score', 0):.3f}")
        print(f"Correctement rejet√©e: {'‚úÖ' if charlotte.get('correctly_rejected') else '‚ùå'}")
        print(f"Alerte hi√©rarchique: {'‚úÖ' if charlotte.get('hierarchical_alert_triggered') else '‚ùå'}")
    
    print("\nüìã RECOMMANDATIONS:")
    for rec in report['recommendations']:
        print(f"  {rec}")
    
    # Sauvegarde du rapport
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = f"integration_commitment_nextvision_report_{timestamp}.json"
    
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nüíæ Rapport d√©taill√© sauvegard√©: {report_file}")
    
    # Code de sortie
    exit_code = 0 if summary['integration_ready'] else 1
    print(f"\nüéØ Tests d'int√©gration termin√©s avec le code: {exit_code}")
    
    return exit_code


if __name__ == "__main__":
    try:
        exit_code = asyncio.run(main())
        exit(exit_code)
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Tests d'int√©gration interrompus")
        exit(2)
    except Exception as e:
        print(f"\n‚ùå Erreur critique: {str(e)}")
        exit(3)
