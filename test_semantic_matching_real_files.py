#!/usr/bin/env python3
"""
üß† TEST MATCHING S√âMANTIQUE AVEC CV ET FDP R√âELS
Test sp√©cialis√© pour valider le scoring s√©mantique avec vrais documents

Author: Assistant Claude  
Version: 1.0.0-semantic-focus
"""

import os
import asyncio
import time
from pathlib import Path
from typing import Dict, List, Any, Optional
import json
from datetime import datetime

# Import du semantic scorer
from nextvision.services.bidirectional_scorer import SemanticScorer
from nextvision.models.bidirectional_models import (
    BiDirectionalCandidateProfile, BiDirectionalCompanyProfile,
    PersonalInfoBidirectional, CompetencesProfessionnelles, 
    InformationsEntreprise, DescriptionPoste,
    NiveauExperience, TypeContrat
)

class SemanticMatchingTester:
    """üß† Testeur sp√©cialis√© matching s√©mantique"""
    
    def __init__(self):
        self.semantic_scorer = SemanticScorer()
        self.bureau_path = Path.home() / "Desktop"
        self.cv_folder = self.bureau_path / "CV TEST"
        self.fdp_folder = self.bureau_path / "FDP TEST"
        
        print("üß† === TESTEUR MATCHING S√âMANTIQUE ===")
        print(f"üìÇ Dossier CV: {self.cv_folder}")
        print(f"üìÇ Dossier FDP: {self.fdp_folder}")
    
    def scan_documents(self) -> Dict[str, List[Path]]:
        """üìÇ Scanner les dossiers CV et FDP"""
        
        documents = {
            "cv_files": [],
            "fdp_files": []
        }
        
        # Scanner dossier CV TEST
        if self.cv_folder.exists():
            for ext in ['*.pdf', '*.docx', '*.doc', '*.txt']:
                documents["cv_files"].extend(self.cv_folder.glob(ext))
            print(f"üìÑ CV trouv√©s: {len(documents['cv_files'])}")
            for cv in documents["cv_files"]:
                print(f"   ‚Ä¢ {cv.name}")
        else:
            print(f"‚ö†Ô∏è Dossier CV TEST non trouv√©: {self.cv_folder}")
        
        # Scanner dossier FDP TEST  
        if self.fdp_folder.exists():
            for ext in ['*.pdf', '*.docx', '*.doc', '*.txt']:
                documents["fdp_files"].extend(self.fdp_folder.glob(ext))
            print(f"üìã FDP trouv√©es: {len(documents['fdp_files'])}")
            for fdp in documents["fdp_files"]:
                print(f"   ‚Ä¢ {fdp.name}")
        else:
            print(f"‚ö†Ô∏è Dossier FDP TEST non trouv√©: {self.fdp_folder}")
        
        return documents
    
    def extract_text_from_file(self, file_path: Path) -> str:
        """üìù Extraction texte depuis diff√©rents formats"""
        
        try:
            if file_path.suffix.lower() == '.txt':
                # Fichiers texte
                with open(file_path, 'r', encoding='utf-8') as f:
                    return f.read()
            
            elif file_path.suffix.lower() in ['.pdf']:
                # PDF (n√©cessite PyPDF2 ou pdfplumber)
                try:
                    import PyPDF2
                    with open(file_path, 'rb') as f:
                        reader = PyPDF2.PdfReader(f)
                        text = ""
                        for page in reader.pages:
                            text += page.extract_text() + "\n"
                        return text
                except ImportError:
                    print(f"‚ö†Ô∏è PyPDF2 non install√© pour lire {file_path.name}")
                    return f"CONTENU PDF NON EXTRACTIBLE - {file_path.name}"
                except Exception as e:
                    print(f"‚ö†Ô∏è Erreur lecture PDF {file_path.name}: {e}")
                    return f"ERREUR LECTURE PDF - {file_path.name}"
            
            elif file_path.suffix.lower() in ['.docx', '.doc']:
                # Documents Word (n√©cessite python-docx)
                try:
                    from docx import Document
                    doc = Document(file_path)
                    text = ""
                    for paragraph in doc.paragraphs:
                        text += paragraph.text + "\n"
                    return text
                except ImportError:
                    print(f"‚ö†Ô∏è python-docx non install√© pour lire {file_path.name}")
                    return f"CONTENU DOCX NON EXTRACTIBLE - {file_path.name}"
                except Exception as e:
                    print(f"‚ö†Ô∏è Erreur lecture DOCX {file_path.name}: {e}")
                    return f"ERREUR LECTURE DOCX - {file_path.name}"
            
            else:
                return f"FORMAT NON SUPPORT√â - {file_path.name}"
                
        except Exception as e:
            print(f"‚ùå Erreur extraction {file_path.name}: {e}")
            return f"ERREUR EXTRACTION - {file_path.name}"
    
    def parse_cv_content(self, cv_text: str, filename: str) -> BiDirectionalCandidateProfile:
        """üîç Parser basique du contenu CV pour cr√©er un profil candidat"""
        
        # Extraction basique des comp√©tences (mots-cl√©s techniques)
        competences_techniques = []
        keywords_tech = [
            'python', 'java', 'javascript', 'react', 'node', 'angular', 'vue',
            'php', 'sql', 'mysql', 'postgresql', 'mongodb', 'docker', 'kubernetes',
            'aws', 'azure', 'git', 'jenkins', 'linux', 'windows', 'html', 'css',
            'bootstrap', 'jquery', 'typescript', 'c++', 'c#', 'ruby', 'go',
            'comptabilit√©', 'cegid', 'sage', 'excel', 'powerpoint', 'word',
            'gestion', 'marketing', 'vente', 'commercial', 'rh', 'finance'
        ]
        
        cv_lower = cv_text.lower()
        for keyword in keywords_tech:
            if keyword in cv_lower:
                competences_techniques.append(keyword.title())
        
        # Extraction nom (basique - premier mot en majuscules)
        lines = cv_text.strip().split('\n')
        first_name = "Candidat"
        last_name = filename.replace('.pdf', '').replace('.docx', '').replace('.txt', '')
        
        # Tentative extraction nom plus intelligente
        for line in lines[:5]:  # Check premi√®res lignes
            words = line.strip().split()
            if len(words) >= 2 and words[0].isupper() and words[1].isupper():
                first_name = words[0].title()
                last_name = words[1].title()
                break
        
        # Estimation exp√©rience (cherche patterns d'ann√©es)
        experience_globale = NiveauExperience.CONFIRME  # D√©faut
        import re
        experience_patterns = re.findall(r'(\d+)\s*an[s]?', cv_lower)
        if experience_patterns:
            max_exp = max([int(x) for x in experience_patterns])
            if max_exp <= 2:
                experience_globale = NiveauExperience.JUNIOR
            elif max_exp <= 5:
                experience_globale = NiveauExperience.CONFIRME
            else:
                experience_globale = NiveauExperience.SENIOR
        
        # Cr√©ation profil candidat
        candidat = BiDirectionalCandidateProfile(
            personal_info=PersonalInfoBidirectional(
                firstName=first_name,
                lastName=last_name,
                email=f"{first_name.lower()}.{last_name.lower()}@test.com",
                phone="0123456789"
            ),
            experience_globale=experience_globale,
            competences=CompetencesProfessionnelles(
                competences_techniques=competences_techniques if competences_techniques else ["Comp√©tences g√©n√©rales"],
                logiciels_maitrise=competences_techniques[:5],  # Top 5
                langues={"Fran√ßais": "Natif", "Anglais": "Courant"}
            ),
            attentes=None,  # Pas n√©cessaire pour test s√©mantique
            motivations=None  # Pas n√©cessaire pour test s√©mantique
        )
        
        return candidat
    
    def parse_fdp_content(self, fdp_text: str, filename: str) -> BiDirectionalCompanyProfile:
        """üè¢ Parser basique du contenu FDP pour cr√©er un profil entreprise"""
        
        # Extraction comp√©tences requises (m√™mes mots-cl√©s)
        competences_requises = []
        keywords_tech = [
            'python', 'java', 'javascript', 'react', 'node', 'angular', 'vue',
            'php', 'sql', 'mysql', 'postgresql', 'mongodb', 'docker', 'kubernetes',
            'aws', 'azure', 'git', 'jenkins', 'linux', 'windows', 'html', 'css',
            'bootstrap', 'jquery', 'typescript', 'c++', 'c#', 'ruby', 'go',
            'comptabilit√©', 'cegid', 'sage', 'excel', 'powerpoint', 'word',
            'gestion', 'marketing', 'vente', 'commercial', 'rh', 'finance'
        ]
        
        fdp_lower = fdp_text.lower()
        for keyword in keywords_tech:
            if keyword in fdp_lower:
                competences_requises.append(keyword.title())
        
        # Extraction titre de poste (premi√®re ligne contenant des mots comme "d√©veloppeur", "comptable", etc.)
        titre_poste = filename.replace('.pdf', '').replace('.docx', '').replace('.txt', '')
        poste_keywords = ['d√©veloppeur', 'comptable', 'commercial', 'manager', 'chef', 'responsable', 'analyst']
        
        lines = fdp_text.strip().split('\n')
        for line in lines[:10]:  # Check premi√®res lignes
            line_lower = line.lower()
            for keyword in poste_keywords:
                if keyword in line_lower and len(line.strip()) < 100:  # Pas trop long = probablement titre
                    titre_poste = line.strip()
                    break
        
        # Extraction nom entreprise (cherche patterns)
        nom_entreprise = "Entreprise Test"
        import re
        # Patterns pour entreprises (SA, SARL, SAS, etc.)
        company_patterns = re.findall(r'([A-Z][a-zA-Z\s]+(?:SA|SARL|SAS|EURL|Group|Corp|Inc|Ltd))', fdp_text)
        if company_patterns:
            nom_entreprise = company_patterns[0].strip()
        
        # Cr√©ation profil entreprise
        entreprise = BiDirectionalCompanyProfile(
            entreprise=InformationsEntreprise(
                nom=nom_entreprise,
                secteur="Technologie",  # D√©faut
                localisation="Paris"  # D√©faut
            ),
            poste=DescriptionPoste(
                titre=titre_poste,
                localisation="Paris",
                type_contrat=TypeContrat.CDI,
                salaire_min=40000,  # D√©faut
                salaire_max=60000,  # D√©faut
                competences_requises=competences_requises if competences_requises else ["Comp√©tences g√©n√©rales"]
            ),
            exigences=None,  # Pas n√©cessaire pour test s√©mantique
            conditions=None,  # Pas n√©cessaire pour test s√©mantique
            recrutement=None  # Pas n√©cessaire pour test s√©mantique
        )
        
        return entreprise
    
    async def test_semantic_matching(self, candidat: BiDirectionalCandidateProfile, 
                                   entreprise: BiDirectionalCompanyProfile,
                                   cv_filename: str, fdp_filename: str) -> Dict[str, Any]:
        """üß† Test matching s√©mantique entre CV et FDP"""
        
        print(f"\nüß† === MATCHING S√âMANTIQUE ===")
        print(f"üìÑ CV: {cv_filename}")
        print(f"üìã FDP: {fdp_filename}")
        print(f"üë§ {candidat.personal_info.firstName} {candidat.personal_info.lastName} ({candidat.experience_globale.value})")
        print(f"üè¢ {entreprise.entreprise.nom} - {entreprise.poste.titre}")
        
        start_time = time.time()
        
        # Calcul score s√©mantique
        try:
            semantic_result = self.semantic_scorer.calculate_score(candidat, entreprise)
            calc_time = (time.time() - start_time) * 1000
            
            print(f"\nüìä R√âSULTATS S√âMANTIQUES:")
            print(f"‚ö° Temps calcul: {calc_time:.1f}ms")
            print(f"üéØ Score s√©mantique: {semantic_result.score:.3f}")
            print(f"üß† Confiance: {semantic_result.confidence:.3f}")
            
            # D√©tails du matching
            if semantic_result.details:
                print(f"\nüîç D√âTAILS MATCHING:")
                for key, value in semantic_result.details.items():
                    if isinstance(value, (int, float)):
                        print(f"   ‚Ä¢ {key}: {value:.3f}")
                    else:
                        print(f"   ‚Ä¢ {key}: {value}")
            
            # Comp√©tences candidat vs requises
            print(f"\nüíº ANALYSE COMP√âTENCES:")
            candidat_competences = set([c.lower() for c in candidat.competences.competences_techniques])
            requises_competences = set([c.lower() for c in entreprise.poste.competences_requises])
            
            correspondances = candidat_competences.intersection(requises_competences)
            manquantes = requises_competences - candidat_competences
            bonus = candidat_competences - requises_competences
            
            print(f"   ‚úÖ Correspondances ({len(correspondances)}): {', '.join(correspondances) if correspondances else 'Aucune'}")
            print(f"   ‚ùå Manquantes ({len(manquantes)}): {', '.join(manquantes) if manquantes else 'Aucune'}")
            print(f"   üéÅ Bonus candidat ({len(bonus)}): {', '.join(list(bonus)[:5]) if bonus else 'Aucune'}")
            
            # √âvaluation globale
            if semantic_result.score >= 0.8:
                evaluation = "üéâ EXCELLENT MATCH"
            elif semantic_result.score >= 0.6:
                evaluation = "‚úÖ BON MATCH"  
            elif semantic_result.score >= 0.4:
                evaluation = "‚ö†Ô∏è MATCH MOYEN"
            else:
                evaluation = "‚ùå MATCH FAIBLE"
            
            print(f"\n{evaluation}")
            
            return {
                "cv_filename": cv_filename,
                "fdp_filename": fdp_filename,
                "candidat_name": f"{candidat.personal_info.firstName} {candidat.personal_info.lastName}",
                "entreprise_name": entreprise.entreprise.nom,
                "poste_titre": entreprise.poste.titre,
                "semantic_score": semantic_result.score,
                "confidence": semantic_result.confidence,
                "calculation_time_ms": calc_time,
                "correspondances": list(correspondances),
                "manquantes": list(manquantes),
                "bonus": list(bonus),
                "evaluation": evaluation,
                "details": semantic_result.details
            }
            
        except Exception as e:
            print(f"‚ùå Erreur calcul s√©mantique: {e}")
            import traceback
            traceback.print_exc()
            return {
                "error": str(e),
                "cv_filename": cv_filename,
                "fdp_filename": fdp_filename
            }
    
    async def run_full_semantic_test(self):
        """üöÄ Test complet matching s√©mantique tous CV vs toutes FDP"""
        
        # Scanner documents
        documents = self.scan_documents()
        
        if not documents["cv_files"]:
            print("‚ùå Aucun CV trouv√© dans le dossier CV TEST")
            return
        
        if not documents["fdp_files"]:
            print("‚ùå Aucune FDP trouv√©e dans le dossier FDP TEST")
            return
        
        # R√©sultats de tous les matchings
        all_results = []
        
        print(f"\nüß† === D√âBUT TESTS S√âMANTIQUES ===")
        print(f"üìä {len(documents['cv_files'])} CV √ó {len(documents['fdp_files'])} FDP = {len(documents['cv_files']) * len(documents['fdp_files'])} matchings")
        
        total_start = time.time()
        
        # Test chaque CV contre chaque FDP
        for cv_file in documents["cv_files"]:
            print(f"\nüìÑ Traitement CV: {cv_file.name}")
            
            # Extraction contenu CV
            cv_text = self.extract_text_from_file(cv_file)
            candidat = self.parse_cv_content(cv_text, cv_file.name)
            
            for fdp_file in documents["fdp_files"]:
                print(f"   üìã vs FDP: {fdp_file.name}")
                
                # Extraction contenu FDP
                fdp_text = self.extract_text_from_file(fdp_file)
                entreprise = self.parse_fdp_content(fdp_text, fdp_file.name)
                
                # Test matching s√©mantique
                result = await self.test_semantic_matching(
                    candidat, entreprise, cv_file.name, fdp_file.name
                )
                all_results.append(result)
        
        total_time = (time.time() - total_start) * 1000
        
        # Rapport final
        self.generate_final_report(all_results, total_time)
    
    def generate_final_report(self, results: List[Dict], total_time_ms: float):
        """üìä G√©n√©ration rapport final des matchings s√©mantiques"""
        
        print(f"\n" + "="*70)
        print(f"üìä RAPPORT FINAL - MATCHING S√âMANTIQUE")
        print(f"="*70)
        
        successful_results = [r for r in results if "error" not in r]
        failed_results = [r for r in results if "error" in r]
        
        print(f"üìà Statistiques g√©n√©rales:")
        print(f"   üéØ Total matchings: {len(results)}")
        print(f"   ‚úÖ R√©ussis: {len(successful_results)}")
        print(f"   ‚ùå √âchou√©s: {len(failed_results)}")
        print(f"   ‚è±Ô∏è Temps total: {total_time_ms:.0f}ms")
        print(f"   ‚ö° Temps moyen: {total_time_ms/len(results):.1f}ms par matching")
        
        if successful_results:
            scores = [r["semantic_score"] for r in successful_results]
            confidences = [r["confidence"] for r in successful_results]
            
            print(f"\nüìä Distribution des scores:")
            print(f"   üéØ Score moyen: {sum(scores)/len(scores):.3f}")
            print(f"   üìà Score max: {max(scores):.3f}")
            print(f"   üìâ Score min: {min(scores):.3f}")
            print(f"   üß† Confiance moyenne: {sum(confidences)/len(confidences):.3f}")
            
            # Top 3 meilleurs matchings
            top_results = sorted(successful_results, key=lambda x: x["semantic_score"], reverse=True)[:3]
            print(f"\nüèÜ TOP 3 MEILLEURS MATCHINGS:")
            for i, result in enumerate(top_results, 1):
                print(f"   {i}. {result['candidat_name']} ‚Üí {result['poste_titre']}")
                print(f"      üìä Score: {result['semantic_score']:.3f} | ‚úÖ Correspondances: {len(result['correspondances'])}")
        
        # Sauvegarde r√©sultats
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = f"semantic_matching_results_{timestamp}.json"
        
        try:
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)
            print(f"\nüíæ R√©sultats sauv√©s: {results_file}")
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur sauvegarde: {e}")
        
        print(f"="*70)

async def main():
    """üöÄ Point d'entr√©e principal"""
    
    print("üß† === TEST MATCHING S√âMANTIQUE CV/FDP R√âELS ===")
    print("üìÇ Lecture des dossiers CV TEST et FDP TEST sur le bureau")
    print("="*60)
    
    tester = SemanticMatchingTester()
    await tester.run_full_semantic_test()
    
    print(f"\nüí° Notes:")
    print(f"‚Ä¢ Assurez-vous d'avoir les dossiers 'CV TEST' et 'FDP TEST' sur votre bureau")
    print(f"‚Ä¢ Formats support√©s: PDF, DOCX, TXT")
    print(f"‚Ä¢ Pour PDF: installer 'pip install PyPDF2'")
    print(f"‚Ä¢ Pour DOCX: installer 'pip install python-docx'")

if __name__ == "__main__":
    asyncio.run(main())
